<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Stevan A" />
  <title>Implementing Erlang's behaviours without using lightweight processes</title>
  <link rel="stylesheet" href="style.css" />
  <link rel="alternate" type="application/rss+xml"
        title="RSS feed"
        href="rss.xml" />
  <script data-goatcounter="https://stevana-github-io.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
  <noscript>
    <img src="https://stevana-github-io.goatcounter.com/count?p=/implementing_behaviours.html&t=Implementing Erlang's behaviours without using lightweight processes">
  </noscript>
</head>
<body>
<header id="title-block-header">
  <nav id="nav">
    <span class="title"><a href="/">Stevan's notes...</a></span>
    <a href="about.html">About</a>
    <a href="rss.xml">Feed <img height="10px" src="rss.svg" /></a>
  </nav>
</header>
<hr />
<main>
<h1>Implementing Erlang's behaviours without using lightweight processes</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#lightweight-processes-and-message-passing"
id="toc-lightweight-processes-and-message-passing">Lightweight processes
and message passing</a></li>
<li><a href="#generic-server" id="toc-generic-server">Generic
server</a></li>
<li><a href="#the-concurrent-infrastructure-for-a-single-generic-server"
id="toc-the-concurrent-infrastructure-for-a-single-generic-server">The
concurrent infrastructure for a single generic server</a></li>
<li><a href="#supervisor" id="toc-supervisor">Supervisor</a></li>
<li><a href="#the-concurrent-infrastructure-for-supervisor-trees"
id="toc-the-concurrent-infrastructure-for-supervisor-trees">The
concurrent infrastructure for supervisor trees</a></li>
<li><a href="#generic-event-manager-and-performance"
id="toc-generic-event-manager-and-performance">Generic event manager and
performance</a></li>
<li><a href="#application-and-release"
id="toc-application-and-release">Application and release</a></li>
<li><a href="#summary-and-contributing"
id="toc-summary-and-contributing">Summary and contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
</ul>
</nav>
<p>The other week I made the <a
href="https://github.com/stevana/armstrong-distributed-systems/blob/main/docs/erlang-is-not-about.md">claim</a>
that the big idea in Erlang isn’t lightweight processes and message
passing but rather its <em>behaviours</em><a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>.</p>
<p>In short: Erlang’s six behaviours, <code>gen_server</code>,
<code>gen_statem</code>, <code>gen_event</code>,
<code>supervisor</code>, <code>application</code> and
<code>release</code>, are building blocks for reliable distributed
systems. They abstract away the repetitive, difficult, low-level and
concurrent details, and let the user focus on the semantics of their
problem.</p>
<p>In Joe Armstrong’s own words: “Behaviors in Erlang can be thought of
as parameterizable higher-order parallel processes. They represent an
extension of conventional higher-order functions (like map, fold etc)
into a concurrent domain.”</p>
<p>Many comments, including <a
href="https://news.ycombinator.com/item?id=34558745">one</a> from Robert
Virding<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>, basically claim that one
<em>needs</em> lightweight processes and message passing in order to
implement behaviours.</p>
<p>Conceptually lightweight processes and message passing came before
behaviours after all, as Robert points out.</p>
<p>I can imagine that perhaps Erlang’s concurrency model makes it easier
to implement behaviours.</p>
<p>But I don’t think we can draw the conclusion that they are therefore
<em>needed</em> for implementing behaviours (maybe they <em>were</em>
needed in the special case of how Erlang evolved, but that’s not my
point, I’m talking about in <em>general</em>).</p>
<p>My intuition is: there are other ways of doing concurrency than
lightweight processes and message passing, a popular one is event-driven
programming and perhaps it make sense to implement behaviours in that
setting as well.</p>
<p>My goal isn’t to reimplement OTP, merely understand the fundamental
ideas behind behaviours, so that we can build and improve upon them
(outside of Erlang/OTP).</p>
<p>I think this is important because the understanding of behaviour
isn’t well established, unlike the idea of lightwight process and
message passing.</p>
<p>Leading to people stealing lightweight processes and message passing,
while failing to copy behaviours – which, from my understanding of Joe’s
thesis, are the key ingredients in being able to write reliable
systems<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>.</p>
<h2 id="lightweight-processes-and-message-passing">Lightweight processes
and message passing</h2>
<p>Let’s start off by defining what we mean by lightweight processes and
message passing.</p>
<p>To really understand a concept one needs to understand the context in
which it was conceived.</p>
<p>When Joe Armstrong <a
href="https://youtu.be/fhOHn9TClXY?t=2236">interviewed</a> Alan Kay in
2017, Joe explained how Erlang <a
href="https://dl.acm.org/doi/10.1145/1238844.1238850">came to
be</a>.</p>
<p>Joe says in the mid 1980s he was trying to improve the state of <a
href="https://en.wikipedia.org/wiki/Plain_old_telephone_service">programming
telephony</a>. This was before internet, but the telephone system had
“services” and “features” so I suppose in a sense he was interested in
improving what what we’d today call “backend development”.</p>
<p>At Ericsson, where he was working, they already had a proprietary
programming language called <a
href="https://en.wikipedia.org/wiki/PLEX_(programming_language)">PLEX</a>
which they used to program telephony. PLEX, which first appeared in the
70s, and the telephone hardware switches were a heavy influence on
Erlang:</p>
<ol type="1">
<li>Process and their isolation from each other;</li>
<li>Signals and ability to wait for them, i.e. message passing;</li>
<li>Hot code swapping.</li>
</ol>
<p>So the early inspiration for Erlang was to be a better version of
PLEX and run on ordinary hardware.</p>
<p>I suppose when Joe was looking around for programming languages that
might fit the bill, he found Alan et al’s <a
href="https://en.wikipedia.org/wiki/Smalltalk">Smalltalk</a>.</p>
<p>Alan said that the <a
href="http://lists.squeakfoundation.org/pipermail/squeak-dev/1998-October/017019.html">big
idea</a> in Smalltalk is message passing after all.</p>
<p>Alan, who did a BSc in mathematics and molecular biology, <a
href="http://userpage.fu-berlin.de/~ram/pub/pub_jf47ht81Ht/doc_kay_oop_en">said</a>:</p>
<blockquote>
<p>I thought of objects being like biological cells and/or individual
computers on a network, only able to communicate with messages (so
messaging came at the very beginning – it took a while to see how to do
messaging in a programming language efficiently enough to be
useful).</p>
</blockquote>
<p>(Smalltalk was also influenced by <a
href="https://dl.acm.org/doi/abs/10.1145/365813.365819">Simula</a>, but
I don’t know anything about Simula so I won’t go further down the rabbit
hole at this point. I’d like to understand Simula better because
apparently it was designed to enable continuous and discrete-event <a
href="https://en.wikipedia.org/wiki/Simula#Simulation">simulation</a>
which is related to the kind of <a
href="https://github.com/stevana/property-based-testing-stateful-systems-tutorial">testing</a>
that I care about.)</p>
<p>The problem was that when Joe was playing around with Smalltalk on
his Sun workstation, and it was so slow that he’d go for a coffee break
while it was garbage collecting.</p>
<p>Joe even ordered the first Tektronix Smalltalk <a
href="https://randoc.wordpress.com/2018/07/20/tektronix-smalltalk-workstations-4400-and-4300-series/">Workstation</a>
in hope of it making things faster.</p>
<p>Parallel to the Smalltalk experiments Joe was also developing an
algebra for telephony (i.e. a domain specific language using
mathematical notation).</p>
<p>While Joe was waiting for his Smalltalk machine to arrive, he got
chatting with a guy called Roger Skagervall and showed him his algebra,
Roger asked Joe if he had seen Prolog. Joe had not, so Roger pulled him
into his office and showed him how to implement his algebra in
Prolog.</p>
<p>The (probably quite expensive) Smalltalk machine arrived, but Joe
didn’t even plug it in…</p>
<p>And that’s the story of how Erlang started, Joe implemented his ideas
on how to improve PLEX in Prolog.</p>
<p>Kerstin Ödling, one of the first Erlang user, wanted to program the
MD110 telephone switch.</p>
<p>She was using fishbone diagrams (finite state machine without cycles)
like these<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> to describe telephony services (I’m
imagining these being something like telephone APIs):</p>
<figure>
<img src="images/fishbone-diagram.png"
alt="Kerstin’s fishbone diagrams" />
<figcaption aria-hidden="true">Kerstin’s fishbone diagrams</figcaption>
</figure>
<p>I suppose they didn’t have cycles, if you wanted to “go back” you’d
simply hang up and call again.</p>
<p>Here’s the direct translation of her diagram into Joe’s telephony
algebra written in Prolog:</p>
<p>Kerstin’s fishbone diagram in the Prolog library version of
Erlang:</p>
<p><img src="images/prolog-erlang.png" /></p>
<p>The diagrams describe one “session”, there were hundreds of thousands
of these happening in parallel.</p>
<p>These messages are sent between “processes”, or lightweight threads
(as opposed to heavyweight OS-level threads). The processes are
isolated, in that if one fails somehow it shouldn’t affect the other
processes.</p>
<p>Not sharing memory and therefor not be able to corrupt each others
memory. This implies no global variables.</p>
<p>But also not be able to hog all CPU in case the process starts doing
something that takes a very long time or ends up getting stuck in an
infinite loop.</p>
<p>That’s why Erlang has pre-emptive scheduling, a process will be run
until it gets stuck, waiting for a message or I/O, or it reaches some
max running time, at which point it will be switched out by the
scheduler and another process will be allowed to run. Hence even if a
process is stuck in an infinite loop, it will not cause any other
process to be stuck.</p>
<p>Given Erlang’s use case at Ericsson, how Ericsson’s hardware already
had process isolation, and Joe’s background in physics it seems quite
natural to opt for the lightweight process and message passing
approach.</p>
<p>Having explained what lightweight processes and message passing is in
Erlang, lets just note that similar concepts in other languages: Scala’s
Akka, Go channels, Microsoft’s <a
href="https://github.com/dotnet/orleans">virtual actors</a>, <a
href="https://haskell-distributed.github.io/">“Cloud Haskell”</a>, <a
href="https://doc.rust-lang.org/book/ch16-02-message-passing.html">Rust</a>,
the actor model…</p>
<p>While there are technical differences between all these
implementations, for the purpose of this article we shall group them all
together and say that they are implementations of lightweight processes
and message passing.</p>
<h2 id="generic-server">Generic server</h2>
<p>Now that we know how Erlang got its lightweight processes and message
passing, lets implement behaviours without them.</p>
<p>Let’s start with the perhaps most useful worker behaviour,
<code>gen_server</code>. We said in the previous post that behaviours
are interfaces, so lets define that first.</p>
<p>I’ll use pseudo code in order to try to be accessible to the wider
community. This pseudo language might have some features that your
favorite language doesn’t have, but don’t dispair I’ll try to provide
workarounds in the footnotes.</p>
<blockquote>
<p>interface <code>GenServer</code> parametrised by the types for
<em>state</em>, <em>input</em> and <em>output</em> and requiring the
functions: * <code>Step</code> that takes an <em>input</em> and the
current <em>state</em> and returns the updated <em>state</em> and an
<em>output</em>; * <code>Init</code> that returns the initial
<em>state</em>; * <code>Terminate</code> which takes the current
<em>state</em> and returns nothing.</p>
</blockquote>
<p>So the user must implement these three (sequential) functions in
order to get a concurrent server. The concurrent code is written against
(or parametrised by) this interface and will work for any instance of
this interface.</p>
<p>Let’s implement a counter as an example. The counter has an integer
as its state and it can be incremented, its current value can be read,
or it can be reset:</p>
<blockquote>
<p>data type <code>State</code> is an <code>Integer</code>. data type
<code>Input</code> is an enum with the tags <code>Increment</code>,
<code>Read</code> and <code>Reset</code>.</p>
</blockquote>
<p>The output of the counter when incrementing and resetting is an
acknowledgement while reading the current value returns an integer.</p>
<blockquote>
<p>data type <code>Output</code> is a tagged union<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>
with the tags <code>Ack</code> and <code>Value</code> where
<code>Value</code> has an <code>Integer</code> parameter.</p>
</blockquote>
<p>The implementation of the <code>Step</code> function is a completely
sequential program:</p>
<blockquote>
<p>function <code>Step</code> from <em>input</em> and <em>state</em> is
defined by case analysis on <em>input</em>: * if <code>Increment</code>,
then the new state is the old <em>state</em> + 1 and the output is
<code>Ack</code>; * if <code>Read</code>, then the new state is the old
<em>state</em> and the output is <code>Value</code> with the old
<em>state</em> as parameter; * if <code>Reset</code>, then check what
the current state is: if it’s 0 then crash (deliberate bug), otherwise
the new state is 0 and the output is <code>Ack</code>.</p>
</blockquote>
<p>We initialise our counter as follows:</p>
<blockquote>
<p>function <code>Init</code> checks if an previous state of the counter
has been saved to the disk. If that’s the case then use the saved value
as the intial state otherwise start with 0.</p>
</blockquote>
<p>Lastly we terminate our counter as follows:</p>
<blockquote>
<p>function <code>Terminate</code> takes the current <em>state</em> and
saves it to disk.</p>
</blockquote>
<p>The three functions, <code>Step</code>, <code>Init</code> and
<code>Terminate</code>, together implement the <code>GenServer</code>
interface.</p>
<p>Using the <code>Step</code> function we can define a <code>Run</code>
function which takes an intial state and a asequence of
<code>Input</code>s , it applies the <code>Step</code> function to the
first input and the initial state, takes the resulting state and
<code>Step</code>s the second input with it and so on, until it reaches
the last input then it returns the <code>Output</code>.</p>
<p>Using the <code>Run</code> function we can write some unit tests:</p>
<blockquote>
<p><code>Run</code> applied to the inital state <code>0</code> and the
sequence of <code>Input</code>s: *
<code>[Increment, Increment, Read]</code> should return
<code>Value 2</code>; * <code>[Increment, Increment]</code> should
return <code>Ack</code>; * <code>[Increment, Reset, Read]</code> should
return <code>Value 0</code>; * <code>[Reset, Reset, Read]</code> should
crash (because of our deliberate bug in <code>Step</code>).</p>
</blockquote>
<h2 id="the-concurrent-infrastructure-for-a-single-generic-server">The
concurrent infrastructure for a single generic server</h2>
<p>Before we make things more complicated by introducing other
behaviours than <code>gen_server</code>, lets see how we can get the
concurrent server from merely using our sequential
<code>GenServer</code> interface.</p>
<p>Lets introduce a new data type which packs up a few more pieces that
we need:</p>
<blockquote>
<p>data type <code>SomeServer</code> is a struct with the fields: *
<code>name</code> of type <code>String</code>; * <code>server</code> of
type <code>GenServer</code> where the type parameters <em>state</em>,
<em>input</em>, and <em>output</em> have been existenially quantified<a
href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>; * <code>state</code> of type
<em>state</em>. * <code>decode</code> of partial function type
<code>ByteString</code> to <em>input</em>; * <code>encode</code> of
function type <em>output</em> to <code>ByteString</code>.</p>
</blockquote>
<blockquote>
<p>function <code>EventLoop</code> is parametrised by
<em>someServer</em> of type <code>SomeServer</code> and is defined in
steps: 1. Create a concurrent <em>queue</em> of <code>Event</code>s; 2.
Fork off a new worker (heavyweight) thread with the <em>someServer</em>
and the <em>queue</em>; 3. Start a server with the <em>queue</em>.</p>
</blockquote>
<blockquote>
<p>data type <code>Event</code> is a tagged union with the tags: *
<code>Input</code> with a <code>ByteString</code> parameter and a
incoming <code>Socket</code> parameter; * <code>Exit</code>.</p>
</blockquote>
<p>The server accepts new connections concurrently, reads the incoming
request as a <code>ByteString</code> and enqueues an <code>Input</code>
to the concurrent <em>queue</em> together with the <code>Socket</code>
of the client that made the request.</p>
<p>Have we not just moved the problem of needing lightweight processes
from our <code>GenServer</code> implementation to the concurrent
<code>EventLoop</code>?</p>
<p>Using one lightweight process (or thread) per client is one way of
implementing the concurrent server, but we can also use a small fixed
number of (heavyweight OS-level) threads and a <a
href="https://eli.thegreenplace.net/2017/concurrent-servers-part-2-threads/">thread
pool</a>, or a single thread and do <a
href="https://eli.thegreenplace.net/2017/concurrent-servers-part-3-event-driven/">I/O
multiplexing</a>.</p>
<p>The worker thread reads from the <em>queue</em>, if it sees an
<code>Input</code> event it tries to <code>decode</code>s the
<code>ByteString</code>, if decoding fails we move on, if it succeeds we
feed the <em>input</em> to the <code>Step</code> function of the server
together with the current <code>state</code>. The <code>state</code>
field gets updated with the new state and the <em>output</em> gets
<code>encode</code>d into a <code>BytesString</code> and sent back to
the client via the <code>Socket</code>.</p>
<ul>
<li>XXX: Example interaction with our gen server &gt; definition
<code>SomeCounter</code> … &gt; function <code>Main</code> …</li>
</ul>
<p>Hopefully by now I’ve managed to convince you that we can, at least,
implement the <code>gen_server</code> behaviour without using
lightweight processes or message passing.</p>
<ul>
<li><p>The key idea is that the concurrent queue serialises the
concurrent requests, so that a single thread can apply the requests one
by one in a sequential fashion, similar to how we implemented
<code>Run</code>.</p></li>
<li><p>Already useful: separates concurrent networking code from the
sequential “business logic”</p></li>
<li><p>event loop (or game loop), event-driven program, reactor pattern
are all different names for the same well known alternatives to
lightweight processes/threads</p></li>
<li><p>One write thread, sqlite</p></li>
<li><p>Timeouts, schedule timer event to yourself, event loop takes care
of this</p></li>
<li><p>All in-memory, power loss = data loss, command sourcing or <a
href="https://github.com/stevana/coroutine-state-machines">async writing
to disk</a></p></li>
</ul>
<h2 id="supervisor">Supervisor</h2>
<p>Next lets have a look at how we can add supervisors.</p>
<blockquote>
<p>data type <code>Supervisor</code> is a recursive tagged union with
the tags: * <code>Leaf</code> with a <code>SomeServer</code> parameter
(or more generally any worker behaviour); * <code>Node</code> with a
<code>RestartStrategy</code> parameter and a <code>List</code> of child
<code>Supervisor</code>s parameter.</p>
</blockquote>
<blockquote>
<p>data type <code>RestartStrategy</code> is an enum with the tags
<code>OneForOne</code> and <code>OneForAll</code>.</p>
</blockquote>
<blockquote>
<p>definition <code>SupervisorExample</code> is of type
<code>Supervisor</code> and is a <code>Ǹode</code> with the restart
strategy <code>OneForOne</code> and the children: * <code>Leaf</code>
with a <code>SomeCounter</code>; * <code>Leaf</code> with a
<code>SomeCounter</code>.</p>
</blockquote>
<blockquote>
<p>function <code>Restart</code> takes the <em>name</em> (of type
<code>String</code>) of the <code>SomeServer</code> which failed and a
<code>Supervisor</code> tree and returns a <code>Supervisor</code> tree.
It’s defined in steps: 1. Traverse the supervisor tree and find the
<code>Leaf</code> which has a <code>SomeServer</code> with matching
<em>name</em>, lets calls this <code>SomeServer</code>
<em>failedServer</em>; 2. Go up the tree one step in the tree to find
the supervisor <code>Node</code> and its <code>RestartStrategy</code>,
lets call this <code>Node</code> <em>supervisorOfFailed</em>; 3. By case
analysis on the <code>RestartStrategy</code>: - If
<code>OneForOne</code> then <code>Terminate</code> and <code>Init</code>
<em>failedServer</em>; - If <code>OneForAll</code> then traverse the
list of child supervisor trees of <em>supervisorOfFailed</em> in
depth-first fashion and <code>Terminate</code> all
<code>SomeServer</code>s, then do another traversal and
<code>Init</code> all of them again.</p>
</blockquote>
<h2 id="the-concurrent-infrastructure-for-supervisor-trees">The
concurrent infrastructure for supervisor trees</h2>
<p>Since our plan is to be able to deploy several
<code>SomeServer</code>s arranged in a <code>Supervisor</code> tree, we
need to change the event data type to also include the name of which
<code>SomeServer</code> the <code>Input</code> is for.</p>
<blockquote>
<p>data type <code>EventSup</code> is a tagged union with the tags: *
<code>Input</code> with a name of type <code>String</code>, a
<code>ByteString</code> parameter and a incoming <code>Socket</code>
parameter; * <code>Exit</code>.</p>
</blockquote>
<p>The event loop for supervisor trees looks the same as before except
it’s now parametrised by a supervisor tree rather than just a single
<code>SomeServer</code>.</p>
<blockquote>
<p>function <code>EventLoopSup</code> is parametrised by <em>sup</em> of
type <code>Supervisor</code> and is defined in steps: 1. Create a
concurrent <em>queue</em> of <code>EventSup</code>s; 2. Fork off a new
worker thread with the <em>sup</em> and the <em>queue</em>; 3. Start a
server with the <em>queue</em>.</p>
</blockquote>
<p>The difference is in the worker thread. As before it reads from the
<em>queue</em>, if it sees an <code>Input</code> event it tries to
<code>decode</code>s the <code>ByteString</code>, if decoding fails we
move on, if it succeeds we feed the <em>input</em> to the
<code>Step</code> function of the server together with the current
<code>state</code>. It’s this <code>Step</code> function that is the
only thing that can fail, so we wrap the call in a try-catch and if it
fails we catch the error and call <code>Restart</code> on the supervisor
tree with the name of the failing worker.</p>
<p>The <code>state</code> field gets updated with the new state and the
<em>output</em> gets <code>encode</code>d into a
<code>BytesString</code> and sent back to the client via the
<code>Socket</code>.</p>
<ul>
<li><p>try to <code>Step</code>, if it fails then catch and call
<code>Restart</code></p></li>
<li><p>What is catchable might vary between programming languages,
ideally we want to be able to catch <em>any</em> exception including
assertion failures, explicitly signaled errors, undefined or missing
functionality, etc.</p></li>
<li><p>example using <code>SupervisorExample</code></p></li>
<li><p>Why is this effective?</p></li>
<li><p>Save log that lead up to crash for later debugging</p></li>
<li><p>Frequently restarted processes further down the tree</p></li>
</ul>
<h2 id="generic-event-manager-and-performance">Generic event manager and
performance</h2>
<ul>
<li><p>Concurrent queue = <a
href="https://en.wikipedia.org/wiki/Fan-in">fan-in</a></p></li>
<li><p>Event manager = fan-out / broadcast / pubsub</p></li>
<li><p>In Erlang event manager is a process that gets a message in its
mailbox and it copies it to the mailboxes of all subscribers to that
message</p></li>
<li><p>There’s a much more efficient way of doing this that doesn’t
require any copying (assuming that the broadcast is local, i.e. within
the node): LMAX disruptor</p></li>
<li><p>How disruptor works</p>
<ul>
<li>One worker behaviour per CPU core = parallelism, no copying due to
disruptor?</li>
<li>“multi-cast”</li>
<li>batching</li>
<li>pipelining</li>
<li>sharding</li>
<li>Built-in support for back-pressure, unlike in Erlang where you can
run out of memory due to the fact that the mailboxes are <a
href="https://github.com/ferd/pobox">unbounded</a></li>
<li>Determinstic (unlike lightweight processes, well there’s <a
href="http://quviq.com/documentation/pulse/index.html">PULSE</a>,
OCaml’s eio and Java’s project Loom has deterministic scheduling I
think)</li>
</ul></li>
</ul>
<p>Martin Thompson is perhaps best known for introducing the concept of
<em>mechanical sympathy</em> in the context of computers.</p>
<p>The term was originally coined by the racing driver <a
href="https://en.wikipedia.org/wiki/Jackie_Stewart">Jackie “Flying Scot”
Stewart</a>, who said:</p>
<blockquote>
<p>You don’t have to be an engineer to be be a racing driver, but you do
have to have Mechanical Sympathy.</p>
</blockquote>
<p>What he meant was that understanding how the car works makes you a
better driver. Martin makes the analogous claim that knowing how modern
CPUs work will make you a better programmer.</p>
<p>Martin has given several full talks on the topic, so I’ll not attempt
to repeat all that here</p>
<ul>
<li><p>short version: cpu caches: temporal, spatial, striding <a
href="https://youtu.be/fDGWWpHlzvw?t=1264"
class="uri">https://youtu.be/fDGWWpHlzvw?t=1264</a></p></li>
<li><p>queue’s don’t have mechanical sympathy, another (perhaps better
known?) Martin, Martin Fowler as <a
href="https://martinfowler.com/articles/lmax.html?ref=wellarchitected#QueuesAndTheirLackOfMechanicalSympathy">written</a>
about this</p></li>
</ul>
<p>In a <a href="https://youtu.be/OqsAGFExFgQ?t=2532">talk</a> at
Functional Conf 2017, Martin Thompson said:</p>
<blockquote>
<p>“If there’s one thing I’d say to the Erlang folks, it’s you got the
stuff right from a high-level, but you need to invest in your messaging
infrastructure so it’s super fast, super efficient and obeys all the
right properties to let this stuff work really well.”</p>
</blockquote>
<ul>
<li>Multicore OCaml’s <a
href="https://github.com/ocaml-multicore/eio">eio</a>
<ul>
<li>determinism</li>
<li>io_uring</li>
</ul></li>
<li>TigerBeetleDB’s <a
href="https://tigerbeetle.com/blog/a-friendly-abstraction-over-iouring-and-kqueue/">event
loop</a>
<ul>
<li>also determinism and io_uring</li>
</ul></li>
</ul>
<h2 id="application-and-release">Application and release</h2>
<p>Recall that an <code>application</code> is a <code>supervisor</code>
tree together with whatever else the application needs that is not the
code itself, e.g. graphical assets, configuration files, etc.</p>
<ul>
<li>Supervisor trees have a start up order.</li>
</ul>
<p>The final behaviour <code>release</code> is one or more
<code>application</code>s together with a way of upgrading from the
currently running release and a way of rolling back in case the upgrade
fails.</p>
<p>But they do provide structure in areas where most programming
languages don’t give you anything: reconfiguration, deployment and
upgrades.</p>
<p>Joe has <a href="https://youtu.be/h8nmzPh5Npg?t=960">talked</a> how
modules can evolve over time, how git is useless… while this isn’t part
of Erlang’s <code>release</code>s, it could still be interesting to
ponder.</p>
<ul>
<li>release?
<ul>
<li>upgrades
<ul>
<li>versioning messages and always supporting previous version?</li>
</ul></li>
<li>configuration</li>
<li>overcoming “container and yaml hell”?</li>
<li>hot code swapping</li>
<li>ssh access to remote machines in case of multi node deployment?</li>
</ul></li>
</ul>
<p>The last two behaviours <code>application</code> and
<code>release</code> clearly don’t have anything to do with lightweigt
processes and message passing.</p>
<ul>
<li>packaging, dependency management, dependency hell, nix…</li>
</ul>
<h2 id="summary-and-contributing">Summary and contributing</h2>
<ul>
<li><p>Hopefully it’s clear by now that <code>gen_server</code>,
<code>gen_event</code> and <code>supervisor</code> don’t <em>have</em>
to be implemented using lightweight processes and message
passing.</p></li>
<li><p>In fact implementing it the way outlined above might even have
performance benefits (benchmarks?)</p></li>
<li><p>Many things missing. Far from reimplementing OTP, but that’s not
the point. I want to understand the ideas behind OTP so that we one day
can implement something better!</p>
<ul>
<li>supervisors themselves failing</li>
<li>remote supervisors</li>
</ul></li>
<li><p>Performance penalty of having a try-catch around
<code>Step</code>? Is there something clever in the BEAM for how a
linked process that dies sends it exception to its supervisor?</p></li>
<li><p>If one worker behaviour per CPU/core then how does supervision
work? Links?</p></li>
<li><p>remote supervisors, how is this implemented in Erlang actually?
What happens if nodes get partitioned? Heartbeats?</p></li>
<li><p>pre-emptive? Less important when we are not spawning processes
left and right? One worker per CPU/core.</p></li>
<li><p>Erlang supports upgrading/hot code swapping a behaviour while
it’s running, but what about upgrading clustered Erlang nodes without
downtime?</p></li>
<li><p>What about the original problem of many concurrent state
machines?</p></li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><p>My Haskell <a
href="https://github.com/stevana/supervised-state-machines">implementation</a>
of the above pseudo code;</p></li>
<li><p><a href="https://dl.acm.org/doi/10.1145/1238844.1238850">A
history of Erlang</a> paper and talk (scroll down to “supplemental
material”) by Joe Armstrong (HOPL III, 2007);</p></li>
<li><p><a href="https://www.es.mdh.se/pdf_publications/663.pdf">The
Execution Model of APZ/PLEX</a></p></li>
<li><p><a href="https://blog.stenmans.org/theBeamBook/">The Erlang
Runtime System</a> by Erik Stenman;</p></li>
<li><p>Alan Kay on Erlang being an <a
href="https://www.quora.com/What-does-Alan-Kay-think-about-Joe-Armstrong-claiming-that-Erlang-might-be-the-only-object-oriented-language-and-also-his-thesis-supervisor-s-claim-that-Erlang-is-extremely-object-oriented">object
oriented programming language</a>;</p></li>
<li><p>Martin Thompson’s <a
href="https://www.infoq.com/presentations/mechanical-sympathy/">talk</a>
on <em>Mechanical Sympathy</em> (2013);</p></li>
<li><p><a href="https://www.infoq.com/presentations/LMAX/"><em>LMAX -
How to Do 100K TPS at Less than 1ms Latency</em></a> by Martin Thompson
(QCon 2010).</p></li>
<li><p><a href="https://www.youtube.com/watch?v=tM4YskS94b0"><em>Aeron:
Open-source high-performance messaging</em></a> talk by Martin Thompson
(Strange Loop, 2014);</p></li>
<li><p><a href="https://www.youtube.com/watch?v=p1bsloPeBzE"><em>Aeron:
What, Why and What Next?</em></a> talk by Todd Montgomery (GOTO,
2015);</p></li>
<li><p><a href="https://www.youtube.com/watch?v=RmheuBo3Cy0"><em>Cluster
Consensus When Aeron Met Raft</em></a> talk by Martin Thompson (Build
Stuff, 2018);</p></li>
<li><p><a href="https://github.com/mitchellh/libxev"
class="uri">https://github.com/mitchellh/libxev</a></p></li>
<li><p><a href="https://unixism.net/loti/index.html">Welcome to Lord of
the io_uring</a></p></li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Technically behaviours are part of the <a
href="https://en.wikipedia.org/wiki/Open_Telecom_Platform">Open Telecom
Platform</a> (OTP). According to <a
href="https://en.wikipedia.org/wiki/Erlang_(programming_language)">Wikipedia</a>
“the term Erlang is used interchangeably with Erlang/OTP”, so we’ll just
say Erlang.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>One of the original designers and implementors of
Erlang, as well as one of the “actors” in <a
href="https://www.youtube.com/watch?v=xrIjfIjssLE">Erlang the
movie</a>.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>In fact I think many languages and libraries have been
blinded by thinking that lightweight threads <em>have</em> to be part of
the solution in order to achieve Erlang’s robustness.</p>
<p>The example I’m most familiar with is <a
href="https://hackage.haskell.org/package/distributed-process">“Cloud
Haskell”</a>.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Kerstin’s fishbone diagams and Prolog implementation are
taken from the following <a href="https://vimeo.com/97329186">talk</a>
(18:00) by Joe.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Or enums and structs and potentially union types if your
language of choice doesn’t have <a
href="https://en.wikipedia.org/wiki/Tagged_union">sum types</a>.<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>If your language of choice doesn’t support <a
href="https://en.wikipedia.org/wiki/Type_system#Existential_types">existential
types</a>, then you got the choice of being less generic or less
well-typed. One way to be less generic is to parametrise the supervisor
type by the parameters of the generic server, but that means that all
your generic servers will have to have the same parameters. Or you can
be less well-typed by removing the parameters from
<code>GenServer</code> and simply use some generic but fixed type, like
type type of JSON objects.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</main>
</body>
</html>
