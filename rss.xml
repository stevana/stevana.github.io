<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stevan's notes</title>
    <description>Collection of notes on distributed systems.</description>
    <language>en</language>
    <link>https://stevana.github.io/rss.xml</link>
    <atom:link href="https://stevana.github.io/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parallel stream processing with zero-copy fan-out and sharding</title>
      <link>https://stevana.github.io/parallel_stream_processing_with_zero-copy_fan-out_and_sharding.html</link>
      <guid>https://stevana.github.io/parallel_stream_processing_with_zero-copy_fan-out_and_sharding.html</guid>
      <pubDate>Wed, 11 Oct 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>Parallel stream processing with zero-copy fan-out and sharding</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation-and-inspiration"
id="toc-motivation-and-inspiration">Motivation and inspiration</a></li>
<li><a href="#prior-work" id="toc-prior-work">Prior work</a></li>
<li><a href="#plan" id="toc-plan">Plan</a></li>
<li><a href="#list-transformer-model"
id="toc-list-transformer-model">List transformer model</a></li>
<li><a href="#queue-pipeline-deployment"
id="toc-queue-pipeline-deployment">Queue pipeline deployment</a></li>
<li><a href="#disruptor" id="toc-disruptor">Disruptor</a></li>
<li><a href="#disruptor-pipeline-deployment"
id="toc-disruptor-pipeline-deployment">Disruptor pipeline
deployment</a></li>
<li><a href="#observability"
id="toc-observability">Observability</a></li>
<li><a href="#running" id="toc-running">Running</a></li>
<li><a href="#further-work-and-contributing"
id="toc-further-work-and-contributing">Further work and
contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
</ul>
</nav>
<div class="date">Posted on Oct 11, 2023</div>
<p>In a previous <a
href="https://stevana.github.io/pipelined_state_machines.html">post</a>
I explored how we can make better use of our parallel hardware by means
of pipelining.</p>
<p>In a nutshell the idea of pipelining is to break up the problem in
stages and have one (or more) thread(s) per stage and then connect the
stages with queues. For example, imagine a service where we read some
request from a socket, parse it, validate, update our state and
construct a response, serialise the response and send it back over the
socket. These are six distinct stages and we could create a pipeline
with six CPUs/cores each working on a their own stage and feeding the
output to the queue of the next stage. If one stage is slow we can shard
the input, e.g. even requests to go to one worker and odd requests go to
another thereby nearly doubling the throughput for that stage.</p>
<p>One of the concluding remarks to the previous post is that we can
gain even more performance by using a better implementation of queues,
e.g. the <a
href="https://en.wikipedia.org/wiki/Disruptor_(software)">LMAX
Disruptor</a>.</p>
<p>The Disruptor is a low-latency high-throughput queue implementation
with support for multi-cast (many consumers can in parallel process the
same event), batching (both on producer and consumer side),
back-pressure, sharding (for scalability) and dependencies between
consumers.</p>
<p>In this post we’ll recall the problem of using “normal” queues,
discuss how Disruptor helps solve this problem and have a look at how we
can we provide a declarative high-level language for expressing
pipelines backed by Disruptors where all low-level details are hidden
away from the user of the library. We’ll also have a look at how we can
monitor and visualise such pipelines for debugging and performance
troubleshooting purposes.</p>
<h2 id="motivation-and-inspiration">Motivation and inspiration</h2>
<p>Before we dive into <em>how</em> we can achieve this, let’s start
with the question of <em>why</em> I’d like to do it.</p>
<p>I believe the way we write programs for multiprocessor networks,
i.e. multiple connected computers each with multiple CPUs/cores, can be
improved upon. Instead of focusing on the pitfalls of the current
mainstream approaches to these problems, let’s have a look at what to me
seems like the most promising way forward.</p>
<p>Jim Gray gave a great explanation of dataflow programming in this
Turing Award Recipient <a
href="https://www.youtube.com/watch?v=U3eo49nVxcA&amp;t=1949s">interview</a>.
He uses props to make his point, which makes it a bit difficult to
summaries in text here. I highly recommend watching the video clip, the
relevant part is only three minutes long.</p>
<p>The key point is exactly that of pipelining. Each stage is running on
a CPU/core, this program is completely sequential, but by connecting
several stages we create a parallel pipeline. Further parallelism (what
Jim calls partitioned parallelism) can be gained by partitioning the
inputs, by say odd and even sequence number, and feeding one half of the
inputs to one copy of the pipeline and the other half to another copy,
thereby almost doubling the throughput. Jim calls this a “natural” way
to achieve parallelism.</p>
<p>While I’m not sure if “natural” is the best word, I do agree that
it’s a nice way to make good use of CPUs/cores on a single computer
without introducing non-determinism. Pipelining is also effectively used
to achieve parallelism in manufacturing and hardware, perhaps that’s why
Jim calls it “natural”?</p>
<p>Things get a bit more tricky if we want to involve more computers.
Part of the reason, I believe, is that we run into the problem
highlighted by Barbara Liskov at the very end of her Turing award <a
href="https://youtu.be/qAKrMdUycb8?t=3058">lecture</a> (2009):</p>
<blockquote>
<p>“There’s a funny disconnect in how we write distributed programs. You
write your individual modules, but then when you want to connect them
together you’re out of the programming language and into this other
world. Maybe we need languages that are a little bit more complete now,
so that we can write the whole thing in the language.”</p>
</blockquote>
<p>Ideally we’d like our pipelines to seamlessly span over multiple
computers. In fact it should be possible to deploy same pipeline to
different configurations of processors without changing the pipeline
code (nor having to add any networking related code).</p>
<p>A pipeline that is redeployed with additional CPUs or computers might
or might not scale, it depends on whether it makes sense to partition
the input of a stage further or if perhaps the introduction of an
additional computer merely adds more overhead. How exactly the pipeline
is best spread over the available computers and CPUs/cores will require
some combination of domain knowledge, measurement and judgment.
Depending on how quick we can make redeploying of pipelines, it might be
possible to autoscale them using a program that monitors the queue
lengths.</p>
<p>Also related to redeploying, but even more important than
autoscaling, are upgrades of pipelines. That’s both upgrading the code
running at the individual stages, as well as how the stages are
connected to each other, i.e. the pipeline itself.</p>
<p>Martin Thompson has given many <a
href="https://www.youtube.com/watch?v=_KvFapRkR9I">talks</a> which echo
the general ideas of Jim and Barbara. If you prefer reading then you can
also have a look at the <a
href="https://www.reactivemanifesto.org/">reactive manifesto</a> which
he cowrote. Martin is also one of the people behind the Disruptor, which
we will come back to soon, and he also <a
href="https://youtu.be/OqsAGFExFgQ?t=2532">said</a> the following:</p>
<blockquote>
<p>“If there’s one thing I’d say to the Erlang folks, it’s you got the
stuff right from a high-level, but you need to invest in your messaging
infrastructure so it’s super fast, super efficient and obeys all the
right properties to let this stuff work really well.”</p>
</blockquote>
<p>This quote together with Joe Armstrong’s <a
href="https://youtu.be/bo5WL5IQAd0?t=2494">anecdote</a> of an unmodified
Erlang program <em>only</em> running 33 times faster on a 64 core
machine, rather than 64 times faster as per the Ericsson higher-up’s
expectations, inspired me to think about how one can improve upon the
already excellent work that Erlang is doing in this space.</p>
<p>Longer term, I like to think of pipelines spanning computers as a
building block for what Barbara <a
href="https://www.youtube.com/watch?v=8M0wTX6EOVI">calls</a> a
“substrate for distributed systems”. Unlike Barbara I don’t think this
substrate should be based on shared memory, but overall I agree with her
goal of making it easier to program distributed systems by providing
generic building blocks.</p>
<h2 id="prior-work">Prior work</h2>
<p>Working with streams of data is common. The reason for this is that
it’s a nice abstraction when dealing with data that cannot fit in
memory. The alternative is to manually load chunks of data one wants to
process into memory, load the next chunk etc, when we processes streams
this is hidden away from us.</p>
<p>Parallelism is a related problem, in that when one has big volumes of
data it’s also common to care about performance and how we can utilise
multiple processors.</p>
<p>Since dealing with limited memory and multiprocessors is a problem
that as bothered programmers and computer scientists for a long time, at
least since the 1960s, there’s a lot of work that has been done in this
area. I’m at best familiar with a small fraction of this work, so please
bear with me but also do let me know if I missed any important
development.</p>
<p>In 1963 Melvin Conway proposed <a
href="https://dl.acm.org/doi/10.1145/366663.366704">coroutines</a>,
which allows the user to conveniently process very large, or even
infinite, lists of items without first loading the list into memory,
i.e. streaming.</p>
<p>Shortly after, in 1965, Peter Landin introduced <a
href="https://dl.acm.org/doi/10.1145/363744.363749">streams</a> as a
functional analogue of Melvin’s imperative coroutines.</p>
<p>A more radical departure from Von Neumann style sequential
programming can be seen in the work on <a
href="https://en.wikipedia.org/wiki/Dataflow_programming">dataflow
programming</a> in general and especially in Paul Morrison’s <a
href="https://jpaulm.github.io/fbp/index.html">flow-based
programming</a> (late 1960s). Paul uses the following picture to
illustrate the similarity between flow-based programming and an assembly
line in manufacturing:</p>
<p><img
src="https://raw.githubusercontent.com/stevana/pipelining-with-disruptor/main/data/bottling_factory.png" /></p>
<p>Each stage is its own process running in parallel with the other
stages. In flow-based programming stages are computation and the
conveyor belts are queues. This gives us implicit parallelism and
determinate outcome.</p>
<p>Doug McIlroy, who was aware of some of the dataflow work<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>, wrote a <a
href="http://doc.cat-v.org/unix/pipes/">memo</a> in 1964 about the idea
of pipes, although it took until 1973 for them to get implemented in
Unix by Ken Thompson. Unix pipes have a strong feel of flow-based
programming, although all data is of type string. A pipeline of commands
will start a process per command, so there’s implicit parallelism as
well (assuming the operative system schedules different processes on
different CPUs/cores). Fanning out can be done with <code>tee</code> and
process substitution,
e.g. <code>echo foo | tee &gt;(cat) &gt;(cat) | cat</code>, and more
complicated non-linear flows can be achieved with
<code>mkfifo</code>.</p>
<p>With the release of GNU <a
href="https://en.wikipedia.org/wiki/GNU_parallel"><code>parallel</code></a>
in 2010 more explicit control over parallelism was introduced as well as
the ability to run jobs on remote computers.</p>
<p>Around the same time many (functional) programming languages started
getting streaming libraries. Haskell’s <a
href="https://hackage.haskell.org/package/conduit">conduit</a> library
had its first release in 2011 and Haskell’s <a
href="https://hackage.haskell.org/package/pipes">pipes</a> library came
shortly after (2012). Java version 8, which has streams, was released in
2014. Both <a
href="https://clojure.org/reference/transducers">Clojure</a> and <a
href="https://doc.akka.io/docs/akka/current/stream/index.html">Scala</a>,
which also use the JVM, got streams that same year (2014).</p>
<p>Among the more imperative programming languages, JavaScript and
Python both have generators (a simple form of coroutines) since around
2006. Go has “goroutines”, a clear nod to coroutines, since its first
version (2009). Coroutines are also part of the C++20 standard.</p>
<p>Almost all of the above mentioned streaming libraries are intended to
be run on a single computer. Often they even run in a single thread,
i.e. not exploiting parallelism at all. Sometimes concurrent/async
constructs are available which create a pool of worker threads that
process the items concurrently, but they often break determinism
(i.e. rerunning the same computation will yield different results,
because the workers do not preserve the order of the inputs).</p>
<p>If the data volumes are too big for a single computer then there’s a
different set of streaming tools, such as Apache Hadoop (2006), Apache
Spark (2009), Apache Kafka (2011), Apache Storm (2011), and Apache Flink
(2011). While the Apache tools can often be deployed locally for testing
purposes, they are intended for distributed computations and are
therefore perhaps a bit more cumbersome to deploy and use than the
streaming libraries we mentioned earlier.</p>
<p>Initially it might not seem like a big deal that streaming libraries
don’t “scale up” or distributed over multiple computers, and that
streaming tools like the Apache ones don’t gracefully “scale down” to a
single computer. Just pick the right tool for the right job, right?
Well, it turns out that <a
href="https://youtu.be/XPlXNUXmcgE?t=2783">40-80%</a> of jobs submitted
to MapReduce systems (such as Apache Hadoop) would run faster if they
were ran on a single computer instead of a distributed cluster of
computers, so picking the right tool is perhaps not as easy as it first
seems.</p>
<p>There are two exceptions, that I know of, of streaming libraries that
also work in a distributed setting. Scala’s Akka/Pekko <a
href="https://doc.akka.io/docs/akka/current/stream/stream-refs.html">streams</a>
(2014) when combined with Akka/Pekko <a
href="https://github.com/apache/incubator-pekko-management">clusters</a>
and <a href="https://aeron.io/">Aeron</a> (2014). Aeron is the spiritual
successor of the Disruptor also written by Martin Thompson et al. The
Disruptor’s main use case was as part of the LMAX exchange. From what I
understand exchanges close in the evening (or at least did back then in
the case of LMAX), which allows for updates etc. These requirements
changed for Aeron where 24/7 operation was necessary and so distributed
stream processing is necessary where upgrades can happen without
processing stopping (or even slowing down).</p>
<p>Finally, I’d also like to mention functional reactive programming, or
FRP, (1997). I like to think of it as a neat way of expressing stream
processing networks. Disruptor’s <a
href="https://github.com/LMAX-Exchange/disruptor/wiki/Disruptor-Wizard">“wizard”</a>
DSL and Akka’s <a
href="https://doc.akka.io/docs/akka/current/stream/stream-graphs.html">graph
DSL</a> try to add a high-level syntax for expressing networks, but they
both have a rather imperative rather than declarative feel. It’s however
not clear (to me) how effectively implement, parallelise<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, or
distribute FRP. Some interesting work has been done with hot code
swapping in the FRP <a
href="https://github.com/turion/essence-of-live-coding">setting</a>,
which is potentially useful for a telling a good upgrade story.</p>
<p>To summarise, while there are many streaming libraries there seem to
be few (at least that I know of) that tick all of the following
boxes:</p>
<ol type="1">
<li>Parallel processing:
<ul>
<li>in a determinate way;</li>
<li>fanning out and sharding without copying data (when run on a single
computer).</li>
</ul></li>
<li>Potentially distributed over multiple computers for fault tolerance
and upgrades, without the need to change the code of the pipeline;</li>
<li>Observable, to ease debugging and performance analysis;</li>
<li>Declarative high-level way of expressing stream processing networks
(i.e. the pipeline);</li>
<li>Good deploy, upgrade, rescale story for stateful systems;</li>
<li>Elastic, i.e. ability to rescale automatically to meet the
load.</li>
</ol>
<p>I think we need all of the above in order to build Barbara’s
“substrate for distributed systems”. We’ll not get all the way there in
this post, but at least this should give you a sense of the direction
I’d like to go.</p>
<h2 id="plan">Plan</h2>
<p>The rest of this post is organised as follows.</p>
<p>First we’ll have a look at how to model pipelines as a transformation
of lists. The purpose of this is to give us an easy to understand
sequential specification of what we would like our pipelines to do.</p>
<p>We’ll then give our first parallel implementation of pipelines using
“normal” queues. The main point here is to recap of the problem with
copying data that arises from using “normal” queues, but we’ll also
sketch how one can test the parallel implementation using the model.</p>
<p>After that we’ll have a look at the Disruptor API, sketch its single
producer implementation and discuss how it helps solve the problems we
identified in the previous section.</p>
<p>Finally we’ll have enough background to be able to sketch the
Disruptor implementation of pipelines. We’ll also discuss how
monitoring/observability can be added.</p>
<h2 id="list-transformer-model">List transformer model</h2>
<p>Let’s first introduce the type for our pipelines. We index our
pipeline datatype by two types, in order to be able to precisely specify
its input and output types. For example, the <code>Id</code>entity
pipeline has the same input as output type, while pipeline composition
(<code>:&gt;&gt;&gt;</code>) expects its first argument to be a pipeline
from <code>a</code> to <code>b</code>, and the second argument a
pipeline from <code>b</code> to <code>c</code> in order for the
resulting composed pipeline to be from <code>a</code> to <code>c</code>
(similar to functional composition).</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">P</span><span class="ot"> ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span> <span class="kw">where</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Id</span><span class="ot">      ::</span> <span class="dt">P</span> a a</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&gt;&gt;&gt;)  ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">P</span> b c <span class="ot">-&gt;</span> <span class="dt">P</span> a c</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Map</span><span class="ot">     ::</span> (a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> <span class="dt">P</span> a b</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:***)  ::</span> <span class="dt">P</span> a c <span class="ot">-&gt;</span> <span class="dt">P</span> b d <span class="ot">-&gt;</span> <span class="dt">P</span> (a, b) (c, d)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&amp;&amp;&amp;)  ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">P</span> a c <span class="ot">-&gt;</span> <span class="dt">P</span> a (b, c)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:+++)  ::</span> <span class="dt">P</span> a c <span class="ot">-&gt;</span> <span class="dt">P</span> b d <span class="ot">-&gt;</span> <span class="dt">P</span> (<span class="dt">Either</span> a b) (<span class="dt">Either</span> c d)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:|||)  ::</span> <span class="dt">P</span> a c <span class="ot">-&gt;</span> <span class="dt">P</span> b c <span class="ot">-&gt;</span> <span class="dt">P</span> (<span class="dt">Either</span> a b) c</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span><span class="ot">   ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">P</span> a b</span></code></pre></div>
<p>Here’s a pipeline that takes a stream of integers as input and
outputs a stream of pairs where the first component is the input integer
and the second component is a boolean indicating if the first component
was an even integer or not.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ot">examplePipeline ::</span> <span class="dt">P</span> <span class="dt">Int</span> (<span class="dt">Int</span>, <span class="dt">Bool</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>examplePipeline <span class="ot">=</span> <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Map</span> <span class="fu">even</span></span></code></pre></div>
<p>So far our pipelines are merely data which describes what we’d like
to do. In order to actually perform a stream transformation we’d need to
give semantics to our pipeline datatype<a href="#fn3"
class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>.</p>
<p>The simplest semantics we can give our pipelines is that in terms of
list transformations.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ot">model ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> [a] <span class="ot">-&gt;</span> [b]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>model <span class="dt">Id</span>         xs  <span class="ot">=</span> xs</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>model (f <span class="op">:&gt;&gt;&gt;</span> g) xs  <span class="ot">=</span> model g (model f xs)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>model (<span class="dt">Map</span> f)    xs  <span class="ot">=</span> <span class="fu">map</span> f xs</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>model (f <span class="op">:***</span> g) xys <span class="ot">=</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    (xs, ys) <span class="ot">=</span> <span class="fu">unzip</span> xys</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">in</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">zip</span> (model f xs) (model g ys)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>model (f <span class="op">:&amp;&amp;&amp;</span> g) xs <span class="ot">=</span> <span class="fu">zip</span> (model f xs) (model g xs)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>model (f <span class="op">:+++</span> g) es <span class="ot">=</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    (xs, ys) <span class="ot">=</span> partitionEithers es</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">in</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- Note that we pass in the input list, in order to perserve the order.</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    merge es (model f xs) (model g ys)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    merge []             []       []       <span class="ot">=</span> []</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    merge (<span class="dt">Left</span>  _ <span class="op">:</span> es) (l <span class="op">:</span> ls) rs       <span class="ot">=</span> <span class="dt">Left</span>  l <span class="op">:</span> merge es ls rs</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    merge (<span class="dt">Right</span> _ <span class="op">:</span> es) ls       (r <span class="op">:</span> rs) <span class="ot">=</span> <span class="dt">Right</span> r <span class="op">:</span> merge es ls rs</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>model (f <span class="op">:|||</span> g) es <span class="ot">=</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    (xs, ys) <span class="ot">=</span> partitionEithers es</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  <span class="kw">in</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    merge es (model f xs) (model g ys)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    merge []             []       []       <span class="ot">=</span> []</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    merge (<span class="dt">Left</span>  _ <span class="op">:</span> es) (l <span class="op">:</span> ls) rs       <span class="ot">=</span> l <span class="op">:</span> merge es ls rs</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    merge (<span class="dt">Right</span> _ <span class="op">:</span> es) ls       (r <span class="op">:</span> rs) <span class="ot">=</span> r <span class="op">:</span> merge es ls rs</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>model (<span class="dt">Shard</span> f) xs <span class="ot">=</span> model f xs</span></code></pre></div>
<p>Note that this semantics is completely sequential and preserves the
order of the inputs (determinism). Also note that since we don’t have
parallelism yet, <code>Shard</code>ing doesn’t do anything. We’ll
introduce parallelism without breaking determinism in the next
section.</p>
<p>We can now run our example pipeline in the REPL:</p>
<pre><code>&gt; model examplePipeline [1,2,3,4,5]
[(1,False),(2,True),(3,False),(4,True),(5,False)]</code></pre>
<h2 id="queue-pipeline-deployment">Queue pipeline deployment</h2>
<p>In the previous section we saw how to deploy pipelines in a purely
sequential way in order to process lists. The purpose of this is merely
to give ourselves an intuition of what pipelines should do as well as an
executable model which we can test our intuition against.</p>
<p>Next we shall have a look at our first parallel deployment. The idea
here is to show how we can involve multiple threads in the stream
processing, without making the output non-deterministic (same input
should always give the same output).</p>
<p>We can achieve this as follows:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ot">deploy ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">TQueue</span> b)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>deploy <span class="dt">Id</span>         xs <span class="ot">=</span> <span class="fu">return</span> xs</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>deploy (f <span class="op">:&gt;&gt;&gt;</span> g) xs <span class="ot">=</span> deploy g <span class="op">=&lt;&lt;</span> deploy f xs</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>deploy (<span class="dt">Map</span> f)    xs <span class="ot">=</span> deploy (<span class="dt">MapM</span> (<span class="fu">return</span> <span class="op">.</span> f)) xs</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>deploy (<span class="dt">MapM</span> f)   xs <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- (Where `MapM :: (a -&gt; IO b) -&gt; P a b` is the monadic generalisation of</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- `Map` from the list model that we saw earlier.)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  ys <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  forkIO <span class="op">$</span> forever <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> atomically (readTQueue xs)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> f x</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    atomically (writeTQueue ys y)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> ys</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>deploy (f <span class="op">:&amp;&amp;&amp;</span> g) xs <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  xs1 <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  xs2 <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  forkIO <span class="op">$</span> forever <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> atomically (readTQueue xs)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    atomically <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>      writeTQueue xs1 x</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>      writeTQueue xs2 x</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  ys <span class="ot">&lt;-</span> deploy f xs1</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  zs <span class="ot">&lt;-</span> deploy g xs2</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  yzs <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>  forkIO <span class="op">$</span> forever <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> atomically (readTQueue ys)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> atomically (readTQueue zs)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    atomically (writeTQueue yzs (y, z))</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> yzs</span></code></pre></div>
<p>(I’ve omitted the cases for <code>:|||</code> and <code>:+++</code>
to not take up too much space. We’ll come back and handle
<code>Shard</code> separately later.)</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ot">example&#39; ::</span> [<span class="dt">Int</span>] <span class="ot">-&gt;</span> <span class="dt">IO</span> [(<span class="dt">Int</span>, <span class="dt">Bool</span>)]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>example&#39; xs0 <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  xs <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mapM_</span> (atomically <span class="op">.</span> writeTQueue xs) xs0</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  ys <span class="ot">&lt;-</span> deploy (<span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Map</span> <span class="fu">even</span>) xs</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  replicateM (<span class="fu">length</span> xs0) (atomically (readTQueue ys))</span></code></pre></div>
<p>Running <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/QueueDeployment.hs">this</a>
in our REPL, gives the same result as in the model:</p>
<pre><code>&gt; example&#39; [1,2,3,4,5]
[(1,False),(2,True),(3,False),(4,True),(5,False)]</code></pre>
<p>In fact, we can use our model to define a property-based test which
asserts that our queue deployment is faithful to the model:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ot">prop_commute ::</span> <span class="dt">Eq</span> b <span class="ot">=&gt;</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> [a] <span class="ot">-&gt;</span> <span class="dt">PropertyM</span> <span class="dt">IO</span> ()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>prop_commute p xs <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  ys <span class="ot">&lt;-</span> run <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    qxs <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mapM_</span> (atomically <span class="op">.</span> writeTQueue qxs) xs</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    qys <span class="ot">&lt;-</span> deploy p qxs</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    replicateM (<span class="fu">length</span> xs) (atomically (readTQueue qys))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  assert (model p xs <span class="op">==</span> ys)</span></code></pre></div>
<p>Actually running this property for arbitrary pipelines would require
us to first define a pipeline generator, which is a bit tricky given the
indexes of the datatype<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>. It can still me used as a helper
for testing specific pipelines though,
e.g. <code>prop_commute examplePipeline</code>.</p>
<p>A bigger problem is that we’ve spawned two threads, when deploying
<code>:&amp;&amp;&amp;</code>, whose mere job is to copy elements from
the input queue (<code>xs</code>) to the input queues of <code>f</code>
and <code>g</code> (<code>xs{1,2}</code>), and from the outputs of
<code>f</code> and <code>g</code> (<code>ys</code> and <code>zs</code>)
to the output of <code>f &amp;&amp;&amp; g</code> (<code>ysz</code>).
Copying data is expensive.</p>
<p>When we shard a pipeline we effectively clone it and send half of the
traffic to one clone and the other half to the other. One way to achieve
this is as follows, notice how in <code>shard</code> we swap
<code>qEven</code> and <code>qOdd</code> when we recurse:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>deploy (<span class="dt">Shard</span> f) xs <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  xsEven <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  xsOdd  <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  _pid   <span class="ot">&lt;-</span> forkIO (shard xs xsEven xsOdd)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  ysEven <span class="ot">&lt;-</span> deploy f xsEven</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  ysOdd  <span class="ot">&lt;-</span> deploy f xsOdd</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  ys     <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  _pid   <span class="ot">&lt;-</span> forkIO (merge ysEven ysOdd ys)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> ys</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="ot">    shard ::</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    shard  qIn qEven qOdd <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>      atomically (readTQueue qIn <span class="op">&gt;&gt;=</span> writeTQueue qEven)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>      shard qIn qOdd qEven</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="ot">    merge ::</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">TQueue</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    merge qEven qOdd qOut <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>      atomically (readTQueue qEven <span class="op">&gt;&gt;=</span> writeTQueue qOut)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>      merge qOdd qEven qOut</span></code></pre></div>
<p>This alteration will shard the input queue (<code>qIn</code>) on even
and odd indices, and we can <code>merge</code> it back without losing
determinism. Note that if we’d simply had a pool of worker threads
taking items from the input queue and putting them on the output queue
(<code>qOut</code>) after processing, then we wouldn’t have a
deterministic outcome. Also notice that in the <code>deploy</code>ment
of <code>Shard</code>ing we also end up copying data between the queues,
similar to the fan-out case (<code>:&amp;&amp;&amp;</code>)!</p>
<p>Before we move on to show how to avoid doing this copying, let’s have
a look at a couple of examples to get a better feel for pipelining and
sharding. If we generalise <code>Map</code> to <code>MapM</code> in our
<a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/ModelIO.hs">model</a>
we can write the following contrived program:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ot">modelSleep ::</span> <span class="dt">P</span> () ()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>modelSleep <span class="ot">=</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">MapM</span> (<span class="fu">const</span> (threadDelay <span class="dv">250000</span>)) <span class="op">:&amp;&amp;&amp;</span> <span class="dt">MapM</span> (<span class="fu">const</span> (threadDelay <span class="dv">250000</span>)) <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">MapM</span> (<span class="fu">const</span> (threadDelay <span class="dv">250000</span>)) <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">MapM</span> (<span class="fu">const</span> (threadDelay <span class="dv">250000</span>))</span></code></pre></div>
<p>The argument to <code>threadDelay</code> (or sleep) is microseconds,
so at each point in the pipeline we are sleeping 1/4 of a second.</p>
<p>If we feed this pipeline <code>5</code> items:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ot">runModelSleep ::</span> <span class="dt">IO</span> ()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>runModelSleep <span class="ot">=</span> void (model modelSleep (<span class="fu">replicate</span> <span class="dv">5</span> ()))</span></code></pre></div>
<p>We see that it takes roughly 5 seconds:</p>
<pre><code>&gt; :set +s
&gt; runModelSleep
(5.02 secs, 905,480 bytes)</code></pre>
<p>This is expected, even though we pipeline and fan-out, as the model
is completely sequential.</p>
<p>If we instead run the same pipeline using the queue deployment, we
get:</p>
<pre><code>&gt; runQueueSleep
(1.76 secs, 907,160 bytes)</code></pre>
<p>The reason for this is that the two sleeps in the fan-out happen in
parallel now and when the first item is at the second stage the first
stage starts processing the second item, and so on, i.e. we get a
pipelining parallelism.</p>
<p>If we, for some reason, wanted to achieve a sequential running time
using the queue deployment, we’d have to write a one stage pipeline like
so:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ot">queueSleepSeq ::</span> <span class="dt">P</span> () ()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>queueSleepSeq <span class="ot">=</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">MapM</span> <span class="op">$</span> \() <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    ()       <span class="ot">&lt;-</span> threadDelay <span class="dv">250000</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    ((), ()) <span class="ot">&lt;-</span> (,) <span class="op">&lt;$&gt;</span> threadDelay <span class="dv">250000</span> <span class="op">&lt;*&gt;</span> threadDelay <span class="dv">250000</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    ()       <span class="ot">&lt;-</span> threadDelay <span class="dv">250000</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span> ()</span></code></pre></div>
<pre><code>&gt; runQueueSleepSeq
(5.02 secs, 898,096 bytes)</code></pre>
<p>Using sharding we can get an even shorter running time:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ot">queueSleepSharded ::</span> <span class="dt">P</span> () ()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>queueSleepSharded <span class="ot">=</span> <span class="dt">Shard</span> queueSleep</span></code></pre></div>
<pre><code>&gt; runQueueSleepSharded
(1.26 secs, 920,888 bytes)</code></pre>
<p>This is pretty much where we left off in my previous post. If the
speed ups we are seeing from pipelining don’t make sense, it might help
to go back and reread the <a
href="https://stevana.github.io/pipelined_state_machines.html">old
post</a>, as I spent some more time constructing an intuitive example
there.</p>
<h2 id="disruptor">Disruptor</h2>
<p>Before we can understand how the Disruptor can help us avoid the
problem copying between queues that we just saw, we need to first
understand a bit about how the Disruptor is implemented.</p>
<p>We will be looking at the implementation of the single-producer
Disruptor, because in our pipelines there will never be more than one
producer per queue (the stage before it)<a href="#fn5"
class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>.</p>
<p>Let’s first have a look at the datatype and then explain each
field:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">RingBuffer</span> a <span class="ot">=</span> <span class="dt">RingBuffer</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  {<span class="ot"> capacity             ::</span> <span class="dt">Int</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> elements             ::</span> <span class="dt">IOArray</span> <span class="dt">Int</span> a</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> cursor               ::</span> <span class="dt">IORef</span> <span class="dt">SequenceNumber</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> gatingSequences      ::</span> <span class="dt">IORef</span> (<span class="dt">IOArray</span> <span class="dt">Int</span> (<span class="dt">IORef</span> <span class="dt">SequenceNumber</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> cachedGatingSequence ::</span> <span class="dt">IORef</span> <span class="dt">SequenceNumber</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="kw">newtype</span> <span class="dt">SequenceNumber</span> <span class="ot">=</span> <span class="dt">SequenceNumber</span> <span class="dt">Int</span></span></code></pre></div>
<p>The Disruptor is a ring buffer queue with a fixed
<code>capacity</code>. It’s backed by an array whose length is equal to
the capacity, this is where the <code>elements</code> of the ring buffer
are stored. There’s a monotonically increasing counter called the
<code>cursor</code> which keeps track of how many elements we have
written. By taking the value of the <code>cursor</code> modulo the
<code>capacity</code> we get the index into the array where we are
supposed to write our next element (this is how we wrap around the
array, i.e. forming a ring). In order to avoid overwriting elements
which have not yet been consumed we also need to keep track of the
cursors of all consumers (<code>gatingSequences</code>). As an
optimisation we cache where the last consumer is
(<code>cachedGatingSequence</code>).</p>
<p>The API from the producing side looks as follows:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="ot">tryClaimBatch   ::</span> <span class="dt">RingBuffer</span> a <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Maybe</span> <span class="dt">SequenceNumber</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="ot">writeRingBuffer ::</span> <span class="dt">RingBuffer</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="ot">publish         ::</span> <span class="dt">RingBuffer</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span></code></pre></div>
<p>We first try to claim <code>n :: Int</code> slots in the ring buffer,
if that fails (returns <code>Nothing</code>) then we know that there
isn’t space in the ring buffer and we should apply backpressure upstream
(e.g. if the producer is a web server, we might want to temporarily
rejecting clients with status code 503). Once we successfully get a
sequence number, we can start writing our data. Finally we publish the
sequence number, this makes it available on the consumer side.</p>
<p>The consumer side of the API looks as follows:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ot">addGatingSequence ::</span> <span class="dt">RingBuffer</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">IORef</span> <span class="dt">SequenceNumber</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="ot">waitFor           ::</span> <span class="dt">RingBuffer</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">SequenceNumber</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="ot">readRingBuffer    ::</span> <span class="dt">RingBuffer</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> a</span></code></pre></div>
<p>First we need to add a consumer to the ring buffer (to avoid
overwriting on wrap around of the ring), this gives us a consumer
cursor. The consumer is responsible for updating this cursor, the ring
buffer will only read from it to avoid overwriting. After the consumer
reads the cursor, it calls <code>waitFor</code> on the read value, this
will block until an element has been <code>publish</code>ed on that slot
by the producer. In the case that the producer is ahead it will return
the current sequence number of the producer, hence allowing the consumer
to do a batch of reads (from where it currently is to where the producer
currently is). Once the consumer has caught up with the producer it
updates its cursor.</p>
<p>Here’s an example which hopefully makes things more concrete:</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ot">example ::</span> <span class="dt">IO</span> ()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>example <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  rb <span class="ot">&lt;-</span> newRingBuffer_ <span class="dv">2</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  c <span class="ot">&lt;-</span> addGatingSequence rb</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> batchSize <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Just</span> hi <span class="ot">&lt;-</span> tryClaimBatch rb batchSize</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> lo <span class="ot">=</span> hi <span class="op">-</span> (coerce batchSize <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  assertIO (lo <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>  assertIO (hi <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Notice that these writes are batched:</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mapM_</span> (\(i, c) <span class="ot">-&gt;</span> writeRingBuffer rb i c) (<span class="fu">zip</span> [lo<span class="op">..</span>hi] [<span class="ch">&#39;a&#39;</span><span class="op">..</span>])</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>  publish rb hi</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Since the ring buffer size is only two and we&#39;ve written two</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- elements, it&#39;s full at this point:</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Nothing</span> <span class="ot">&lt;-</span> tryClaimBatch rb <span class="dv">1</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  consumed <span class="ot">&lt;-</span> readIORef c</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>  produced <span class="ot">&lt;-</span> waitFor rb consumed</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- The consumer can do batched reads, and only do some expensive</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- operation once it reaches the end of the batch:</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>  xs <span class="ot">&lt;-</span> <span class="fu">mapM</span> (readRingBuffer rb) [consumed <span class="op">+</span> <span class="dv">1</span><span class="op">..</span>produced]</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>  assertIO (xs <span class="op">==</span> <span class="st">&quot;ab&quot;</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- The consumer updates its cursor:</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>  writeIORef c produced</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Now there&#39;s space again for the producer:</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Just</span> <span class="dv">2</span> <span class="ot">&lt;-</span> tryClaimBatch rb <span class="dv">1</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> ()</span></code></pre></div>
<p>See the <code>Disruptor</code> <a href="src/Disruptor.hs">module</a>
in case you are interested in the implementation details.</p>
<p>Hopefully by now we’ve seen enough internals to be able to explain
why the Disruptor performs well. First of all, by using a ring buffer we
only allocate memory when creating the ring buffer, it’s then reused
when we wrap around the ring. The ring buffer is implemented using an
array, so the memory access patterns are predictable and the CPU can do
prefetching. The consumers don’t have a copy of the data, they merely
have a pointer (the sequence number) to how far in the producer’s ring
buffer they are, which allows for fanning out or sharding to multiple
consumers without copying data. The fact that we can batch on both the
write side (with <code>tryClaimBatch</code>) and on the reader side
(with <code>waitFor</code>) also helps. All this taken together
contributes to the Disruptor’s performance.</p>
<h2 id="disruptor-pipeline-deployment">Disruptor pipeline
deployment</h2>
<p>Recall that the reason we introduced the Disruptor was to avoid
copying elements of the queue when fanning out (using the
<code>:&amp;&amp;&amp;</code> combinator) and sharding.</p>
<p>The idea would be to have the workers we fan-out to both be consumers
of the same Disruptor, that way the inputs don’t need to be copied.
Avoiding to copy the individual outputs from the worker’s queues (of
<code>a</code>s and <code>b</code>s) into the combined output (of
<code>(a, b)</code>s) is a bit trickier.</p>
<p>One way, that I think works, is to do something reminiscent what <a
href="https://hackage.haskell.org/package/vector"><code>Data.Vector</code></a>
does for pairs. That’s a vector of pairs (<code>Vector (a, b)</code>) is
actually represented as a pair of vectors
(<code>(Vector a, Vector b)</code>)<a href="#fn6" class="footnote-ref"
id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<p>We can achieve this with <a
href="http://simonmar.github.io/bib/papers/assoc.pdf">associated
types</a> as follows:</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> <span class="dt">HasRB</span> a <span class="kw">where</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">RB</span><span class="ot"> a ::</span> <span class="dt">Type</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="ot">  newRB               ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">RB</span> a)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  tryClaimBatchRB     ::</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Maybe</span> <span class="dt">SequenceNumber</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="ot">  writeRingBufferRB   ::</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="ot">  publishRB           ::</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="ot">  addGatingSequenceRB ::</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">Counter</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="ot">  waitForRB           ::</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">SequenceNumber</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="ot">  readRingBufferRB    ::</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> a</span></code></pre></div>
<p>The instances for this class for types that are not pairs will just
use the Disruptor that we defined above.</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">instance</span> <span class="dt">HasRB</span> <span class="dt">String</span> <span class="kw">where</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">RB</span> <span class="dt">String</span> <span class="ot">=</span> <span class="dt">RB</span> (<span class="dt">RingBuffer</span> <span class="dt">String</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  newRB n        <span class="ot">=</span> <span class="dt">RB</span> <span class="op">&lt;$&gt;</span> newRingBuffer_ n</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">...</span></span></code></pre></div>
<p>While the instance for pairs will use a pair of Disruptors:</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">instance</span> (<span class="dt">HasRB</span> a, <span class="dt">HasRB</span> b) <span class="ot">=&gt;</span> <span class="dt">HasRB</span> (a, b) <span class="kw">where</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">RB</span> (a, b) <span class="ot">=</span> <span class="dt">RBPair</span> (<span class="dt">RB</span> a) (<span class="dt">RB</span> b)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  newRB n <span class="ot">=</span> <span class="dt">RBPair</span> <span class="op">&lt;$&gt;</span> newRB n <span class="op">&lt;*&gt;</span> newRB n</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">...</span></span></code></pre></div>
<p>The <code>deploy</code> function for the fan-out combinator can now
avoid copying:</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="ot">deploy ::</span> (<span class="dt">HasRB</span> a, <span class="dt">HasRB</span> b) <span class="ot">=&gt;</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">RB</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">RB</span> b)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>deploy (p <span class="op">:&amp;&amp;&amp;</span> q) xs <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  ys <span class="ot">&lt;-</span> deploy p xs</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  zs <span class="ot">&lt;-</span> deploy q xs</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (<span class="dt">RBPair</span> ys zs)</span></code></pre></div>
<p>Sharding, or partition parallelism as Jim calls it, is a way to make
a copy of a pipeline and divert half of the events to the first copy and
the other half to the other copy. Assuming there are enough unused
CPUs/core, this could effectively double the throughput. It might be
helpful to think of the events at even positions in the stream going to
the first pipeline copy while the events in the odd positions in the
stream go to the second copy of the pipeline.</p>
<p>When we shard in the <code>TQueue</code> deployment of pipelines we
end up copying events from the original stream into the two pipeline
copies. This is similar to copying when fanning out, which we discussed
above, and the solution is similar.</p>
<p>First we need to change the pipeline type so that the shard
constructor has an output type that’s <code>Sharded</code>.</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>data P :: Type -&gt; Type -&gt; Type where</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="st">- Shard :: P a b -&gt; P a b</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="va">+ Shard :: P a b -&gt; P a (Sharded b)</span></span></code></pre></div>
<p>This type is in fact merely the identity type:</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">newtype</span> <span class="dt">Sharded</span> a <span class="ot">=</span> <span class="dt">Sharded</span> a</span></code></pre></div>
<p>But it allows us to define a <code>HasRB</code> instance which does
the sharding without copying as follows:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">instance</span> <span class="dt">HasRB</span> a <span class="ot">=&gt;</span> <span class="dt">HasRB</span> (<span class="dt">Sharded</span> a) <span class="kw">where</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">RB</span> (<span class="dt">Sharded</span> a) <span class="ot">=</span> <span class="dt">RBShard</span> <span class="dt">Partition</span> <span class="dt">Partition</span> (<span class="dt">RB</span> a) (<span class="dt">RB</span> a)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  readRingBufferRB (<span class="dt">RBShard</span> p1 p2 xs ys) i</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> partition i p1 <span class="ot">=</span> readRingBufferRB xs i</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> partition i p2 <span class="ot">=</span> readRingBufferRB ys i</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">...</span></span></code></pre></div>
<p>The idea being that we split the ring buffer into two, like when
fanning out, and then we have a way of taking an index and figuring out
which of the two ring buffers it’s actually in.</p>
<p>This partitioning information, <code>p</code>, is threaded though
while deploying:</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>deploy (<span class="dt">Shard</span> f) p xs <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> (p1, p2) <span class="ot">=</span> addPartition p</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  ys1 <span class="ot">&lt;-</span> deploy f p1 xs</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  ys2 <span class="ot">&lt;-</span> deploy f p2 xs</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (<span class="dt">RBShard</span> p1 p2 ys1 ys2)</span></code></pre></div>
<p>For the details of how this works see the following footnote<a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> and the
<code>HasRB (Sharded a)</code> instance in the following <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/RingBufferClass.hs">module</a>.</p>
<p>If we <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/LibMain/Sleep.hs">run</a>
our sleep pipeline from before using the Disruptor <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/Pipeline.hs">deployment</a>
we get similar timings as with the queue deployment:</p>
<pre><code>&gt; runDisruptorSleep False
(2.01 secs, 383,489,976 bytes)

&gt; runDisruptorSleepSharded False
(1.37 secs, 286,207,264 bytes)</code></pre>
<p>In order to get a better understanding of how not copying when
fanning out and sharding improves performance, let’s instead have a look
at this pipeline which fans out five times:</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="ot">copyP ::</span> <span class="dt">P</span> () ()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>copyP <span class="ot">=</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Id</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">:&gt;&gt;&gt;</span> <span class="dt">Map</span> (<span class="fu">const</span> ())</span></code></pre></div>
<p>If we deploy this pipeline using queues and feed it five million
items we get the following statistics from the profiler:</p>
<pre><code>11,457,369,968 bytes allocated in the heap
   198,233,200 bytes copied during GC
     5,210,024 bytes maximum residency (27 sample(s))
     4,841,208 bytes maximum slop
           216 MiB total memory in use (0 MB lost due to fragmentation)


real    0m8.368s
user    0m10.647s
sys     0m0.778s</code></pre>
<p>While the same setup but using the Disruptor deployment gives us:</p>
<pre><code>6,629,305,096 bytes allocated in the heap
  110,544,544 bytes copied during GC
    3,510,424 bytes maximum residency (17 sample(s))
    5,090,472 bytes maximum slop
          214 MiB total memory in use (0 MB lost due to fragmentation)

real    0m5.028s
user    0m7.000s
sys     0m0.626s</code></pre>
<p>So about an half the amount of bytes allocated in the heap using the
Disruptor.</p>
<p>If we double the fan-out factor from five to ten, we get the
following stats with the queue deployment:</p>
<pre><code>35,552,340,768 bytes allocated in the heap
 7,355,365,488 bytes copied during GC
    31,518,256 bytes maximum residency (295 sample(s))
       739,472 bytes maximum slop
           257 MiB total memory in use (0 MB lost due to fragmentation)

real    0m46.104s
user    3m35.192s
sys     0m1.387s</code></pre>
<p>and the following for the Disruptor deployment:</p>
<pre><code>11,457,369,968 bytes allocated in the heap
   198,233,200 bytes copied during GC
     5,210,024 bytes maximum residency (27 sample(s))
     4,841,208 bytes maximum slop
           216 MiB total memory in use (0 MB lost due to fragmentation)

real    0m8.368s
user    0m10.647s
sys     0m0.778s</code></pre>
<p>So it seems that the gap between the two deployments widens as we
introduce more fan-out, this expected as the queue implementation will
have more copying of data to do<a href="#fn8" class="footnote-ref"
id="fnref8" role="doc-noteref"><sup>8</sup></a>.</p>
<h2 id="observability">Observability</h2>
<p>Given that pipelines are directed acyclic graphs and that we have a
concrete datatype constructor for each pipeline combinator, it’s
relatively straight forward to add a visualisation of a deployment.</p>
<p>Furthermore, since each Disruptor has a <code>cursor</code> keeping
that of how many elements it produced and all the consumers of a
Disruptor have one keeping track of how many elements they have
consumed, we can annotate our deployment visualisation with this data
and get a good idea of the progress the pipeline is making over time as
well as spot potential bottlenecks.</p>
<p>Here’s an example of such an visualisation, for a <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/LibMain/WordCount.hs">word
count</a> pipeline, as an interactive SVG (you need to click on the
image):</p>
<p><a
href="https://stevana.github.io/svg-viewer-in-svg/wordcount-pipeline.svg"><img
src="https://stevana.github.io/svg-viewer-in-svg/wordcount-pipeline.svg"
alt="Demo" /></a></p>
<p>The way it’s implemented is that we spawn a separate thread that read
the producer’s cursors and consumer’s gating sequences
(<code>IORef SequenceNumber</code> in both cases) every millisecond and
saves the <code>SequenceNumber</code>s (integers). After collecting this
data we can create one dot diagram for every time the data changed. In
the demo above, we also collected all the elements of the Disruptor,
this is useful for debugging (the implementation of the pipeline
library), but it would probably be too expensive to enable this when
there’s a lot of items to be processed.</p>
<p>I have written a separate write up on how to make the SVG interactive
over <a
href="https://stevana.github.io/visualising_datastructures_over_time_using_svg.html">here</a>.</p>
<h2 id="running">Running</h2>
<p>All of the above Haskell code is available on <a
href="https://github.com/stevana/pipelining-with-disruptor/">GitHub</a>.
The easiest way to install the right version of GHC and cabal is
probably via <a href="https://www.haskell.org/ghcup/">ghcup</a>. Once
installed the <a
href="https://github.com/stevana/pipelining-with-disruptor/tree/main/src/LibMain">examples</a>
can be run as follows:</p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> data/test.txt <span class="kw">|</span> <span class="ex">cabal</span> run uppercase</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> data/test.txt <span class="kw">|</span> <span class="ex">cabal</span> run wc <span class="co"># word count</span></span></code></pre></div>
<p>The <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/LibMain/Sleep.hs">sleep
examples</a> are run like this:</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cabal</span> run sleep</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="ex">cabal</span> run sleep <span class="at">--</span> <span class="at">--sharded</span></span></code></pre></div>
<p>The different <a
href="https://github.com/stevana/pipelining-with-disruptor/blob/main/src/LibMain/Copying.hs">copying
benchmarks</a> can be reproduced as follows:</p>
<div class="sourceCode" id="cb44"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> flag <span class="kw">in</span> <span class="st">&quot;--no-sharding&quot;</span> <span class="dt">\</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;--copy10&quot;</span> <span class="dt">\</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;--tbqueue-no-sharding&quot;</span> <span class="dt">\</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;--tbqueue-copy10&quot;</span><span class="kw">;</span> <span class="cf">do</span> <span class="dt">\</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>  <span class="ex">cabal</span> build copying <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">time</span> cabal run copying <span class="at">--</span> <span class="st">&quot;</span><span class="va">$flag</span><span class="st">&quot;</span> <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">eventlog2html</span> copying.eventlog <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">ghc-prof-flamegraph</span> copying.prof <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">firefox</span> copying.eventlog.html <span class="kw">&amp;&amp;</span> <span class="dt">\</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">firefox</span> copying.svg</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="cf">done</span></span></code></pre></div>
<h2 id="further-work-and-contributing">Further work and
contributing</h2>
<p>There’s still a lot to do, but I thought it would be a good place to
stop for now. Here are a bunch of improvements, in no particular
order:</p>
<ul class="task-list">
<li><input type="checkbox" />Implement the <code>Arrow</code> instance
for Disruptor <code>P</code>ipelines, this isn’t as straightforward as
in the model case, because the combinators are littered with
<code>HasRB</code> constraints, e.g.:
<code>(:&amp;&amp;&amp;) :: (HasRB b, HasRB c) =&gt; P a b -&gt;       P a c -&gt; P a (b, c)</code>.
Perhaps taking inspiration from constrained/restricted monads? This
would allow us to specify pipelines using the <a
href="https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/arrows.html">arrow
notation</a>.</li>
<li><input type="checkbox" />I believe the current pipeline combinator
allow for arbitrary directed acyclic graphs (DAGs), but what if feedback
cycles are needed? Does an <code>ArrowLoop</code> instance make sense in
that case?</li>
<li><input type="checkbox" />Can we avoid copying when using
<code>Either</code> via <code>(:|||)</code> or <code>(:+++)</code>, e.g.
can we store all <code>Left</code>s in one ring buffer and all
<code>Right</code>s in another?</li>
<li><input type="checkbox" />Use unboxed arrays for types that can be
unboxed in the <code>HasRB</code> instances?</li>
<li><input type="checkbox" />In the word count example we get an input
stream of lines, but we only want to produce a single line as output
when we reach the end of the input stream. In order to do this I added a
way for workers to say that <code>NoOutput</code> was produced in one
step. Currently that constructor still gets written to the output
Disruptor, would it be possible to not write it but still increment the
sequence number counter?</li>
<li><input type="checkbox" />Add more monitoring? Currently we only keep
track of the queue length, i.e. saturation. Adding service time,
i.e. how long it takes to process an item, per worker shouldn’t be hard.
Latency (how long an item has been waiting in the queue) would be more
tricky as we’d need to annotate and propagate a timestamp with the
item?</li>
<li><input type="checkbox" />Since monitoring adds a bit of overheard,
it would be neat to be able to turn monitoring on and off at
runtime;</li>
<li><input type="checkbox" />The <code>HasRB</code> instances are
incomplete, and it’s not clear if they need to be completed? More
testing and examples could help answer this question, or perhaps a
better visualisation?</li>
<li><input type="checkbox" />Actually test using
<code>prop_commute</code> partially applied to a concrete pipeline?</li>
<li><input type="checkbox" />Implement a property-based testing
generator for pipelines and test using <code>prop_commute</code> using
random pipelines?</li>
<li><input type="checkbox" />Add network/HTTP source and sink?</li>
<li><input type="checkbox" />Deploy across network of computers?</li>
<li><input type="checkbox" />Hot-code upgrades of workers/stages with
zero downtime, perhaps continuing on my earlier <a
href="https://stevana.github.io/hot-code_swapping_a_la_erlang_with_arrow-based_state_machines.html">attempt</a>?</li>
<li><input type="checkbox" />In addition to upgrading the
workers/stages, one might also want to rewire the pipeline itself. Doug
made me aware of an old <a
href="https://inria.hal.science/inria-00306565">paper</a> by Gilles Kahn
and David MacQueen (1976), where they reconfigure their network on the
fly. Perhaps some ideas can be stole from there?</li>
<li><input type="checkbox" />Related to reconfiguring is to be able
shard/scale/reroute pipelines and add more machines without downtime.
Can we do this automatically based on our monitoring? Perhaps building
upon my earlier <a
href="https://stevana.github.io/elastically_scalable_thread_pools.html">attempt</a>?</li>
<li><input type="checkbox" />More benchmarks, in particular trying to
confirm that we indeed don’t allocate when fanning out and sharding<a
href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a>, as well as benchmarks against other
streaming libraries.</li>
</ul>
<p>If any of this seems interesting, feel free to get involved.</p>
<h2 id="see-also">See also</h2>
<ul>
<li>Guy Steele’s talk <a
href="https://www.infoq.com/presentations/Thinking-Parallel-Programming/">How
to Think about Parallel Programming: Not!</a> (2011);</li>
<li><a href="https://youtube.com/watch?v=DCdGlxBbKU4">Understanding the
Disruptor, a Beginner’s Guide to Hardcore Concurrency</a> by Trisha Gee
and Mike Barker (2011);</li>
<li>Mike Barker’s <a
href="https://github.com/mikeb01/folklore/tree/master/src/main/java/performance">brute-force
solution to Guy’s problem and benchmarks</a>;</li>
<li><a
href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/">Streaming
101: The world beyond batch</a> (2015);</li>
<li><a
href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/">Streaming
102: The world beyond batch</a> (2016);</li>
<li><a
href="https://people.eecs.berkeley.edu/~brewer/papers/SEDA-sosp.pdf"><em>SEDA:
An Architecture for Well-Conditioned Scalable Internet Services</em></a>
(2001);</li>
<li><a
href="https://www.microsoft.com/en-us/research/publication/naiad-a-timely-dataflow-system-2/">Microsoft
Naiad</a>: a timely dataflow system (with stage notifications)
(2013);</li>
<li>Elixir’s ALF flow-based programming <a
href="https://www.youtube.com/watch?v=2XrYd1W5GLo">library</a>
(2021);</li>
<li><a href="https://mazzo.li/posts/fast-pipes.html">How fast are Linux
pipes anyway?</a> (2022);</li>
<li><a
href="https://man.freebsd.org/cgi/man.cgi?query=netmap&amp;sektion=4">netmap</a>:
a framework for fast packet I/O;</li>
<li><a
href="https://www.gibney.org/the_output_of_linux_pipes_can_be_indeter">The
output of Linux pipes can be indeterministic</a> (2019);</li>
<li><a href="https://www.youtube.com/watch?v=Mc3tTRkjCvE">Programming
Distributed Systems</a> by Mae Milano (Strange Loop, 2023);</li>
<li><a
href="https://www.youtube.com/watch?v=ipceTuJlw-M">Pipeline-oriented
programming</a> by Scott Wlaschin (NDC Porto, 2023).</li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>I noticed that the Wikipedia page for <a
href="https://en.wikipedia.org/wiki/Dataflow_programming">dataflow
programming</a> mentions that Jack Dennis and his graduate students
pioneered that style of programming while he was at MIT in the 60s. I
knew Doug was at MIT around that time as well, and so I sent an email to
Doug asking if he knew of Jack’s work. Doug replied saying he had left
MIT by the 60s, but was still collaborating with people at MIT and was
aware of Jack’s work and also the work by Kelly, Lochbaum and Vyssotsky
on <a href="https://archive.org/details/bstj40-3-669">BLODI</a> (1961)
was on his mind when he wrote the garden hose memo (1964).<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>There’s a paper called <a
href="http://flint.cs.yale.edu/trifonov/papers/pfrp.pdf">Parallel
Functional Reactive Programming</a> by Peterson et al. (2000), but as
Conal Elliott <a
href="http://conal.net/papers/push-pull-frp/push-pull-frp.pdf">points</a>
out:</p>
<blockquote>
<p>“Peterson et al. (2000) explored opportunities for parallelism in
implementing a variation of FRP. While the underlying semantic model was
not spelled out, it seems that semantic determinacy was not preserved,
in contrast to the semantically determinate concurrency used in this
paper (Section 11).”</p>
</blockquote>
<p>Conal’s approach (his Section 11) seems to build upon very fine
grained parallelism provided by an “unambiguous choice” operator which
is implemented by spawning two threads. I don’t understand where exactly
this operator is used in the implementation, but if it’s used every time
an element is processed (in parallel) then the overheard of spawning the
threads could be significant?<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The design space of what pipeline combinators to include
in the pipeline datatype is very big. I’ve chosen the ones I’ve done
because they are instances of already well established type classes:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">instance</span> <span class="dt">Category</span> <span class="dt">P</span> <span class="kw">where</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">id</span>    <span class="ot">=</span> <span class="dt">Id</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  g <span class="op">.</span> f <span class="ot">=</span> f <span class="op">:&gt;&gt;&gt;</span> g</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">instance</span> <span class="dt">Arrow</span> <span class="dt">P</span> <span class="kw">where</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  arr     <span class="ot">=</span> <span class="dt">Map</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  f <span class="op">***</span> g <span class="ot">=</span> f <span class="op">:***</span> g</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  f <span class="op">&amp;&amp;&amp;</span> g <span class="ot">=</span> f <span class="op">:&amp;&amp;&amp;</span> g</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="kw">instance</span> <span class="dt">ArrowChoice</span> <span class="dt">P</span> <span class="kw">where</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  f <span class="op">+++</span> g <span class="ot">=</span> f <span class="op">:+++</span> g</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  f <span class="op">|||</span> g <span class="ot">=</span> f <span class="op">:|||</span> g</span></code></pre></div>
<p>Ideally we’d also like to be able to use <code>Arrow</code>
notation/syntax to describe our pipelines. Even better would be if arrow
notation worked for Cartesian categories. See Conal Elliott’s work on <a
href="http://conal.net/papers/compiling-to-categories/">compiling to
categories</a>, as well as Oleg Grenrus’ GHC <a
href="https://github.com/phadej/overloaded/blob/master/src/Overloaded/Categories.hs">plugin</a>
that does the right thing and translates arrow syntax into Cartesian
categories.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Search for “QuickCheck GADTs” if you are interested in
finding out more about this topic.<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The Disruptor also comes in a multi-producer variant,
see the following <a
href="https://github.com/stevana/pipelined-state-machines/tree/main/src/Disruptor/MP">repository</a>
for a Haskell version or the <a
href="https://github.com/LMAX-Exchange/disruptor">LMAX</a> repository
for the original Java implementation.<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>See also <a
href="https://en.wikipedia.org/wiki/AoS_and_SoA">array of structures vs
structure of arrays</a> in other programming languages.<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>The partitioning information consists of the total
number of partitions and the index of the current partition.</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">Partition</span> <span class="ot">=</span> <span class="dt">Partition</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  {<span class="ot"> pIndex ::</span> <span class="dt">Int</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> pTotal ::</span> <span class="dt">Int</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  }</span></code></pre></div>
<p>No partitioning is represented as follows:</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ot">noPartition ::</span> <span class="dt">Partition</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>noPartition <span class="ot">=</span> <span class="dt">Partition</span> <span class="dv">0</span> <span class="dv">1</span></span></code></pre></div>
<p>While creating a new partition is done as follows:</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="ot">addPartition ::</span> <span class="dt">Partition</span> <span class="ot">-&gt;</span> (<span class="dt">Partition</span>, <span class="dt">Partition</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>addPartition (<span class="dt">Partition</span> i total) <span class="ot">=</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  ( <span class="dt">Partition</span> i (total <span class="op">*</span> <span class="dv">2</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  , <span class="dt">Partition</span> (i <span class="op">+</span> total) (total <span class="op">*</span> <span class="dv">2</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>So, for example, if we partition twice we get:</p>
<pre><code>&gt; let (p1, p2) = addPartition noPartition in (addPartition p1, addPartition p2)
((Partition 0 4, Partition 2 4), (Partition 1 4, Partition 3 4))</code></pre>
<p>From this information we can compute if an index is in an partition
or not as follows:</p>
<div class="sourceCode" id="cb35"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="ot">partition ::</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">Partition</span> <span class="ot">-&gt;</span> <span class="dt">Bool</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>partition i (<span class="dt">Partition</span> n total) <span class="ot">=</span> i <span class="ot">`mod`</span> total <span class="op">==</span> <span class="dv">0</span> <span class="op">+</span> n</span></code></pre></div>
<p>To understand why this works, it might be helpful to consider the
case where we only have two partitions. We can partition on even or odd
indices as follows: <code>even i = i `mod` 2 == 0 + 0</code> and
<code>odd i = i `mod` 2 == 0 + 1</code>. Written this way we can easier
see how to generalise to <code>total</code> partitions:
<code>partition i (Partition n total) = i `mod` total == 0 + n</code>.
So for <code>total = 2</code> then
<code>partition i (Partition 0 2) == even</code> while
<code>partition i (Partition 1 2) == odd</code>.</p>
<p>Since partitioning and partitioning a partition, etc, always
introduce a power of two we can further optimise to use bitwise or as
follows:
<code>partition i (Partition n total) = i .|. (total - 1) == 0 + n</code>
thereby avoiding the expensive modulus computation. This is a trick used
in Disruptor as well, and the reason why the capacity of a Disruptor
always needs to be a power of two.<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>I’m not sure why “bytes allocated in the heap” gets
doubled in the Disruptor case and tripled in the queue cases though?<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>I’m not sure why “bytes allocated in the heap” gets
doubled in the Disruptor case and tripled in the queue cases though?<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></description>
      <category>Development</category>
    </item>

    <item>
      <title>Visualising datastructures over time using SVG</title>
      <link>https://stevana.github.io/visualising_datastructures_over_time_using_svg.html</link>
      <guid>https://stevana.github.io/visualising_datastructures_over_time_using_svg.html</guid>
      <pubDate>Sat, 9 Sep 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>SVG viewer written in SVG</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#demo" id="toc-demo">Demo</a></li>
<li><a href="#the-code" id="toc-the-code">The code</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
</ul>
</nav>
<div class="date">Posted on Sep  9, 2023</div>
<p>This post is about how to write an <a
href="https://en.wikipedia.org/wiki/SVG">SVG</a> viewer / browser /
“slideshow” which is itself a self-contained SVG.</p>
<h2 id="motivation">Motivation</h2>
<p>I’ve been working on a parallel processing pipeline. Each stage of
the pipeline is running on a separate thread, and it takes some work
items from a queue in front of it, processes them and then puts them in
the queue in front of the next stage in the pipeline.</p>
<p>In order to better understand what exactly is going on I thought I’d
visualise the pipeline including the length and contents of all queues
as well as the position each worker/stage is at in the queue it’s
processing.</p>
<p>For now lets just imagine that an SVG image is created every time
interval. So after a run of the pipeline we’ll have a bunch of SVGs
showing us how it evolved over time.</p>
<p>Initially I was using the <a
href="https://feh.finalrewind.org/"><code>feh</code></a> image viewer,
which if you pass it several images lets you navigate through them using
the arrow keys.</p>
<p>But then I wondered: how can I show these SVGs to somebody else over
the web?</p>
<h2 id="demo">Demo</h2>
<p>Before I show you how I did it, let’s have a look at the resulting
pipeline visualisation (you need to click on the image):</p>
<p><a
href="https://stevana.github.io/svg-viewer-in-svg/wordcount-pipeline.svg"><img
src="https://stevana.github.io/svg-viewer-in-svg/wordcount-pipeline.svg"
alt="Demo" /></a></p>
<p>The arrows in the top left corner are clickable and will take you to
the first, next, previous and last SVG respectively.</p>
<p>What you are seeing is a run of a parallel word count pipeline, where
lines are coming in from stdin and the counts are being written to
stdout at the end.</p>
<h2 id="the-code">The code</h2>
<p>Let’s start by having a look at the SVG itself.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode xml"><code class="sourceCode xml"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>&lt;<span class="kw">svg</span><span class="ot"> version=</span><span class="st">&quot;1.1&quot;</span><span class="ot"> xmlns=</span><span class="st">&quot;http://www.w3.org/2000/svg&quot;</span>&gt;</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  // The navigation menu for going to the first, previous, next and last</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  // slide/image. There&#39;s also a progress bar here which shows which slide</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  // we are currently on and how many there are in total.</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  &lt;<span class="kw">g</span><span class="ot"> font-family=</span><span class="st">&quot;Times,serif&quot;</span><span class="ot"> font-size=</span><span class="st">&quot;14.00&quot;</span>&gt;</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    &lt;<span class="kw">text</span><span class="ot"> id=</span><span class="st">&quot;first&quot;</span><span class="ot">    x=</span><span class="st">&quot;20&quot;</span><span class="ot">  y=</span><span class="st">&quot;30&quot;</span>&gt;⇤&lt;/<span class="kw">text</span>&gt;</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    &lt;<span class="kw">text</span><span class="ot"> id=</span><span class="st">&quot;previous&quot;</span><span class="ot"> x=</span><span class="st">&quot;50&quot;</span><span class="ot">  y=</span><span class="st">&quot;30&quot;</span>&gt;←&lt;/<span class="kw">text</span>&gt;</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    &lt;<span class="kw">text</span><span class="ot"> id=</span><span class="st">&quot;progress&quot;</span><span class="ot"> x=</span><span class="st">&quot;80&quot;</span><span class="ot">  y=</span><span class="st">&quot;30&quot;</span>&gt;&lt;/<span class="kw">text</span>&gt;</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    &lt;<span class="kw">text</span><span class="ot"> id=</span><span class="st">&quot;next&quot;</span><span class="ot">     x=</span><span class="st">&quot;120&quot;</span><span class="ot"> y=</span><span class="st">&quot;30&quot;</span>&gt;→&lt;/<span class="kw">text</span>&gt;</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    &lt;<span class="kw">text</span><span class="ot"> id=</span><span class="st">&quot;last&quot;</span><span class="ot">     x=</span><span class="st">&quot;150&quot;</span><span class="ot"> y=</span><span class="st">&quot;30&quot;</span>&gt;⇥&lt;/<span class="kw">text</span>&gt;</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  &lt;/<span class="kw">g</span>&gt;</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  // Placeholder for the image.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  &lt;<span class="kw">g</span><span class="ot"> id=</span><span class="st">&quot;image&quot;</span>&gt;&lt;/<span class="kw">g</span>&gt;</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  // The index of the currently viewed image.</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  &lt;<span class="kw">desc</span><span class="ot"> id=</span><span class="st">&quot;0&quot;</span>&gt;&lt;/<span class="kw">desc</span>&gt;</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  // The fact that we can embedd JavaScript into SVGs is what makes this</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  // whole thing work.</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  &lt;<span class="kw">script</span>&gt;</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  // <span class="bn">&lt;![CDATA[</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    // Let me move this out to its own code block, so we get syntax</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    // highlighting.</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  // <span class="bn">]]&gt;</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  &lt;/<span class="kw">script</span>&gt;</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>&lt;/<span class="kw">svg</span>&gt;</span></code></pre></div>
<p>The following goes into the script tag above:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Array holding the SVG images.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> imgs <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;&lt;svg&gt;...&lt;/svg&gt;&quot;</span><span class="op">,</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;&lt;svg&gt;...&lt;/svg&gt;&quot;</span><span class="op">,</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;&lt;svg&gt;...&lt;/svg&gt;&quot;</span><span class="op">,</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      )<span class="op">;</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Helper for registering onclick handlers.</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">registerClick</span>(selector<span class="op">,</span> f) {</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">document</span><span class="op">.</span><span class="fu">querySelector</span>(selector)<span class="op">.</span><span class="fu">addEventListener</span>(<span class="st">&quot;click&quot;</span><span class="op">,</span> (e) <span class="kw">=&gt;</span> {</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            <span class="fu">f</span>(e)<span class="op">;</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        })<span class="op">;</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Set and return the value of our counter, this is abusing the id</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">// of the desc tag...</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">setCounter</span>(f) {</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="kw">const</span> counter <span class="op">=</span> <span class="bu">document</span><span class="op">.</span><span class="fu">querySelector</span>(<span class="st">&quot;desc&quot;</span>)<span class="op">;</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        counter<span class="op">.</span><span class="at">id</span> <span class="op">=</span> <span class="fu">f</span>(<span class="pp">parseInt</span>(counter<span class="op">.</span><span class="at">id</span>))<span class="op">;</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> counter<span class="op">.</span><span class="at">id</span><span class="op">;</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Updates our image placeholder by injecting the SVG into the</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">// image tag. Also updates the progress bar.</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">setImage</span>(i) {</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="kw">const</span> img <span class="op">=</span> <span class="bu">document</span><span class="op">.</span><span class="fu">querySelector</span>(<span class="st">&quot;#image&quot;</span>)<span class="op">;</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        img<span class="op">.</span><span class="fu">setAttribute</span>(<span class="st">&quot;href&quot;</span><span class="op">,</span> imgs[i])<span class="op">;</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>        <span class="fu">updateProgress</span>()<span class="op">;</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Update the progress bar in the menu.</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">updateProgress</span>() {</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        <span class="bu">document</span><span class="op">.</span><span class="fu">querySelector</span>(<span class="st">&quot;#progress&quot;</span>)<span class="op">.</span><span class="at">innerHTML</span> <span class="op">=</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">document</span><span class="op">.</span><span class="fu">querySelector</span>(<span class="st">&quot;desc&quot;</span>)<span class="op">.</span><span class="at">id</span> <span class="op">+</span> <span class="st">&quot;/&quot;</span> <span class="op">+</span> (imgs<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">// We can now define our navigation functions in terms of setting</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">// the counter and the image.</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">first</span>() {</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>        <span class="fu">setImage</span>(<span class="fu">setCounter</span>((_) <span class="kw">=&gt;</span> <span class="dv">0</span>))<span class="op">;</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">previous</span>() {</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        <span class="fu">setImage</span>(<span class="fu">setCounter</span>((i) <span class="kw">=&gt;</span> i <span class="op">&lt;=</span> <span class="dv">0</span> <span class="op">?</span> <span class="dv">0</span> <span class="op">:</span> <span class="op">--</span>i))<span class="op">;</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">next</span>() {</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        <span class="fu">setImage</span>(<span class="fu">setCounter</span>((i) <span class="kw">=&gt;</span> i <span class="op">&gt;=</span> imgs<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span> <span class="op">?</span> imgs<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span> <span class="op">:</span> <span class="op">++</span>i))<span class="op">;</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">last</span>() {</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="fu">setImage</span>(<span class="fu">setCounter</span>((_) <span class="kw">=&gt;</span> imgs<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span>))<span class="op">;</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Finally, to kick things off: register onclick handlers for the</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    <span class="co">// navigation buttons and set the image to the first image in the array.</span></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    <span class="fu">registerClick</span>(<span class="st">&quot;#first&quot;</span><span class="op">,</span>    (_) <span class="kw">=&gt;</span> <span class="fu">first</span>())<span class="op">;</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>    <span class="fu">registerClick</span>(<span class="st">&quot;#next&quot;</span><span class="op">,</span>     (_) <span class="kw">=&gt;</span> <span class="fu">next</span>())<span class="op">;</span></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>    <span class="fu">registerClick</span>(<span class="st">&quot;#previous&quot;</span><span class="op">,</span> (_) <span class="kw">=&gt;</span> <span class="fu">previous</span>())<span class="op">;</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    <span class="fu">registerClick</span>(<span class="st">&quot;#last&quot;</span><span class="op">,</span>     (_) <span class="kw">=&gt;</span> <span class="fu">last</span>())<span class="op">;</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>    <span class="fu">setImage</span>(<span class="dv">0</span>)<span class="op">;</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>    <span class="co">// We could even add keyboard support...</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">window</span><span class="op">.</span><span class="fu">addEventListener</span>(<span class="st">&quot;keydown&quot;</span><span class="op">,</span> (e) <span class="kw">=&gt;</span> {</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Left arrow or k.</span></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (e<span class="op">.</span><span class="at">keyCode</span> <span class="op">===</span> <span class="dv">37</span> <span class="op">||</span> e<span class="op">.</span><span class="at">keyCode</span> <span class="op">===</span> <span class="dv">75</span>) {</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>            <span class="fu">previous</span>()<span class="op">;</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Right arrow or j.</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span> <span class="cf">if</span> (e<span class="op">.</span><span class="at">keyCode</span> <span class="op">===</span> <span class="dv">39</span> <span class="op">||</span> e<span class="op">.</span><span class="at">keyCode</span> <span class="op">===</span> <span class="dv">74</span>) {</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>            <span class="fu">next</span>()<span class="op">;</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>    })<span class="op">;</span></span></code></pre></div>
<p>Another thing worth mentioning is that in my application the thread
that collects the metrics runs about 1000 times per second. If there’s
no change in the metrics then we probably don’t want to display an image
that’s the same as the previous one. So I keep a CRC32 checksum of the
metrics that the last image is generated from and if the next metrics
data has the same checksum, I skip generating that image (as it will be
the same as the previous one).</p>
<p>The (inner) SVGs themselves are generated with graphviz via the <a
href="https://graphviz.org/doc/info/lang.html">dot</a> language, the <a
href="https://graphviz.org/doc/info/shapes.html#record">record-based</a>
node shapes turned out to be useful for visualing data structures.</p>
<p>It’s quite annoying to populate the <code>imgs</code> array by hand,
so I wrote a small bash <a href="src/svg-viewer-in-svg">script</a> which
takes a bunch of SVGs and outputs a single SVG which can be used to view
the original images.</p>
<h2 id="usage">Usage</h2>
<p>The easiest way to get started is probably to clone the
repository.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/stevana/svg-viewer-in-svg</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> svg-viewer-in-svg</span></code></pre></div>
<p>In the <code>img/</code> directory there are three simple SVGs:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span> img/</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ex">circle.svg</span>  ellipse.svg  rectangle.svg</span></code></pre></div>
<p>We can combine them all into one a single SVG that is a “slideshow”
of the shapes as follows:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">./src/svg-viewer-in-svg</span> img/<span class="pp">*</span>.svg <span class="op">&gt;</span> /tmp/combined-shapes.svg</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">firefox</span> /tmp/combined-shapes.svg</span></code></pre></div>
<p>If you want to “install” the script, simply copy it to any directory
that is in your <code>$PATH</code>.</p>
<p>One last thing worth noting is that hosting these combined SVGs on
GitHub is a bit of a pain. Merely checking them into a repository and
trying to include them in markdown won’t work, because GitHub appears to
be doing some SVG script tag sanitising for security reasons. Uploading
them to gh-pages and linking to those seems to work though<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>.</p>
<h2 id="contributing">Contributing</h2>
<p>I hope I’ve managed to inspire you to think about how to visualise
the execution of your own programs! Feel free to copy and adapt the code
as you see fit. If you come up with some interesting modifications or
better ways of doing things, then please do share!</p>
<h2 id="see-also">See also</h2>
<p>Brendan Gregg’s <a
href="https://www.brendangregg.com/flamegraphs.html">flamegraphs</a>
also generates a clickable SVG. I got the idea of adding keyboard
support from looking at his SVG, there’s probably more interesting stuff
to steal there.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The following <a
href="https://gist.github.com/ramnathv/2227408">gist</a> shows how to
create gh-pages branch that doesn’t have any history. Also see the
GitHub pages documentation for how to enable gh-pages for a
respository.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></description>
      <category>Observability</category>
    </item>

    <item>
      <title>Elastically scalable thread pools</title>
      <link>https://stevana.github.io/elastically_scalable_thread_pools.html</link>
      <guid>https://stevana.github.io/elastically_scalable_thread_pools.html</guid>
      <pubDate>Tue, 14 Mar 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>Elastically scalable thread pools</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#plan" id="toc-plan">Plan</a></li>
<li><a href="#pseudo-code" id="toc-pseudo-code">Pseudo-code</a>
<ul>
<li><a href="#main" id="toc-main">Main</a></li>
<li><a href="#worker-pool" id="toc-worker-pool">Worker pool</a></li>
<li><a href="#load-generator" id="toc-load-generator">Load
generator</a></li>
<li><a href="#pid-controller" id="toc-pid-controller">PID
controller</a></li>
</ul></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
<li><a href="#discussion" id="toc-discussion">Discussion</a></li>
</ul>
</nav>
<div class="date">Posted on Mar 14, 2023</div>
<p>An experiment in controlling the size of a thread pool using a PID
controller.</p>
<h2 id="motivation">Motivation</h2>
<p>A tried and tested way to achieve parallelism is to use pipelining.
It’s used extensively in manufacturing and in computer hardware.</p>
<p>For example, Airbus <a
href="https://youtu.be/oxjT7veKi9c?t=2682">apparently</a> outputs two
airplanes per day on average, even though it takes two months to build a
single airplane from start to finish. It’s also used inside CPUs to <a
href="https://en.wikipedia.org/wiki/Instruction_pipelining">pipeline
instructions</a>.</p>
<p>Let’s imagine we want to take advantage of pipelining in some
software system. To make things more concrete, let’s say we have a
system where some kind of requests come on over the network and we want
to process them in some way. The first stage of the pipeline is to parse
the incoming requests from raw bytestrings into some more structured
data, the second stage is to apply some validation logic to the parsed
data and the third stage is to process the valid data and produce some
outputs that are then sent back to the client or stored somewhere.</p>
<p><img
src="https://raw.githubusercontent.com/stevana/elastically-scalable-thread-pools/main/img/pipeline.svg" /></p>
<p>The service time of an item can differ from stage to stage, for
example parsing might be slower than validation, which can create
bottlenecks. Luckily it’s quite easy to spot bottlenecks by merely
observing the queue lengths and once a slow stage is found we can often
fix it by merely adding an additional parallel processor to that stage.
For example we could spin up two or more threads that take bytestrings
from the first queue and turn them into structured data and thereby
compensate for parsing being slow.</p>
<p>By spinning up more threads we can decrease latency (waiting time in
the queue) and increase throughput (process more items), but we are also
on the other hand using more energy and potentially hogging CPU
resources that might be better used elsewhere in the pipeline or system
at large.</p>
<p>So here’s the question that the rest of this post is concerned about:
can we dynamically spin up and spin down threads at a stage in response
to the input queue length for that stage?</p>
<h2 id="plan">Plan</h2>
<p>Let’s focus on a single stage of the pipeline to make things easier
for ourselves.</p>
<p><img
src="https://raw.githubusercontent.com/stevana/elastically-scalable-thread-pools/main/img/stage.svg" /></p>
<p>We’d like to increase the parallelism of the processors if the input
queue grows, and decrease it when the queue shrinks. One simple strategy
might be to establish thresholds, i.e. if there’s over <span
class="math inline">100</span> items in the input queue then allocate
more processors and if there’s no items in the queue then deallocate
them.</p>
<p>Since allocating and deallocating processors can be an expense in
itself, we’d like to avoid changing them processor count
unnecessarily.</p>
<p>The threshold based approach is sensitive to unnecessarily changing
the count if the arrival rate of work fluctuates. The reason for this is
because it only takes the <em>present</em> queue length into
account.</p>
<p>We can do better by also incorporating the <em>past</em> and trying
to predict the <em>future</em>, this is the basic idea of <a
href="https://en.wikipedia.org/wiki/PID_controller">PID controllers</a>
from <a href="https://en.wikipedia.org/wiki/Control_theory">control
theory</a>.</p>
<p>Here’s what the picture looks like with a PID controller in the
loop:</p>
<pre><code>                                            +----------------------------------+
                                            |                                  |
    -------------------------------------------&gt;[Input queue]--&gt;[Worker pool]-----&gt;[Output queue]--&gt;
                                            |                                  |
     r(t)   e(t)                    u(t)    |                                  |
    -----&gt;+------&gt;[PID controller]--------&gt; |                                  |
          ^                                 |                                  |
          |                                 +----------------------------------+
          |                                                 | y(t)
          +-------------------------------------------------+
</code></pre>
<p>The PID controller monitors the queue length <span
class="math inline"><em>y</em>(<em>t</em>)</span>, compares it to some
desired queue length <span
class="math inline"><em>r</em>(<em>t</em>)</span> (also known as the
setpoint) and calculates the error <span
class="math inline"><em>e</em>(<em>t</em>)</span>. The error determines
the control variable <span
class="math inline"><em>u</em>(<em>t</em>)</span> which is used to grow
or shrink the processor pool.</p>
<h2 id="pseudo-code">Pseudo-code</h2>
<p>Let’s start top-down with the <code>main</code> function which drives
our whole experiment.</p>
<h3 id="main">Main</h3>
<pre><code>main =

  // Create the in- and out-queues.
  inQueue  := newQueue()
  outQueue := newQueue()


  // The workers don&#39;t do anything interesting, they merely sleep for a bit to
  // pretend to be doing some work.
  worker := sleep 0.025s

  // Create an empty worker pool.
  pool := newPool(worker, inQueue, outQueue)

  // Start the PID controller in a background thread. The parameters provided
  // here allow us to tune the PID controller, we&#39;ll come back to them later.
  kp := 1
  ki := 0.05
  kd := 0.05
  dt := 0.01s
  fork(pidController(kp, ki, kd, dt, pool))


  // Create a workload for our workers. We use the sine function to create
  // between 0 and 40 work items every 0.1s for 60s. The idea being that because
  // the workload varies over time the PID controller will have some work to do
  // figuring out how many workers are needed.
  sineLoadGenerator(inQueue, 40, 0.1s, 60s)</code></pre>
<h3 id="worker-pool">Worker pool</h3>
<p>The worker pool itself is merely a struct which packs up the
necessary data we need to be able to scale it up and down.</p>
<pre><code>struct Pool =
  { inQueue:  Queue&lt;Input&gt;
  , outQueue: Queue&lt;Output&gt;
  , worker:   Function&lt;Input, Output&gt;
  , pids:     List&lt;ProcessId&gt;
  }</code></pre>
<p>Creating a <code>newPool</code> creates the struct with an empty list
of process ids.</p>
<pre><code>newPool worker inQueue outQueue = Pool { ..., pids: emptyList }</code></pre>
<p>Scaling up and down are functions that take and return a
<code>Pool</code>.</p>
<pre><code>scaleUp pool =
  work := forever
            x := readQueue(pool.inQueue)
            y := pool.worker(x)
            writeQueue(pool.outQueue, y)
  pid   := fork(work)
  pool&#39; := pool.pids = append(pid, pool.pids)
  return pool&#39;</code></pre>
<p>The function <code>scaleDown</code> does the inverse, i.e. kills and
removes the last process id from <code>pool.pids</code>.</p>
<h3 id="load-generator">Load generator</h3>
<p>In order to create work load that varies over time we use the sine
function. The sine function oscillates between <span
class="math inline"> − 1</span> and <span
class="math inline">1</span>:</p>
<p><img
src="https://raw.githubusercontent.com/stevana/elastically-scalable-thread-pools/main/img/sine.svg" /></p>
<p>We would like to have it oscillate between <span
class="math inline">0</span> and some max value <span
class="math inline"><em>m</em></span>. By multiplying the output of the
sine function by <span class="math inline"><em>m</em>/2</span> we get an
oscillation between <span class="math inline"> − <em>m</em>/2</span> and
<span class="math inline"><em>m</em>/2</span>, we can then add <span
class="math inline"><em>m</em>/2</span> to make it oscillate between
<span class="math inline">0</span> and <span
class="math inline"><em>m</em></span>.</p>
<p>We’ll sample the resulting function once every <code>timesStep</code>
seconds, this gives us the amount of work items (<code>n</code>) to
create we then spread those out evenly in time, rinse and repeat until
we reach some <code>endTime</code>.</p>
<pre><code>sineLoadGenerator inQueue workItem maxItems timeStep endTime =
  for t := 0; t &lt; endtime; t += timeStep
    n := sin(t) * maxItems / 2 + maxItems / 2
    for i := 0; i &lt; n; i++
      writeQueue(inQueue, workItem)
      sleep(timeStep / n)</code></pre>
<h3 id="pid-controller">PID controller</h3>
<p>The PID controller implementation follows the pseudo-code given at <a
href="https://en.wikipedia.org/wiki/PID_controller#Pseudocode">Wikipedia</a>:</p>
<pre><code>previous_error := 0
integral := 0
loop:
   error := setpoint − measured_value
   proportional := error;
   integral := integral + error × dt
   derivative := (error − previous_error) / dt
   output := Kp × proportional + Ki × integral + Kd × derivative
   previous_error := error
   wait(dt)
   goto loop</code></pre>
<p>Where <code>Kp</code>, <code>Ki</code> and <code>Kd</code> is
respectively the proportional, integral and derivative gain and
<code>dt</code> is the loop interval time. The proportional part acts on
the <em>present</em> error value, the integral acts on the <em>past</em>
and the derivative tries to predict the <em>future</em>. The measured
value is the input queue length and the setpoint, i.e. desired queue
length, is set to zero. If the <code>output</code> of the PID controller
is less than <span class="math inline"> − 100</span> (i.e. the queue
length is over <span class="math inline">100</span> taking the present,
past and possible future into account) then we scale up and if it’s more
than <span class="math inline"> − 20</span> (i.e. the queue length is
less than <span class="math inline">20</span>) then we scale down the
worker pool.</p>
<h2 id="how-it-works">How it works</h2>
<p>We start off by only setting the proportional part and keeping the
integral and derivative part zero, this is called a P-controller. We see
below that it will scale the worker count up and down proportionally to
the sine wave shaped load:</p>
<p><img
src="https://raw.githubusercontent.com/stevana/elastically-scalable-thread-pools/main/img/elastically-scalable-thread-pools-1.0-0.0-0.0.svg" /></p>
<p>A P-controller only focuses on the <em>present</em>, and we see that
it allocates and deallocates workers unnecessarily. In order to smooth
things out we introduce the integral part, i.e. a PI-controller. The
integral part takes the <em>past</em> into account. We see now that the
worker count stabilises at <span class="math inline">28</span>:</p>
<p><img
src="https://raw.githubusercontent.com/stevana/elastically-scalable-thread-pools/main/img/elastically-scalable-thread-pools-1.0-5.0e-2-0.0.svg" /></p>
<p>We can improve on this by adding the derivative part which takes the
<em>future</em> into account. We then see that it stabilises at <span
class="math inline">26</span> workers:</p>
<p><img
src="https://raw.githubusercontent.com/stevana/elastically-scalable-thread-pools/main/img/elastically-scalable-thread-pools-1.0-5.0e-2-5.0e-2.svg" /></p>
<p>With the full PID controller, which stabilises using less workers
than the PI-controller, we see that the queue length spikes up to <span
class="math inline">20</span> or so each time the work load generator
hits one of the sine function’s peaks. Recall that we started scaling
down once the queue length was less than <span
class="math inline">20</span>.</p>
<h2 id="usage">Usage</h2>
<p>The above graphs were generated by running:
<code>cabal run app -- kp ki kd</code>, where the <span
class="math inline"><em>K</em><sub><em>p</em></sub></span>, <span
class="math inline"><em>K</em><sub><em>i</em></sub></span>, and <span
class="math inline"><em>K</em><sub><em>d</em></sub></span> parameters
are the tuning parameters for the PID controller.</p>
<p>If you don’t have the GHC Haskell compiler and the <code>cabal</code>
build tool already installed, then the easiest way to get it is via <a
href="https://www.haskell.org/ghcup/"><code>ghcup</code></a>.
Alternatively if you got <code>nix</code> then <code>nix-shell</code>
should give give you access to all the dependencies you need.</p>
<h2 id="contributing">Contributing</h2>
<p>There are many ways we can build upon this experiment, here are a few
ideas:</p>
<ul class="task-list">
<li><input type="checkbox" />We probably want to limit the max number of
threads in a pool;</li>
<li><input type="checkbox" /><a
href="https://github.com/m-lundberg/simple-pid/blob/master/simple_pid/pid.py#L128">Clamp</a>
integral part to avoid integral windup;</li>
<li><input type="checkbox" />If two or more threads take items from some
input queue and put them on some output queue then there’s no guarantee
that the order of the output items will be the same as the input items.
We could solve this, and regain determinism, by using array based queues
and shard on the index, i.e. even indices goes to one processor and odd
to an other or more generally modulus N can be used to shard between N
processors. This is essentially what the <a
href="https://en.wikipedia.org/wiki/Disruptor_(software)">LMAX
Disruptor</a> does;</li>
<li><input type="checkbox" />We’ve only looked at one stage in a
pipeline, what happens if we have multiple stages? is it enough to
control each individual stage separately or do we need more global
control?</li>
<li><input type="checkbox" />Can we come up with other things to
control? E.g. batch sizes?</li>
<li><input type="checkbox" />We’ve only monitored the current queue
length, could we combine this with other data? E.g. time series of the
queue length from the previous day?</li>
<li><input type="checkbox" />Is it robust to wildly changing usage
patterns? E.g. bursty traffic or the <a
href="https://en.wikipedia.org/wiki/Slashdot_effect">Slashdot
effect</a>?</li>
<li><input type="checkbox" />We’ve looked at scaling up and down on a
single machine (vertical scaling), what about scaling out and in across
multiple machines (horizontal scaling)?</li>
<li><input type="checkbox" />We generated and processed real work items
(by sleeping), could we do a discrete-event simulation instead to avoid
having to wait for the sleeps?</li>
<li><input type="checkbox" />I just picked random values for the PID
controller parameters, there are more principled <a
href="https://en.wikipedia.org/wiki/PID_controller#Overview_of_tuning_methods">ways</a>
of tuning the PID controller;</li>
<li><input type="checkbox" />The PID controller we implemented merely
followed the pseudo-code from Wikipedia, there’s probably better ways of
implementing it?</li>
</ul>
<p>If any of this sounds interesting, feel free to get in touch!</p>
<h2 id="see-also">See also</h2>
<ul>
<li><p><a
href="https://www.researchgate.net/publication/265611546_A_Review_of_Auto-scaling_Techniques_for_Elastic_Applications_in_Cloud_Environments"><em>A
Review of Auto-scaling Techniques for Elastic Applications in Cloud
Environments</em></a></p>
<ol start="2014" type="1">
<li>is a survey paper which talks about both threshold and PID
controllers;</li>
</ol></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~brewer/papers/SEDA-sosp.pdf"><em>SEDA:
An Architecture for Well-Conditioned Scalable Internet Services</em></a>
(2001), this is paper that I got the idea for elastic scalable thread
pools. They use a threshold approach rather than a PID controller,
saying:</p>
<blockquote>
<p>The controller periodically samples the input queue (once per second
by default) and adds a thread when the queue length exceeds some
threshold (100 events by default). Threads are removed from a stage when
they are idle for a specified period of time (5 seconds by default).</p>
</blockquote>
<p>But also:</p>
<blockquote>
<p>Under SEDA, the body of work on control systems can be brought to
bear on service resource management, and we have only scratched the
surface of the potential for this technique.</p>
</blockquote>
<p>A bit more explanation is provided by Matt Welsh, who is one of the
author, in his PhD <a
href="https://cs.uwaterloo.ca/~brecht/servers/readings-new/mdw-phdthesis.pdf">thesis</a>
(2002):</p>
<blockquote>
<p>A benefit to ad hoc controller design is that it does not rely on
complex models and parameters that a system designer may be unable to
understand or to tune. A common complaint of classic PID controller
design is that it is often difficult to understand the effect of gain
settings.</p>
</blockquote></li>
<li><p>There are many introductory text books on control theory, but
there’s a lot less resources on how to apply control theory to software
systems. Here are a few resources:</p>
<ul>
<li><p><a
href="https://janert.org/books/feedback-control-for-computer-systems/"><em>Feedback
Control for Computer Systems</em></a> book by Philipp K. Janert
(2013);</p></li>
<li><p><a
href="https://www.cse.wustl.edu/~lu/control-tutorials/im09/"><em>Tutorial:
Recent Advances in the Application of Control Theory to Network and
Service Management</em></a>.</p></li>
</ul></li>
<li><p>It could very well be that the way we’ve applied classic PID
controllers isn’t suitable for unpredictable internet traffic loads.
There are branches of control theory might be better suited for this,
see, for example, <a
href="https://en.wikipedia.org/wiki/Robust_control">robust</a> and <a
href="https://en.wikipedia.org/wiki/Adaptive_control">adaptive</a>
control theory;</p></li>
<li><p>The .NET thread pool apparently uses the <a
href="https://en.wikipedia.org/wiki/Hill_climbing">hill climbing</a>
optimisation technique to <a
href="https://mattwarren.org/2017/04/13/The-CLR-Thread-Pool-Thread-Injection-Algorithm/">elastically
scale</a>;</p></li>
<li><p>My previous post: <a
href="https://github.com/stevana/pipelined-state-machines#pipelined-state-machines"><em>An
experiment in declaratively programming parallel pipelines of state
machines</em></a>.</p></li>
</ul>
<h2 id="discussion">Discussion</h2>
<ul>
<li><a href="https://news.ycombinator.com/item?id=35148068">Hacker
News</a>;</li>
<li><a
href="https://lobste.rs/s/ybtxic/experiment_elastically_scaling_thread">lobste.rs</a>;</li>
<li><a
href="https://old.reddit.com/r/haskell/comments/11qyfw7/an_experiment_in_elastically_scaling_a_thread/">r/haskell</a>;</li>
<li>Also see Glyn Normington’s <a
href="https://github.com/stevana/elastically-scalable-thread-pools/issues/1">comment</a>
in the issue tracker.</li>
</ul>
]]></description>
      <category>Deployment</category>
    </item>

    <item>
      <title>Pipelined state machines</title>
      <link>https://stevana.github.io/pipelined_state_machines.html</link>
      <guid>https://stevana.github.io/pipelined_state_machines.html</guid>
      <pubDate>Wed, 1 Mar 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>pipelined-state-machines</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#disruptor" id="toc-disruptor">Disruptor</a>
<ul>
<li><a href="#example" id="toc-example">Example</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
<li><a href="#performance" id="toc-performance">Performance</a></li>
</ul></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a>
<ul>
<li><a href="#presentations"
id="toc-presentations">Presentations</a></li>
<li><a href="#writings" id="toc-writings">Writings</a></li>
</ul></li>
</ul>
</nav>
<div class="date">Posted on Mar  1, 2023</div>
<p>An experiment in declaratively programming parallel pipelines of
state machines.</p>
<h2 id="motivation">Motivation</h2>
<p>Imagine a flat complex in Sweden. Being the socialist utopia Sweden
is there’s a shared laundry room which the people in the flat complex
can book. In the laundry room there’s everything one needs to wash, dry
and iron your clothes. You don’t even need to bring your own laundry
detergent!</p>
<p>Lets call three people living there Ann, Bo and Cecilia, and lets
assume they all want to use the laundry room. Depending on how the
booking system is implemented the total time it would take for all three
people to do their laundry varies.</p>
<p>For example if the booking system allocates a big time slot per
person in which that person can do the whole cycle of <em>W</em>ashing,
<em>D</em>rying and <em>I</em>roning then, assuming each step takes one
time unit, we get a situation like this:</p>
<pre><code>      Person
        ^
    Ann | W D I                             W = Washing
     Bo |       W D I                       D = Drying
Cecilia |             W D I                 I = Ironing
        +-------------------&gt; Time
        0 1 2 3 4 5 6 7 8 9</code></pre>
<p>Bo cannot start washing until Ann is done ironing, because Ann has
booked the room for the whole cycle, and so on.</p>
<p>If the booking system is more granular and allows booking a time slot
per step then we can get a situation that looks like this:</p>
<pre><code>      Person
        ^
    Ann | W D I
     Bo |   W D I
Cecilia |     W D I
        +-------------------&gt; Time
        0 1 2 3 4 5 6 7 8 9</code></pre>
<p>It should be clear that the total time is shorter in this case,
because the machines are utilised better (Bo can start using the washing
machine right after Ann is done with it). Also note that if each person
would start a new washing after they finish ironing the first one and so
on then the time savings would be even greater.</p>
<p>This optimisation is called pipelining. It’s used a lot in
manufacturing, for example Airbus <a
href="https://youtu.be/oxjT7veKi9c?t=2682">builds</a> two airplanes per
day. If you were to order a plane today you’d get it delivered in two
months time. How is that they deliver two per day if it takes two months
to build them? Pipelining! It’s also used inside CPUs to <a
href="https://en.wikipedia.org/wiki/Instruction_pipelining">pipeline
instructions</a>.</p>
<p>The rest of this document is an experiment in how we can construct
such pipelining in software in a declarative way.</p>
<h2 id="usage">Usage</h2>
<p>The workers or stages in our pipeline will be state machines of the
following type.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">SM</span> s a b <span class="kw">where</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Id</span><span class="ot">      ::</span> <span class="dt">SM</span> s a a</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Compose</span><span class="ot"> ::</span> <span class="dt">SM</span> s b c <span class="ot">-&gt;</span> <span class="dt">SM</span> s a b <span class="ot">-&gt;</span> <span class="dt">SM</span> s a c</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Fst</span><span class="ot">     ::</span> <span class="dt">SM</span> s (a, b) a</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Snd</span><span class="ot">     ::</span> <span class="dt">SM</span> s (a, b) b</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&amp;&amp;&amp;)  ::</span> <span class="dt">SM</span> s a c <span class="ot">-&gt;</span> <span class="dt">SM</span> s a d <span class="ot">-&gt;</span> <span class="dt">SM</span> s a (c, d)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:***)  ::</span> <span class="dt">SM</span> s a c <span class="ot">-&gt;</span> <span class="dt">SM</span> s b d <span class="ot">-&gt;</span> <span class="dt">SM</span> s (a, b) (c, d)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SlowIO</span><span class="ot">  ::</span> <span class="dt">SM</span> s a a <span class="co">-- Simulate a slow I/O computation.</span></span></code></pre></div>
<p>Here’s an example of a stage which takes an ordered pair as input and
swaps the elements of the pair. Note the use of <code>SlowIO</code> to
simulate that some slow I/O computation happens.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swap ::</span> <span class="dt">SM</span> () (a, b) (b, a)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>swap <span class="ot">=</span> <span class="dt">Snd</span> <span class="op">:***</span> <span class="dt">Fst</span> <span class="ot">`Compose`</span> copy <span class="ot">`Compose`</span> <span class="dt">SlowIO</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    copy <span class="ot">=</span> <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Id</span></span></code></pre></div>
<p>We can <code>interpret</code> such state machines into plain
functions as follows.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ot">interpret ::</span> <span class="dt">SM</span> s a b <span class="ot">-&gt;</span> (a <span class="ot">-&gt;</span> s <span class="ot">-&gt;</span> <span class="dt">IO</span> (s, b))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">Id</span>            x s <span class="ot">=</span> <span class="fu">return</span> (s, x)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>interpret (<span class="dt">Compose</span> g f) x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  (s&#39;, y) <span class="ot">&lt;-</span> interpret f x s</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  interpret g y s&#39;</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">Fst</span>           x s <span class="ot">=</span> <span class="fu">return</span> (s, <span class="fu">fst</span> x)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">Snd</span>           x s <span class="ot">=</span> <span class="fu">return</span> (s, <span class="fu">snd</span> x)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>interpret (f <span class="op">:&amp;&amp;&amp;</span> g)    x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  (s&#39;, y)  <span class="ot">&lt;-</span> interpret f x s</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  (s&#39;&#39;, z) <span class="ot">&lt;-</span> interpret g x s&#39;</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (s&#39;&#39;, (y, z))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>interpret (f <span class="op">:***</span> g)    x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  (s&#39;, y)  <span class="ot">&lt;-</span> interpret f (<span class="fu">fst</span> x) s</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  (s&#39;&#39;, z) <span class="ot">&lt;-</span> interpret g (<span class="fu">snd</span> x) s&#39;</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (s&#39;&#39;, (y, z))</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">SlowIO</span> x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  threadDelay <span class="dv">200000</span> <span class="co">-- 0.2s</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (s, x)</span></code></pre></div>
<p>Next lets have a look at how we can construct pipelines of such state
machines.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">P</span> a b <span class="kw">where</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span><span class="ot">     ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">SM</span> s a b <span class="ot">-&gt;</span> s <span class="ot">-&gt;</span> <span class="dt">P</span> a b</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&gt;&gt;&gt;) ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">P</span> b c <span class="ot">-&gt;</span> <span class="dt">P</span> a c</span></code></pre></div>
<p>The following is an example pipeline where there’s only one stage in
which we do our pair swapping three times.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swapsSequential ::</span> <span class="dt">P</span> (a, b) (b, a)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>swapsSequential <span class="ot">=</span> <span class="dt">SM</span> <span class="st">&quot;three swaps&quot;</span> (swap <span class="ot">`Compose`</span> swap <span class="ot">`Compose`</span> swap) ()</span></code></pre></div>
<p>The above corresponds to our coarse grained booking system where the
laundry was booked for the whole cycle. Whereas the following
corresponds to the more fine grained approach where we get
pipelining.</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swapsPipelined ::</span> <span class="dt">P</span> (a, b) (b, a)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>swapsPipelined <span class="ot">=</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span> <span class="st">&quot;first swap&quot;</span>  swap () <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span> <span class="st">&quot;second swap&quot;</span> swap () <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span> <span class="st">&quot;third swap&quot;</span>  swap ()</span></code></pre></div>
<p>A pipeline can be deployed, we’ll use the following type to keep
track of the queue associated with the pipeline as well as the name and
pids of the state machines involved in the pipeline.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">Deployment</span> a <span class="ot">=</span> <span class="dt">Deployment</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  {<span class="ot"> queue ::</span> <span class="dt">TQueue</span> a</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> pids  ::</span> [(<span class="dt">String</span>, <span class="dt">Async</span> ())]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="ot">names ::</span> <span class="dt">Deployment</span> a <span class="ot">-&gt;</span> <span class="dt">String</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>names <span class="ot">=</span> bracket <span class="op">.</span> intercalate <span class="st">&quot;,&quot;</span> <span class="op">.</span> <span class="fu">reverse</span> <span class="op">.</span> <span class="fu">map</span> <span class="fu">fst</span> <span class="op">.</span> pids</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    bracket s <span class="ot">=</span> <span class="st">&quot;[&quot;</span> <span class="op">++</span> s <span class="op">++</span> <span class="st">&quot;]&quot;</span></span></code></pre></div>
<p>Here’s the actual <code>deploy</code>ment function which takes a
pipeline and gives back an input-queue and a <code>Deployment</code>
which holds the output-queue and the names and pids of the state
machines.</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ot">deploy ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">TQueue</span> a, <span class="dt">Deployment</span> b)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>deploy p <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  q <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  d <span class="ot">&lt;-</span> deploy&#39; p (<span class="dt">Deployment</span> q [])</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (q, d)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="ot">deploy&#39; ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">Deployment</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Deployment</span> b)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>deploy&#39; (<span class="dt">SM</span> name sm s0) d <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  q&#39; <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  pid <span class="ot">&lt;-</span> async (go s0 q&#39;)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> <span class="dt">Deployment</span> { queue <span class="ot">=</span> q&#39;, pids <span class="ot">=</span> (name, pid) <span class="op">:</span> pids d }</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    f <span class="ot">=</span> interpret sm</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    go s q&#39; <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">&lt;-</span> atomically <span class="op">$</span> readTQueue (queue d)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>      (s&#39;, o) <span class="ot">&lt;-</span> f x s</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>      atomically <span class="op">$</span> writeTQueue q&#39; o</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>      go s&#39; q&#39;</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>deploy&#39; (sm <span class="op">:&gt;&gt;&gt;</span> sm&#39;) d <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  d&#39; <span class="ot">&lt;-</span> deploy&#39; sm d</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>  deploy&#39; sm&#39; d&#39;</span></code></pre></div>
<p>We now have everything we need to run a simple benchmark comparing
the sequential version of three swaps versus the pipelined version.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">PipelineKind</span> <span class="ot">=</span> <span class="dt">Sequential</span> <span class="op">|</span> <span class="dt">Pipelined</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> <span class="dt">Show</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="ot">main ::</span> <span class="dt">IO</span> ()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>main <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mapM_</span> libMain [<span class="dt">Sequential</span>, <span class="dt">Pipelined</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="ot">libMain ::</span> <span class="dt">PipelineKind</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>libMain k <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  (q, d) <span class="ot">&lt;-</span> deploy <span class="op">$</span> <span class="kw">case</span> k <span class="kw">of</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>                       <span class="dt">Sequential</span> <span class="ot">-&gt;</span> swapsSequential</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>                       <span class="dt">Pipelined</span>  <span class="ot">-&gt;</span> swapsPipelined</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span> k</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="op">$</span> <span class="st">&quot;Pids: &quot;</span> <span class="op">++</span> names d</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  start <span class="ot">&lt;-</span> getCurrentTime</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  forM_ [(<span class="dv">1</span>, <span class="dv">2</span>), (<span class="dv">2</span>, <span class="dv">3</span>), (<span class="dv">3</span>, <span class="dv">4</span>), (<span class="dv">4</span>, <span class="dv">5</span>), (<span class="dv">5</span>, <span class="dv">6</span>), (<span class="dv">6</span>, <span class="dv">7</span>)] <span class="op">$</span> \x <span class="ot">-&gt;</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    atomically <span class="op">$</span> writeTQueue q x</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  resps <span class="ot">&lt;-</span> replicateM <span class="dv">6</span> <span class="op">$</span> atomically <span class="op">$</span> readTQueue (queue d)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  end <span class="ot">&lt;-</span> getCurrentTime</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="op">$</span> <span class="st">&quot;Responses: &quot;</span> <span class="op">++</span> <span class="fu">show</span> resps</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="op">$</span> <span class="st">&quot;Time: &quot;</span> <span class="op">++</span> <span class="fu">show</span> (diffUTCTime end start)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="st">&quot;&quot;</span></span></code></pre></div>
<p>We can run the above with
<code>cabal run readme-pipeline-example</code>, which results in
something like the following being printed to the screen.</p>
<pre><code>Sequential
Pids: [three swaps]
Responses: [(2,1),(3,2),(4,3),(5,4),(6,5),(7,6)]
Time: 3.611045787s

Pipelined
Pids: [first swap,second swap,third swap]
Responses: [(2,1),(3,2),(4,3),(5,4),(6,5),(7,6)]
Time: 1.604990775s</code></pre>
<p>Cool, we managed to reduce the total running time by more than half!
We can do even better though! In addition to pipelining we can also
shard the queues by letting two state machines work on the same queue,
the first processing the elements in the even positions of the queue and
the second processing the elements in the odd positions.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>data P a b where</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  SM     :: String -&gt; SM s a b -&gt; s -&gt; P a b</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  (:&gt;&gt;&gt;) :: P a b -&gt; P b c -&gt; P a c</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="va">+ Shard  :: P a b -&gt; P a b</span></span></code></pre></div>
<p>Here’s an example of a sharded pipeline, where each shard will spawn
two state machines (one working on the even indexes of the queue and the
other on the odd).</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swapsSharded ::</span> <span class="dt">P</span> (a, b) (b, a)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>swapsSharded <span class="ot">=</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span> (<span class="dt">SM</span> <span class="st">&quot;first swap&quot;</span>  swap ()) <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span> (<span class="dt">SM</span> <span class="st">&quot;second swap&quot;</span> swap ()) <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span> (<span class="dt">SM</span> <span class="st">&quot;third swap&quot;</span>  swap ())</span></code></pre></div>
<p>In the deployment of shards, we achieve the even-odd split by reading
from the input queue, <code>qIn</code>, and first writing to the even
queue, <code>qEven</code>, and then switching over to the odd queue,
<code>qOdd</code>, when making the recursive call in
<code>shardQIn</code>. Whereas <code>shardQOut</code> does the inverse
and merges the two queues back into the output queue:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="va">+ deploy&#39; (Shard p) d = do</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="va">+   let qIn = queue d</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="va">+   qEven  &lt;- newTQueueIO</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="va">+   qOdd   &lt;- newTQueueIO</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="va">+   pidIn  &lt;- async $ shardQIn qIn qEven qOdd</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="va">+   dEven  &lt;- deploy&#39; p (Deployment qEven [])</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="va">+   dOdd   &lt;- deploy&#39; p (Deployment qOdd [])</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="va">+   qOut   &lt;- newTQueueIO</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="va">+   pidOut &lt;- async $ shardQOut (queue dEven) (queue dOdd) qOut</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="va">+   return (Deployment qOut ((&quot;shardIn:  &quot; ++ names dEven ++ &quot; &amp; &quot; ++ names dOdd, pidIn) :</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="va">+                            (&quot;shardOut: &quot; ++ names dEven ++ &quot; &amp; &quot; ++ names dOdd, pidOut) :</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="va">+                            pids dEven ++ pids dOdd ++ pids d))</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="va">+   where</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQIn :: TQueue a -&gt; TQueue a -&gt; TQueue a -&gt; IO ()</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQIn  qIn qEven qOdd = do</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="va">+       atomically (readTQueue qIn &gt;&gt;= writeTQueue qEven)</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="va">+       shardQIn qIn qOdd qEven</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQOut :: TQueue a -&gt; TQueue a -&gt; TQueue a -&gt; IO ()</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQOut qEven qOdd qOut = do</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="va">+       atomically (readTQueue qEven &gt;&gt;= writeTQueue qOut)</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="va">+       shardQOut qOdd qEven qOut</span></span></code></pre></div>
<p>Running this version we see more than 3.5x speed-up compared to the
sequential pipeline.</p>
<pre><code>Sharded
Pids: [first swap,first swap,shardOut: [first swap] &amp; [first swap],shardIn:  [first swap] &amp; [first swap],second swap,second swap,shardOut: [second swap] &amp; [second swap],shardIn:  [second swap] &amp; [second swap],third swap,third swap,shardOut: [third swap] &amp; [third swap],shardIn:  [third swap] &amp; [third swap]]
Responses: [(2,1),(3,2),(4,3),(5,4),(6,5),(7,6)]
Time: 1.00241912s</code></pre>
<p>There are still many more improvements to be made here:</p>
<ul>
<li>Avoid spawning threads for merely shuffling elements between queues,
e.g. <code>shardQ{In, Out}</code> above;</li>
<li>Avoid copying elements between queues;</li>
<li>Back-pressure;</li>
<li>Batching.</li>
</ul>
<p>I believe all these problems can be solved by choosing a better
concurrent queue data structure than <code>TQueue</code>, so that’s what
we’ll have a look at next.</p>
<h2 id="disruptor">Disruptor</h2>
<p>The <code>Disruptor*</code> modules are a Haskell port of the <a
href="https://github.com/LMAX-Exchange/disruptor">LMAX Disruptor</a>,
which is a high performance inter-thread messaging library. The
developers at LMAX, which operates a financial exchange, <a
href="https://www.infoq.com/presentations/LMAX/">reported</a> in 2010
that they could process more than 100,000 transactions per second at
less than 1 millisecond latency.</p>
<p>At its core it’s just a lock-free concurrent queue, but it also
provides building blocks for achieving several useful concurrent
programming tasks that typical queues don’t (or at least don’t make
obvious how to do). The extra features include:</p>
<ul>
<li>Multi-cast (many consumers can in parallel process the same
event);</li>
<li>Batching (both on producer and consumer side);</li>
<li>Back-pressure;</li>
<li>Sharding for scalability;</li>
<li>Dependencies between consumers.</li>
</ul>
<p>It’s also performs better than most queues, as we shall see further
down.</p>
<h3 id="example">Example</h3>
<div class="sourceCode" id="cb17"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">Control.Concurrent</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">Control.Concurrent.Async</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">Disruptor.SP</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="ot">main ::</span> <span class="dt">IO</span> ()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>main <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Create the shared ring buffer.</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> bufferCapacity <span class="ot">=</span> <span class="dv">128</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  rb <span class="ot">&lt;-</span> newRingBuffer bufferCapacity</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- The producer keeps a counter and produces events that are merely the pretty</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- printed value as a string of that counter.</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span><span class="ot"> produce ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">String</span>, <span class="dt">Int</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>      produce n <span class="ot">=</span> <span class="fu">return</span> (<span class="fu">show</span> n, n <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- The counter starts at zero.</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>      initialProducerState <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- No back-pressure is applied in this example.</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="ot">      backPressure ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>      backPressure _ <span class="ot">=</span> <span class="fu">return</span> ()</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>  producer <span class="ot">&lt;-</span> newEventProducer rb produce backPressure initialProducerState</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- The consumer merely prints the string event to the terminal.</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span><span class="ot"> consume ::</span> () <span class="ot">-&gt;</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">EndOfBatch</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>      consume () event snr endOfBatch <span class="ot">=</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        <span class="fu">putStrLn</span> (event <span class="op">++</span> <span class="kw">if</span> endOfBatch <span class="kw">then</span> <span class="st">&quot; (end of batch)&quot;</span> <span class="kw">else</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- The consumer doesn&#39;t need any state in this example.</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>      initialConsumerState <span class="ot">=</span> ()</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- Which other consumers do we need to wait for before consuming an event?</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>      dependencies <span class="ot">=</span> []</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- What to do in case there are no events to consume?</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>      waitStrategy <span class="ot">=</span> <span class="dt">Sleep</span> <span class="dv">1</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>  consumer <span class="ot">&lt;-</span> newEventConsumer rb consume initialConsumerState dependencies waitStrategy</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tell the ring buffer which the last consumer is, to avoid overwriting</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- events that haven&#39;t been consumed yet.</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>  setGatingSequences rb [ecSequenceNumber consumer]</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>  withEventProducer producer <span class="op">$</span> \ap <span class="ot">-&gt;</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>    withEventConsumer consumer <span class="op">$</span> \ac <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>      threadDelay (<span class="dv">3</span> <span class="op">*</span> <span class="dv">1000</span> <span class="op">*</span> <span class="dv">1000</span>) <span class="co">-- 3 sec</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>      cancel ap</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>      cancel ac</span></code></pre></div>
<p>You can run the above example with
<code>cabal run readme-disruptor-example</code>.</p>
<p>A couple of things we could change to highlight the features we
mentioned in the above section:</p>
<ol type="1">
<li><p>Add a second consumer that saves the event to disk, this consumer
would be slower than the current one which logs to the terminal, but we
could use buffer up events in memory and only actually write when the
end of batch flag is set to speed things up;</p></li>
<li><p>We could also shard depending on the sequence number, e.g. have
two slower consumers that write to disk and have one of them handle even
sequence numbers while the other handles odd ones;</p></li>
<li><p>The above producer writes one event at the time to the ring
buffer, but since we know at which sequence number the last consumer is
at we can easily make writes in batches as well;</p></li>
<li><p>Currently the producer doesn’t apply any back-pressure when the
ring buffer is full, in a more realistic example where the producer
would, for example, create events from requests made to a http server we
could use back-pressure to tell the http server to return status code
429 (too many requests);</p></li>
<li><p>If we have one consumer that writes to the terminal and another
one that concurrently writes to disk, we could add a third consumer that
does something with the event only if it has both been logged and stored
to disk (i.e. the third consumer depends on both the first and the
second).</p></li>
</ol>
<h3 id="how-it-works">How it works</h3>
<p>The ring buffer is implemented using a bounded array, it keeps track
of a monotonically increasing sequence number and it knows its the
capacity of the array, so to find out where to write the next value by
simply taking the modulus of the sequence number and the capacity. This
has several advantages over traditional queues:</p>
<ol type="1">
<li><p>We never remove elements when dequeing, merely overwrite them
once we gone all way around the ring. This removes write <a
href="https://en.wikipedia.org/wiki/Resource_contention">contention</a>
between the producer and the consumer, one could also imagine avoiding
garbage collection by only allocating memory the first time around the
ring (but we don’t do this in Haskell);</p></li>
<li><p>Using an array rather than linked list increasing <a
href="https://en.wikipedia.org/wiki/Stride_of_an_array">striding</a> due
to <a
href="https://en.wikipedia.org/wiki/Locality_of_reference#Spatial_and_temporal_locality_usage">spatial
locality</a>.</p></li>
</ol>
<p>The ring buffer also keeps track of up to which sequence number its
last consumer has consumed, in order to not overwrite events that
haven’t been handled yet.</p>
<p>This also means that producers can ask how much capacity left a ring
buffer has, and do batched writes. If there’s no capacity left the
producer can apply back-pressure upstream as appropriate.</p>
<p>Consumers need keep track of which sequence number they have
processed, in order to avoid having the ring buffer overwrite
unprocessed events as already mentioned, but this also allows consumers
to depend on each other.</p>
<p>When a consumer is done processing an event, it asks the ring buffer
for the event at its next sequence number, the ring buffer then replies
that either there are no new events, in which case the consumer applies
it wait strategy, or the ring buffer can reply that there are new
events, the consumer the handles each one in turn and the last one will
be have the end of batch flag set, so that the consumer can effectively
batch the processing.</p>
<h3 id="performance">Performance</h3>
<p>Our Disruptor implementation, which hasn’t been optimised much yet,
is about 2x slower than LMAX’s Java version on their single-producer
single-consumer <a
href="https://github.com/LMAX-Exchange/disruptor/blob/master/src/perftest/java/com/lmax/disruptor/sequenced/OneToOneSequencedThroughputTest.java">benchmark</a>
(1P1C) (basically the above example) on a couple of years old Linux
laptop.</p>
<p>The same benchmark compared to other Haskell libraries:</p>
<ul>
<li><p>10.3x faster than <a
href="https://hackage.haskell.org/package/base-4.15.0.0/docs/Control-Concurrent-Chan.html"><code>Control.Concurrent.Chan</code></a>;</p></li>
<li><p>8.3x faster than <a
href="https://hackage.haskell.org/package/stm/docs/Control-Concurrent-STM-TBQueue.html"><code>Control.Concurrent.STM.TBQueue</code></a>;</p></li>
<li><p>1.7x faster than <a
href="https://hackage.haskell.org/package/unagi-chan"><code>unagi-chan</code></a>;</p></li>
<li><p>25.5x faster than <a
href="https://hackage.haskell.org/package/chaselev-deque"><code>chaselev-deque</code></a>;</p></li>
<li><p>700x faster than <a
href="https://hackage.haskell.org/package/ring-buffer"><code>ring-buffer</code></a>;</p></li>
<li><p>1.3x slower than <a
href="https://hackage.haskell.org/package/lockfree-queue"><code>lockfree-queue</code></a>;</p></li>
<li><p>TODO: Compare with <a
href="https://github.com/kim/data-ringbuffer/tree/master/src/Data/RingBuffer"><code>data-ringbuffer</code></a>.</p></li>
</ul>
<p>In the triple-producer single-consumer (3P1C) <a
href="https://github.com/LMAX-Exchange/disruptor/blob/master/src/perftest/java/com/lmax/disruptor/sequenced/ThreeToOneSequencedThroughputTest.java">benchmark</a>,
the Java version is 5x slower than the Java 1P1C case. And our 3P1C is
4.6x slower than our 1P1C version and our 3P1C version is 2.7x slower
than the Java version.</p>
<p>The same benchmark compared to other Haskell libraries:</p>
<ul>
<li><p>73x faster than <a
href="https://hackage.haskell.org/package/base-4.15.0.0/docs/Control-Concurrent-Chan.html"><code>Control.Concurrent.Chan</code></a>;</p></li>
<li><p>3.5x faster than <a
href="https://hackage.haskell.org/package/stm/docs/Control-Concurrent-STM-TBQueue.html"><code>Control.Concurrent.STM.TBQueue</code></a>;</p></li>
<li><p>1.3x faster than <a
href="https://hackage.haskell.org/package/unagi-chan"><code>unagi-chan</code></a>;</p></li>
<li><p>1.9x faster than <a
href="https://hackage.haskell.org/package/lockfree-queue"><code>lockfree-queue</code></a>.</p></li>
</ul>
<p>For a slightly more “real world” example, we modified the 3P1C test
to have three producers that log messages while the consumer writes them
to a log file and compared it to <a
href="https://hackage.haskell.org/package/fast-logger"><code>fast-logger</code></a>.
The <code>pipelined-state-machines</code> benchmark has a throughput of
3:4 that of <code>fast-logger</code>. When we bump it to ten
concurrently logging threads the <code>pipelined-state-machines</code>
benchmark has a throughput of 10:7 that of <code>fast-logger</code>.</p>
<p>See the file <a href="benchmark.sh"><code>benchmark.sh</code></a> for
full details about how the benchmarks are run.</p>
<p>As always take benchmarks with a grain of salt, we’ve tried to make
them as fair with respect to each other and as true to the original Java
versions as possible. If you see anything that seems unfair, or if you
get very different results when trying to reproduce the numbers, then
please file an issue.</p>
<h2 id="contributing">Contributing</h2>
<p>There’s a lot of possible paths to explore from here, including:</p>
<ul class="task-list">
<li><input type="checkbox" />Can we swap out our use of
<code>TQueue</code> for <code>Disruptor</code> in our
<code>deploy</code> of <code>P</code>ipelines?</li>
<li><input type="checkbox" />Can we add something like a
<code>FanOut :: P a b -&gt; P a c -&gt; P a (b, c)</code> and a
<code>Par :: P a c -&gt; P b d -&gt; P (a, b) (c, d)</code> combinator
to allow two parallel queues?</li>
<li><input type="checkbox" />What about sum-types and error
handling?</li>
<li><input type="checkbox" />Our current, and the above just mentioned,
pipeline combinators are all binary to can we generalise this to
N-ary?</li>
<li><input type="checkbox" />Can we visualise pipelines using
<code>dot</code> or similar?</li>
<li><input type="checkbox" />Can we build a performance/cost simulator
of pipelines?</li>
<li><input type="checkbox" />Arrow syntax or monadic DSL for
pipelines?</li>
<li><input type="checkbox" />We’ve seen <a
href="https://github.com/stevana/hot-swapping-state-machines">previously</a>
how we can hot-code upgrade state machines, what about hot-code
upgrading pipelines?</li>
<li><input type="checkbox" />Can we implement the Erlang
<code>gen_event</code> behaviour using Disruptor?</li>
<li><input type="checkbox" />Would it make sense to use the spiritual
successor of the Disruptor instead, i.e. the different array queues from
<code>aeron</code> and <code>agrona</code>:
<ul>
<li><a
href="https://github.com/real-logic/agrona/blob/master/agrona/src/main/java/org/agrona/concurrent/OneToOneConcurrentArrayQueue.java">Single-producer
single-consumer</a>;</li>
<li><a
href="https://github.com/real-logic/agrona/blob/master/agrona/src/main/java/org/agrona/concurrent/ManyToOneConcurrentArrayQueue.java">Multiple-producers
single-consumer</a>;</li>
<li><a
href="https://github.com/real-logic/agrona/blob/master/agrona/src/main/java/org/agrona/concurrent/ManyToManyConcurrentArrayQueue.java">Multiple-producers
multiple-consumers</a>.</li>
</ul></li>
<li><input type="checkbox" />How exactly do these pipelines relate to
the libraries <a
href="https://hackage.haskell.org/package/pipes"><code>pipes</code></a>,
<a
href="https://hackage.haskell.org/package/conduit"><code>conduit</code></a>
and <a
href="https://hackage.haskell.org/package/streamly"><code>streamly</code></a>?</li>
<li><input type="checkbox" />How does it relate to synchronous
programming languages such as <a
href="https://en.wikipedia.org/wiki/Esterel">Esterel</a>, <a
href="https://en.wikipedia.org/wiki/Lustre_(programming_language)">Lustre</a>,
<a href="https://rml.lri.fr">ReactiveML</a>, etc? It seems to me that
their main motivation is to be concurrent or parallel while still
determinstic, which is what we’d like as well. Looking at ReactiveML’s
documentation for <a
href="https://rml.lri.fr/documentation.html#compositions">compositions</a>
we see the same constructs as we’ve discussed: their <code>;</code> is
our <code>Compose</code> (with its arguments flipped), their
<code>||</code> is our <code>FanOut</code>, their <code>|&gt;</code> is
our <code>:&gt;&gt;&gt;</code> and their <code>let-and</code> construct
could be achived by adding projection functions to our
<code>P</code>ipelines similar to <code>Fst</code> and <code>Snd</code>
for <code>SM</code>. Interestingly they don’t have any sum-types-like
construct here, i.e. something like
<code>(:|||) :: P a c -&gt; P b c -&gt; P (Either a b) c</code>;</li>
<li><input type="checkbox" />I like to think of how one constructs a
pipeline, i.e. the choice of which tasks should happen in parallel or
should be sharded etc, as a choice of how to best make use of the
CPUs/cores of a single computer. If seen this way then that begs the
question: what about a network of multiple computers? Perhaps there
should be something like a <code>Topology</code> data type which
describes how multiple pipelines interact and a topology is deployed by
deploying multiple pipelines over multiple machines?</li>
</ul>
<h2 id="see-also">See also</h2>
<h3 id="presentations">Presentations</h3>
<ul>
<li><p><a href="https://www.infoq.com/presentations/LMAX/">LMAX - How to
Do 100K TPS at Less than 1ms Latency</a> by Martin Thompson (QCon
2010);</p></li>
<li><p><a href="https://youtube.com/watch?v=Qho1QNbXBso">LMAX Disruptor
and the Concepts of Mechanical Sympathy</a> by Jamie Allen
(2011);</p></li>
<li><p><a
href="https://www.infoq.com/presentations/Concurrent-Programming-Using-The-Disruptor/">Concurrent
Programming with the Disruptor</a> by Trisha Gee (2012);</p></li>
<li><p><a href="https://youtube.com/watch?v=2Be_Lqa35Y0">Disruptor 3.0:
Details and Advanced Patterns</a> by Mike Barker (YOW! 2013);</p></li>
<li><p><a href="https://youtube.com/watch?v=fDGWWpHlzvw">Designing for
Performance</a> by Martin Thompson (GOTO 2015);</p></li>
<li><p><a href="https://vimeo.com/181814364">A quest for predictable
latency with Java concurrency</a> Martin Thompson (JavaZone
2016);</p></li>
<li><p><a href="https://www.youtube.com/watch?v=qDhTjE0XmkE">Evolution
of Financial Exchange Architectures</a> by Martin Thompson (QCon
2020)</p>
<ul>
<li>1,000,000 tx/s and less than 100 microseconds latency, he is no
longer at LMAX though so we don’t know if these exchanges are using the
disruptor pattern.</li>
</ul></li>
<li><p><a href="https://youtube.com/watch?v=tM4YskS94b0"><em>Aeron:
Open-source high-performance messaging</em></a> talk by Martin Thompson
(Strange Loop, 2014);</p></li>
<li><p><em>Aeron: What, Why and What Next?</em> <a
href="https://youtube.com/watch?v=p1bsloPeBzE">talk</a> by Todd
Montgomery (GOTO, 2015);</p></li>
<li><p><em>Cluster Consensus: when Aeron met Raft</em> <a
href="https://youtube.com/watch?v=GFfLCGW_5-w">talk</a> by Martin
Thompson (GOTO, 2018);</p></li>
<li><p><em>Fault Tolerant 24/7 Operations with Aeron Cluster</em> <a
href="https://youtube.com/watch?v=H9yqzfNiEb4">talk</a> by Todd
Montgomery (2022).</p></li>
</ul>
<h3 id="writings">Writings</h3>
<ul>
<li>Martin Thompson’s <a
href="https://mechanical-sympathy.blogspot.com/">blog</a>;</li>
<li>The Disruptor <a
href="https://groups.google.com/g/lmax-disruptor">mailing list</a>;</li>
<li>The Mechanical Sympathy <a
href="https://groups.google.com/g/mechanical-sympathy">mailing
list</a>;</li>
<li><a href="https://martinfowler.com/articles/lmax.html">The LMAX
Architecture</a> by Martin Fowler (2011);</li>
<li><a
href="https://en.wikipedia.org/wiki/Staged_event-driven_architecture">Staged
event-driven architecture</a>;</li>
<li><a href="https://www.reactivemanifesto.org/">The Reactive
Manifesto</a>;</li>
<li><a
href="https://en.wikipedia.org/wiki/Flow-based_programming">Flow-based
programming</a>.</li>
</ul>
]]></description>
      <category>Development</category>
    </item>

    <item>
      <title>Hot-code swapping à la Erlang with Arrow-based state machines</title>
      <link>https://stevana.github.io/hot-code_swapping_a_la_erlang_with_arrow-based_state_machines.html</link>
      <guid>https://stevana.github.io/hot-code_swapping_a_la_erlang_with_arrow-based_state_machines.html</guid>
      <pubDate>Tue, 21 Feb 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>hot-swapping-state-machines</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#background" id="toc-background">Background</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
<li><a href="#acknowledgments"
id="toc-acknowledgments">Acknowledgments</a></li>
</ul>
</nav>
<div class="date">Posted on Feb 21, 2023</div>
<p>An experiment in implementing remote hot code swapping, or dynamic
code upgrade, for state machines.</p>
<h2 id="background">Background</h2>
<p>In Erlang it’s possible to seamlessly hot swap the code on a running
process.</p>
<p>Consider the following <code>gen_server</code> implementation of a
counter which can be <code>incr</code>emented and have its current
<code>count</code> value retrieved:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-module</span><span class="fu">(</span><span class="ch">counter</span><span class="fu">).</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="fu">version(</span><span class="st">&quot;1&quot;</span><span class="fu">).</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">start_link</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">incr</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">count</span><span class="op">/</span><span class="dv">0</span><span class="fu">]).</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="fu">behavior(</span><span class="ch">gen_server</span><span class="fu">).</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">init</span><span class="op">/</span><span class="dv">1</span><span class="fu">,</span> <span class="ch">handle_call</span><span class="op">/</span><span class="dv">3</span><span class="fu">,</span> <span class="ch">handle_cast</span><span class="op">/</span><span class="dv">2</span><span class="fu">,</span> <span class="ch">handle_info</span><span class="op">/</span><span class="dv">2</span><span class="fu">,</span> <span class="ch">terminate</span><span class="op">/</span><span class="dv">2</span><span class="fu">,</span> <span class="ch">code_change</span><span class="op">/</span><span class="dv">3</span><span class="fu">]).</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">start_link()</span> <span class="op">-&gt;</span> <span class="fu">gen_server:start_link({</span><span class="ch">local</span><span class="fu">,</span> <span class="fu">?</span><span class="va">MODULE</span><span class="fu">},</span> <span class="fu">?</span><span class="va">MODULE</span><span class="fu">,</span> <span class="fu">[],</span> <span class="fu">[{</span><span class="ch">debug</span><span class="fu">,</span> <span class="fu">[</span><span class="ch">trace</span><span class="fu">]}]).</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">incr()</span>  <span class="op">-&gt;</span> <span class="fu">gen_server:call(?</span><span class="va">MODULE</span><span class="fu">,</span> <span class="ch">incr</span><span class="fu">).</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">count()</span> <span class="op">-&gt;</span> <span class="fu">gen_server:call(?</span><span class="va">MODULE</span><span class="fu">,</span> <span class="ch">count</span><span class="fu">).</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">init([])</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="dv">0</span><span class="fu">}.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call(</span><span class="ch">incr</span><span class="fu">,</span> <span class="va">_From</span><span class="fu">,</span> <span class="va">State</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">reply</span><span class="fu">,</span> <span class="ch">ok</span><span class="fu">,</span> <span class="va">State</span><span class="op">+</span><span class="dv">1</span><span class="fu">};</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call(</span><span class="ch">count</span><span class="fu">,</span> <span class="va">_From</span><span class="fu">,</span> <span class="va">State</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">reply</span><span class="fu">,</span> <span class="va">State</span><span class="fu">,</span> <span class="va">State</span><span class="fu">};</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call(</span><span class="va">_Call</span><span class="fu">,</span> <span class="va">_From</span><span class="fu">,</span> <span class="va">State</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">noreply</span><span class="fu">,</span> <span class="va">State</span><span class="fu">}.</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_cast(</span><span class="va">_Cast</span><span class="fu">,</span> <span class="va">State</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">noreply</span><span class="fu">,</span> <span class="va">State</span><span class="fu">}.</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_info(</span><span class="va">_Info</span><span class="fu">,</span> <span class="va">State</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">noreply</span><span class="fu">,</span> <span class="va">State</span><span class="fu">}.</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">terminate(</span><span class="va">_Reason</span><span class="fu">,</span> <span class="va">_State</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="ch">ok</span><span class="fu">.</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="fu">code_change(</span><span class="va">_OldVsn</span><span class="fu">,</span> <span class="va">State</span><span class="fu">,</span> <span class="va">_Extra</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="va">State</span><span class="fu">}.</span></span></code></pre></div>
<p>Here’s a small REPL session which shows how it works:</p>
<pre><code>1&gt; c(counter).
{ok,counter}
2&gt; counter:start_link().
{ok,&lt;0.87.0&gt;}
3&gt; counter:incr().
*DBG* counter got call incr from &lt;0.80.0&gt;
*DBG* counter sent ok to &lt;0.80.0&gt;, new state 1
ok
4&gt; counter:incr().
*DBG* counter got call incr from &lt;0.80.0&gt;
*DBG* counter sent ok to &lt;0.80.0&gt;, new state 2
ok
5&gt; counter:count().
*DBG* counter got call count from &lt;0.80.0&gt;
*DBG* counter sent 2 to &lt;0.80.0&gt;, new state 2
2</code></pre>
<p>Now lets introduce a contrived change to the counter where we change
the state to contain an additional counter, which starts at the value of
the old one (see <code>code_change</code>). The two operations
<code>incr</code> and <code>count</code> are changed to operate on the
new counter leaving the old one alone.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,5 +1,5 @@</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a> -module(counter).</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="st">--version(&quot;1&quot;).</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="va">+-version(&quot;2&quot;).</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a> -export([start_link/0, incr/0, count/0]).</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -13,14 +13,13 @@</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a> init([]) -&gt; {ok, 0}.</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="st">-handle_call(incr, _From, State) -&gt; {reply, ok, State+1};</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="st">-handle_call(count, _From, State) -&gt; {reply, State, State};</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="va">+handle_call(incr, _From, {OldState, State}) -&gt; {reply, ok, {OldState, State+1}};</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="va">+handle_call(count, _From, {OldState, State}) -&gt; {reply, State, {OldState, State}};</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a> handle_call(_Call, _From, State) -&gt; {noreply, State}.</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a> handle_cast(_Cast, State) -&gt; {noreply, State}.</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a> handle_info(_Info, State) -&gt; {noreply, State}.</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a> terminate(_Reason, _State) -&gt; ok.</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="st">-code_change(_OldVsn, State, _Extra) -&gt; {ok, State}.</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="va">+code_change(&quot;1&quot;, State, _Extra) -&gt; {ok, {State, State}}.</span></span></code></pre></div>
<p>We can now upgrade the running process as follows:</p>
<pre><code>6&gt; compile:file(counter).
{ok,counter}
7&gt; sys:suspend(counter).
ok
8&gt; code:purge(counter).
false
9&gt; code:load_file(counter).
{module,counter}
10&gt; sys:change_code(counter, counter, &quot;1&quot;, []).
ok
11&gt; sys:resume(counter).
ok
12&gt; counter:incr().
*DBG* counter got call incr from &lt;0.80.0&gt;
*DBG* counter sent ok to &lt;0.80.0&gt;, new state {2,3}
ok
13&gt; counter:incr().
*DBG* counter got call incr from &lt;0.80.0&gt;
*DBG* counter sent ok to &lt;0.80.0&gt;, new state {2,4}
ok
14&gt; counter:count().
*DBG* counter got call count from &lt;0.80.0&gt;
*DBG* counter sent 4 to &lt;0.80.0&gt;, new state {2,4}
4</code></pre>
<p>This repository is an experiment which tries to do something similar
in Haskell for state machines of type
<code>input -&gt; state -&gt; (state, output)</code>.</p>
<h2 id="usage">Usage</h2>
<p>Before we go into the details of how this is implemented in Haskell,
lets have a look at how it looks from the user’s perspective.</p>
<p>In one terminal run <code>cabal run exe</code> and in another
terminal run <code>cabal repl</code> and type:</p>
<pre><code>&gt; import LibMain
&gt; incr
&gt; count</code></pre>
<p>This should show the following in the first terminal:</p>
<pre><code>Output:    L Unit
New state: Int 1

Output:    R (Int 1)
New state: Int 1</code></pre>
<p>Where <code>L Unit</code> is the output from <code>incr</code> and
<code>R (Int 1)</code> the output from <code>count</code>.</p>
<p>Next we will upgrade the state machine from the REPL:</p>
<pre><code>&gt; import Example.Counter
&gt; upgrade (Upgrade counterSM counterSM2 upgradeState)
&gt; incr
&gt; incr
&gt; count</code></pre>
<p>Which will result in the following being printed in the first
terminal:</p>
<pre><code>Upgrade successful!

Output:    L Unit
New state: Pair (Int 1) (Int 1)

Output:    L Unit
New state: Pair (Int 1) (Int 2)

Output:    R (Int 2)
New state: Pair (Int 1) (Int 2)</code></pre>
<p>If we try to upgrade again, we get an error:</p>
<pre><code>The version running isn&#39;t the one the upgrade expects. Aborting upgrade.</code></pre>
<h2 id="how-it-works">How it works</h2>
<p>The basic idea is that we want our state machines to be seralisable
so that we can send them over the network in order to perform remote
upgrades.</p>
<p>The key observation is that a state machine of type:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> <span class="dt">SM</span> state input output <span class="ot">=</span> input <span class="ot">-&gt;</span> state <span class="ot">-&gt;</span> (state, output)</span></code></pre></div>
<p>is an instance of <code>Arrow</code> and <code>Arrow</code>s allow us
to express functions in a first-order way, as long as
<code>arr :: Arrow a =&gt; (b -&gt; c) -&gt; a b c</code> is
<em>not</em> used.</p>
<p>The <code>Arrow</code> type class modulo <code>arr</code> is the
<code>CartesianCategory</code> type class from Conal Elliott’s work on
<a href="http://conal.net/papers/compiling-to-categories/">compiling to
categories</a>.</p>
<p>The <code>CartesianCategory</code> type class is defined as
follows:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> <span class="dt">Category</span> k <span class="ot">=&gt;</span> <span class="dt">Cartesian</span> k <span class="kw">where</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  (&amp;&amp;&amp;) ::</span> k a c <span class="ot">-&gt;</span> k a d <span class="ot">-&gt;</span> k a (c, d)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ot">  (***) ::</span> k b c <span class="ot">-&gt;</span> k b&#39; c&#39; <span class="ot">-&gt;</span> k (b, b&#39;) (c, c&#39;)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  fst   ::</span> k (a, b) a</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="ot">  snd   ::</span> k (a, b) b</span></code></pre></div>
<p>The initial (or free) <code>CartesianCategory</code> is given by the
following data type:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">FreeCC</span> a b <span class="kw">where</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Id</span><span class="ot">      ::</span> <span class="dt">FreeCC</span> a a</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Compose</span><span class="ot"> ::</span> <span class="dt">FreeCC</span> b c <span class="ot">-&gt;</span> <span class="dt">FreeCC</span> a b <span class="ot">-&gt;</span> <span class="dt">FreeCC</span> a c</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&amp;&amp;&amp;)  ::</span> <span class="dt">FreeCC</span> a c <span class="ot">-&gt;</span> <span class="dt">FreeCC</span> a d <span class="ot">-&gt;</span> <span class="dt">FreeCC</span> a (c, d)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:***)  ::</span> <span class="dt">FreeCC</span> b c <span class="ot">-&gt;</span> <span class="dt">FreeCC</span> b&#39; c&#39; <span class="ot">-&gt;</span> <span class="dt">FreeCC</span> (b, b&#39;) (c, c&#39;)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Fst</span><span class="ot">     ::</span> <span class="dt">FreeCC</span> (a, b) a</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Snd</span><span class="ot">     ::</span> <span class="dt">FreeCC</span> (a, b) b</span></code></pre></div>
<p>with the, hopefully, obvious <code>Cartesian</code> instance.</p>
<p>So the idea is that we write our program using the
<code>Cartesian</code>:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swap ::</span> <span class="dt">Cartesian</span> k <span class="ot">=&gt;</span> k (a, b) (b, a)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>swap <span class="ot">=</span> copy <span class="op">&gt;&gt;&gt;</span> <span class="fu">snd</span> <span class="op">***</span> <span class="fu">fst</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="ot">    copy ::</span> <span class="dt">Cartesian</span> k <span class="ot">=&gt;</span> k a (a, a)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    copy <span class="ot">=</span> <span class="fu">id</span> <span class="op">&amp;&amp;&amp;</span> <span class="fu">id</span></span></code></pre></div>
<p>And then we can instantiate <code>k</code> to be <code>FreeCC</code>
and get ahold of the serialisable syntax.</p>
<p>Ideally, since writing larger programs in this point-free style is
tricky, we’d like to use Haskell’s arrow syntax:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swap&#39; ::</span> <span class="dt">Cartesian</span> k <span class="ot">=&gt;</span> k (a, b) (b, a)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>swap&#39; <span class="ot">=</span> proc (x, y) <span class="ot">-&gt;</span> returnA <span class="op">-&lt;</span> (y, x)</span></code></pre></div>
<p>After all <code>Cartesian</code> is merely <code>Arrow</code> without
<code>arr</code> and we’ve shown how <code>swap</code> can be
implemented without <code>arr</code>, but alas GHC nevertheless tries to
translate <code>swap'</code> into something that uses <code>arr</code>
which ruins our plan.</p>
<p>Conal developed the <code>concat</code> GHC plugin to avoid this
problem. It translates any monomorphic Haskell function into an
<code>Arrow</code> of any user-defined Haskell Cartesian closed category
(CCC)<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>.</p>
<p>Oleg Grenrus also developed another GHC <a
href="https://github.com/phadej/overloaded/blob/master/src/Overloaded/Categories.hs">plugin</a>
that does the right thing and translates arrow syntax into
<code>CartesianCategory</code> rather than <code>Arrow</code> which also
solves the problem.</p>
<p>Since both of these approaches rely on the GHC plugin machinery they
are quite heavyweight. Conal’s translation works for any monomorphic
function, so in a sense it solves a more general problem than we need.
Oleg’s library is also solving a bunch of other problems that we don’t
care about, it implements OverloadedStrings, OverloadedLists,
OverloadedLabels using the plugin, and more importantly it doesn’t
compile with GHC 9.2 or above.</p>
<p>More recently Lucas Escot <a
href="https://acatalepsie.fr/posts/overloading-lambda">showed</a> how to
use ideas from Jean-Philippe Bernardy and Arnaud Spiwack’s <a
href="https://arxiv.org/abs/2103.06195">paper</a> <em>Evaluating Linear
Functions to Symmetric Monoidal Categories</em> (2021) to provide a
small DSL which gives us something close to the arrow syntax. It’s also
not quite perfect, in particular higher-order combinators cannot be
expressed, but Lucas tells me that he’s working on a follow up post
which tackles this problem. As we’ve seen in the above example, we also
need to encode the state machine’s inputs and outputs as explicit
<code>Either</code>s, it might be possible to get around this with some
generically derived isomorphism though.</p>
<p>Anyway, we use the <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/main/src/Syntax.hs">trick</a>
that Lucas described to express our <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/3e0a0cf8f605cfd8edd60aef1ebe6fb002bbea3e/src/Example/Counter.hs#L6">state
machines</a> and from that we get something <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/main/src/StateMachine.hs">similar</a>
to the free Cartesian category (<code>FreeCC</code> above), which we
then compile to the <a
href="https://en.wikipedia.org/wiki/Categorical_abstract_machine">Categorical
abstract machine</a> (CAM). This <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/main/src/Compiler.hs">compilation</a>
process is rather straight-forward as <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/main/src/AbstractMachine.hs">CAM</a>
is similar to <code>FreeCC</code>. The CAM <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/main/src/Code.hs">“bytecode”</a>
is our serialised state machine and this is what gets sent over the
network when doing upgrades.</p>
<p>The idea is that each deployed node runs a CAM (or some other
abstract machine), when we <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/3f7c4081d84a6ca3eeafbe892ca0798b96f61645/src/LibMain.hs#L25">deploy</a>
the node we specify a initial state machine (SM) to run there. We then
remotely upgrade the state machine on a node by sending it CAM bytecode
of the old SM (this is used to verify that we are not updating the wrong
SM), the bytecode for the new SM and the bytecode for a state migration
(old state to new state). The state migration is <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/3f7c4081d84a6ca3eeafbe892ca0798b96f61645/src/LibMain.hs#L65">type-safe</a>.</p>
<p>We could also serialise the free Cartesian category and send that
over the network, but the bytecode is “flatter” (i.e. can more easily be
turned into a list of bytecodes) and hopefully a more stable API. I can
imagine situations where the syntax for writing state machines changes
or gets more expressive, but the bytecode stays the same. Which is a
good thing, since upgrading the abstract machine on a node can probably
not be done as easily without any downtime.</p>
<h2 id="contributing">Contributing</h2>
<p>I believe this is a good starting point for further experiments, here
are a few ideas:</p>
<ul class="task-list">
<li><input type="checkbox" />Generate <code>FreeFunc s a b</code> so
that the <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/main/src/Correctness.hs">correctness</a>
can be tested using property-based testing;</li>
<li><input type="checkbox" />Backwards compatibility, i.e. allow old
inputs after an upgrade, perhaps similar to how state migrations are
handled by providing a <code>FreeFunc ()       oldInput newInput</code>
as part of <a
href="https://github.com/stevana/hot-swapping-state-machines/blob/02b84cf590addcb35d9ac524070ac93859e1b035/src/LibMain.hs#L62"><code>Upgrade</code></a>;</li>
<li><input type="checkbox" />Automatic state migration? C.f. <a
href="https://github.com/turion/essence-of-live-coding#migration">essence-of-live-coding</a>;</li>
<li><input type="checkbox" />Downgrades and rollback in case upgrades
fail;</li>
<li><input type="checkbox" />Improve the DSL for writing state machines:
<ul>
<li>Either building upon the current approach described in <a
href="https://acatalepsie.fr/posts/overloading-lambda"><em>Overloading
the lambda abstraction in Haskell</em></a> by Lucas;</li>
<li>Or perhaps using a custom preprocessor and quasiquoter for Cartesian
(closed) categories, see Pepe Iborra’s <a
href="https://hackage.haskell.org/package/arrowp-qq">arrowp-qq</a> for
inspiration;</li>
<li>Or porting the <a
href="https://hackage.haskell.org/package/overloaded-0.3.1/docs/Overloaded-Categories.html">Overloaded.Categories</a>
bits from Oleg’s plugin to newer GHC versions;</li>
<li>Or actually fixing GHC, I’m not sure if there’s a proposal for this
already, I think the closest thing I could find is <a
href="https://github.com/ghc-proposals/ghc-proposals/pull/303">this</a>
(stale) one by Alexis King.</li>
</ul></li>
<li><input type="checkbox" />In Erlang upgrades are usually not done
directly on <code>gen_server</code> but rather via the
<code>application</code> and <code>release</code>s behaviours. In short
one <code>application</code> is a supervisor tree and a
<code>release</code> is one or more <code>application</code>s. For more
see <a
href="https://kennyballou.com/blog/2016/12/elixir-hot-swapping/index.html">appup
and relups</a>, as well as how this can be automated using rebar3 over
<a
href="https://lrascao.github.io/automatic-release-upgrades-in-erlang/">here</a>.
What would porting that over to our setting look like?</li>
<li><input type="checkbox" />How does Erlang handle upgrades of the VM
without downtime?</li>
<li><input type="checkbox" />Would anything need to be changed if we
tried to combine the arrow-based state machines with <a
href="https://github.com/stevana/supervised-state-machines">supervisors</a>
or <a href="https://github.com/stevana/coroutine-state-machines">async
I/O</a>?</li>
<li><input type="checkbox" />Can we implement the abstract machine and
event loop using <a
href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> or
WebAssembly for portability?</li>
<li><input type="checkbox" />Imagine if we wanted to develop state
machines in an other programming language but still target the CAM. Most
programming languages don’t have GADTs so type-safe the free Cartesian
category will not be possible to implement, furthermore even if we could
there’s the problem of working with combinators vs arrow syntax… Is
there a more low-tech solution that would be easier to port to less
featureful languages?</li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a
href="https://github.com/turion/essence-of-live-coding"><code>essence-of-live-coding</code></a>:
FRP library with hot code swapping support.</li>
<li>Dan Piponi’s <code>circuit</code>s are similar to our state
machines:
<ul>
<li><a
href="http://blog.sigfpe.com/2017/01/addressing-pieces-of-state-with.html"
class="uri">http://blog.sigfpe.com/2017/01/addressing-pieces-of-state-with.html</a>;</li>
<li><a
href="http://blog.sigfpe.com/2017/01/building-free-arrows-from-components.html"
class="uri">http://blog.sigfpe.com/2017/01/building-free-arrows-from-components.html</a>.</li>
</ul></li>
<li>Chris Penner’s <em>Deconstructing Lambdas</em> <a
href="https://youtube.com/watch?v=xZmPuz9m2t0">talk</a> (2021);</li>
<li>The <em>Dynamic code change</em> chapter (p. 72) in Joe Armstrong’s
PhD <a
href="http://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A9492&amp;dswid=2250">thesis</a>
(2003).</li>
</ul>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Thanks to Daniel Gustafsson for helping me understand
<code>Port</code> from the <em>Overloading the lambda abstraction in
Haskell</em> blog post!</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The closed part of Cartesian <em>closed</em> category
means that we also add exponents (not just finite products),
i.e. analogous to <a
href="https://hackage.haskell.org/package/base-4.17.0.0/docs/Control-Arrow.html#t:ArrowApply"><code>ArrowApply</code></a>.<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></description>
      <category>Upgrading</category>
    </item>

    <item>
      <title>Deploying and restarting state machines using supervisor trees</title>
      <link>https://stevana.github.io/deploying_and_restarting_state_machines_using_supervisor_trees.html</link>
      <guid>https://stevana.github.io/deploying_and_restarting_state_machines_using_supervisor_trees.html</guid>
      <pubDate>Mon, 13 Feb 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>supervised-state-machines</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a>
<ul>
<li><a href="#generic-server" id="toc-generic-server">Generic
server</a></li>
<li><a href="#supervisor" id="toc-supervisor">Supervisor</a></li>
<li><a href="#event-loop" id="toc-event-loop">Event loop</a></li>
<li><a href="#example" id="toc-example">Example</a></li>
</ul></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
</ul>
</nav>
<div class="date">Posted on Feb 13, 2023</div>
<p>An experimental implementation of Erlang/OTP’s
<code>gen_server</code> and <code>supervisor</code> behaviours that
doesn’t use lightweight threads and message passing.</p>
<h2 id="motivation">Motivation</h2>
<p>What exactly is it that makes Erlang suitable for writing reliable
distributed systems?</p>
<p>I’ve previously <a
href="https://github.com/stevana/armstrong-distributed-systems/blob/main/docs/erlang-is-not-about.md#erlangs-not-about-lightweight-processes-and-message-passing">argued</a>
that it’s Erlang’s <em>behaviours</em> rather than its lightweight
processes and message passing.</p>
<p>Behaviours can be thought of as generic building blocks for building
reliable distributed systems. Erlang/OTP exposes six behaviours and
encourages its users to compose them into bigger systems. The behaviours
are generic in that they are parametrised by interfaces, the idea being
that the user implements the interface in a problem specific way and
then the user gets the generic component from Erlang/OTP. Typically the
interface requires a sequential implementation while the generic
component exposes a concurrent (or thread-safe) API, i.e. behaviours
abstract away the low-level and difficult concurrent code which is
difficult to get right. Joe Armstrong <a
href="https://dl.acm.org/doi/10.1145/1238844.1238850">describes</a> them
as follows:</p>
<blockquote>
<p>Behaviors in Erlang can be thought of as parameterizable higher-order
parallel processes. They represent an extension of conventional
higher-order functions (like map, fold etc) into a concurrent
domain.</p>
</blockquote>
<p>Which I think is a good analogy, as e.g. <code>map</code> and
<code>fold</code> hide the low-level details of <code>for</code>-loops,
although the concurrent details of behaviours are typically more
complicated than manually dealing with index variables.</p>
<p>This repo is an experiment in trying to implement two of these
behaviours, namely <code>gen_server</code> and <code>supervisor</code>,
without using lightweight processes/threads and message passing. I
believe the last part about not using lightweight threads is a design
space that hasn’t been explored much yet. Most programming languages or
libraries seem to start with the assumption that what makes Erlang great
for writing reliable distributed systems is its lightweight threads and
message passing, and they never even get to the point where they steal
the structure of behaviours!</p>
<h2 id="how-it-works">How it works</h2>
<h3 id="generic-server">Generic server</h3>
<p>The sequential semantics (or “business logic”) of a generic server
(<code>gen_server</code>) should take some input and the current state
and produce some output and a new updated state, i.e.:</p>
<pre><code>  input -&gt; state -&gt; (state, output)</code></pre>
<p>Client requests to the server will come in via the network, so we
also need a <code>Codec</code> to be able to decode
<code>ByteString</code>s into <code>input</code>s and encode
<code>output</code>s into <code>ByteString</code>s to be able to reply
to the client. We might also want to deserialise the initial state
<code>state</code> from disk on startup and serialise it to disk on
termination. See the <code>StateMachine</code> <a
href="src/StateMachine.hs">module</a> for the details of the above.</p>
<h3 id="supervisor">Supervisor</h3>
<p>The job of a supervisor is to monitor its children for failures and
do restarts according to some predetermined restart strategy in case a
failure happens.</p>
<p>Supervisors are organised in trees where generic servers (or more
generally any other worker behaviours) are at the leaves and other
supervisors are at the nodes. Since supervisors trees determine an order
(depth-first) they can be used to deploy a system of generic
servers.</p>
<p>See the <code>Supervisor</code> <a
href="src/Supervisor.hs">module</a> for details.</p>
<h3 id="event-loop">Event loop</h3>
<p>The concurrent part of the generic servers is implemented in the
<code>EventLoop</code> <a href="src/EventLoop.hs">module</a>. The basic
idea is that we concurrently write client request
<code>ByteString</code>s to a concurrent queue and the event loop will
decode the input and <code>step</code> the right server with said input
and respond to the client with the output produce by the server.</p>
<p>The behavior of supervisors is also implemented in the event loop.
Basically we wrap the <code>step</code> function in a <code>try</code>
and <code>catch</code> and in case of failure we do the appropriate
restarts.</p>
<h3 id="example">Example</h3>
<p>As an example of generic server I’ve implemented a simple key value
store in the <code>Example.KeyValueStore</code> <a
href="src/Example/KeyValueStore.hs">module</a>. In <a
href="app/Main.hs"><code>app/Main.hs</code></a> we start an event loop
with a simple supervisor tree containing the key value store:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ot">    main ::</span> <span class="dt">IO</span> ()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    main <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>      <span class="kw">let</span> sup <span class="ot">=</span> <span class="dt">Supervisor</span> <span class="dt">OneForOne</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                  [ <span class="dt">Worker</span> (<span class="st">&quot;kv1&quot;</span>, kvStore)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                  , <span class="dt">Supervisor</span> <span class="dt">RestForOne</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                      [ <span class="dt">Worker</span> (<span class="st">&quot;kv2&quot;</span>, kvStore), <span class="dt">Worker</span> (<span class="st">&quot;kv3&quot;</span>, kvStore) ]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                  ]</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>      queue <span class="ot">&lt;-</span> newTBQueueIO <span class="dv">128</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>      withEventLoop sup queue <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        call_ <span class="st">&quot;kv2&quot;</span> (<span class="dt">Store</span> <span class="st">&quot;x&quot;</span> <span class="dv">1</span>) queue</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        r0 <span class="ot">&lt;-</span> call <span class="st">&quot;kv2&quot;</span> (<span class="dt">Lookup</span> <span class="st">&quot;x&quot;</span>) queue</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span> r0</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        call_ <span class="st">&quot;kv2&quot;</span> (<span class="dt">Lookup</span> <span class="st">&quot;crash&quot;</span>) queue <span class="co">-- Deliberate bug which causes a crash.</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        r1 <span class="ot">&lt;-</span> call <span class="st">&quot;kv2&quot;</span> (<span class="dt">Lookup</span> <span class="st">&quot;x&quot;</span>) queue</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span> r1</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        r2 <span class="ot">&lt;-</span> call <span class="st">&quot;kv2&quot;</span> (<span class="dt">Lookup</span> <span class="st">&quot;y&quot;</span>) queue</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span> r2</span></code></pre></div>
<p>When run with <code>cabal run kv</code> it produces the following
output:</p>
<pre><code>    Calling kv2: Store &quot;x&quot; 1
    KV store starting: kv1
    KV store starting: kv2
    KV store starting: kv3
    Calling kv2: Lookup &quot;x&quot;
    Right &quot;Result (Just 1)&quot;
    Calling kv2: Lookup &quot;crash&quot;
    kv2 threw: divide by zero
    KV store terminating: kv2
    KV store terminating: kv3
    KV store starting: kv2
    KV store starting: kv3
    Calling kv2: Lookup &quot;x&quot;
    Right &quot;Result Nothing&quot;
    Calling kv2: Lookup &quot;y&quot;
    Right &quot;Result Nothing&quot;</code></pre>
<h2 id="contributing">Contributing</h2>
<p>There are many ways in which this repo can be extended, here are some
ideas:</p>
<ul class="task-list">
<li><input type="checkbox" />Add HTTP endpoint for writing to the event
loop queue. (Hint: see the <code>HttpServer</code> and
<code>EventLoop</code> modules of this <a
href="https://github.com/stevana/coroutine-state-machines">repo</a>));</li>
<li><input type="checkbox" />Save and restore the state of the example
to disk in <code>terminate</code> and <code>init</code>;</li>
<li><input type="checkbox" />Customisable shutdown grace time;</li>
<li><input type="checkbox" />The supervisors itself should fail if its
children have failed too many times within some time interval;</li>
<li><input type="checkbox" />Supervisors should be able to supervise
supervisor trees that are deployed on other computers.</li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li>There are a handful of supervisor implementations in Haskell <a
href="https://hackage.haskell.org/packages/search?terms=supervisor">already</a>,
but I think all of them assume that the children are running on their
own threads.</li>
</ul>
]]></description>
      <category>Deployment</category>
    </item>

    <item>
      <title>Simulation testing using state machines</title>
      <link>https://stevana.github.io/simulation_testing_using_state_machines.html</link>
      <guid>https://stevana.github.io/simulation_testing_using_state_machines.html</guid>
      <pubDate>Tue, 7 Feb 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>Property-based testing stateful systems: a tutorial</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#structure" id="toc-structure">Structure</a></li>
<li><a href="#table-of-contents" id="toc-table-of-contents">Table of
contents</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#license" id="toc-license">License</a></li>
</ul>
</nav>
<div class="date">Posted on Feb  7, 2023</div>
<p><a
href="https://github.com/stevana/property-based-testing-stateful-systems-tutorial/actions"><img
src="https://github.com/stevana/property-based-testing-stateful-systems-tutorial/workflows/CI/badge.svg"
alt="GitHub CI" /></a> <a
href="https://hackage.haskell.org/package/property-based-testing-stateful-systems-tutorial"><img
src="https://img.shields.io/hackage/v/property-based-testing-stateful-systems-tutorial.svg"
alt="Hackage" /></a></p>
<p>Property-based testing (PBT), i.e. generating random inputs and
checking some property of the output, of pure programs is an established
practice by now. It’s taught in introductory university classes and it’s
part of test suites in industry.</p>
<p>Most real world programs are not pure though, they are stateful.
While it’s often possible to structure your program in such a way that
the impure stuff is done in <code>main</code>, e.g. read the contents of
a file, and then passed on to a pure function, e.g. a parser, it’s not
always possible. Consider a long-running program that interacts with the
filesystem and with other programs over the network, e.g. some kind of
web service or a distributed database. It’s difficult to split such a
program up into doing a little bit of impure stuff at the start, then
hand it over to a pure function (which we can apply PBT on).</p>
<p>Given this it’s perhaps a bit surprising that there are relatively
few resources about applying PBT to stateful systems. This repository is
an attempt to close that gap and try to make PBT stateful systems more
common.</p>
<p>The goals we’d like to achieve are:</p>
<ul>
<li><p>Show how to test stateful (i.e. impure/monadic) programs using
property-based testing;</p></li>
<li><p>Show how we can do concurrent testing to help uncover problems
such as race conditions;</p></li>
<li><p>Show how we can build bigger systems in a modular way by applying
the property-based testing equivalent of integration and contract
tests;</p></li>
<li><p>Show how to use fault injection and so called simulation testing
to “end-to-end” test distributed systems;</p></li>
<li><p>Introduce the reader to related work and open problems in the
area along the way.</p></li>
</ul>
<p>In the interest of brevity, we assume that the reader already
has:</p>
<ul>
<li><p>Enough familiarity with Haskell to be able to read simple
programs, for example if you can follow along in the <em>Learn You a
Haskell for Great Good!</em> <a
href="http://learnyouahaskell.com/chapters">tutorial</a>, then you
should be fine;</p></li>
<li><p>Some experience with property-based testing of non-stateful
(i.e. pure) programs. For example as explained in the official
QuickCheck <a
href="http://www.cse.chalmers.se/~rjmh/QuickCheck/manual.html">manual</a>
or in the following <a
href="https://begriffs.com/posts/2017-01-14-design-use-quickcheck.html">tutorial</a>;</p></li>
<li><p>Basic knowledge of state machines (i.e. <a
href="https://en.wikipedia.org/wiki/Mealy_machine">Mealy</a> / <a
href="https://en.wikipedia.org/wiki/Moore_machine">Moore machines</a>
and <a
href="https://en.wikipedia.org/wiki/Finite-state_transducer">transducers</a>).</p></li>
</ul>
<p>Other than that this tutorial is striving to be as self-contained as
possibly as well as accessible to non-Haskell programmers.</p>
<h2 id="structure">Structure</h2>
<p>The tutorial is split up into five parts (so far), and each part has
the following structure:</p>
<ul>
<li>Motivation: explains why we are doing what we are about to do;</li>
<li>Plan: how we will do it;</li>
<li>Code: a concrete implementation of the idea (in case you get stuck
when trying to implement it yourself);</li>
<li>Discussion: common questions or objections;</li>
<li>Exercises: things the authors were to lazy to do, but they know how
to;</li>
<li>Problems: things the authors don’t know how to do (yet);</li>
<li>See also: links to further reading about the topic or related
topics;</li>
<li>Summary: the most important take away.</li>
</ul>
<p>The parts build upon each other. We start by modelling and testing a
simple counter using a state machine in part 1, we then reuse the same
state machine model to test the counter for thread-safety using
linearisability in part 2. In part 3 we will implement a queue and a web
service that uses said queue, the state machine model for the queue and
the real implementation of the queue will be contract tested to ensure
that the model is faithful to the implementation, subsequently while
testing the web service we will use the model in place of the real
queue. In part 4 we introduce fault injection to the queue allowing us
to test how the web service performs when its dependency fails. Finally,
in part 5, we combine all the above ideas in what, sometimes is called
simulation testing, to test a distributed system that uses replicated
state machines.</p>
<h2 id="table-of-contents">Table of contents</h2>
<ol type="1">
<li><a href="./docs/Part01SMTesting.md#readme">State machine
testing</a></li>
<li><a href="./docs/Part02ConcurrentSMTesting.md#readme">Concurrent
state machine testing with linearisability</a></li>
<li><a href="./docs/Part03SMContractTesting.md#readme">Integration tests
against state machine fakes and consumer-driven contract tests for the
fakes</a></li>
<li><a
href="./docs/Part04FaultInjection.md#readme">Fault-injection</a></li>
<li>Simulation testing</li>
</ol>
<h2 id="usage">Usage</h2>
<p>This repository contains literate Haskell code in <code>src</code>.
If you want to interact with it, install <a
href="https://www.haskell.org/ghcup/install/"><code>ghcup</code></a> and
then type <code>cabal repl</code>. Alternatively, if you are using the
<a href="https://nixos.org/download.html"><code>nix</code></a> package
manager, then running <code>nix-shell</code> in the root directory
should give you the right <code>ghc</code> version and all other
dependencies you might need.</p>
<p>The literate code is transformed into markdown using <a
href="https://pandoc.org/"><code>pandoc</code></a> in <a
href="./tools/generate_markdown.sh"><code>tools/generate_markdown.sh</code></a>
and the markdown is put inside the <a
href="./docs"><code>docs</code></a> directory for easier browsing.</p>
<p>The following is a link to the <a
href="./docs/Part01SMTesting.md#readme">first part</a> of the generate
markdown, at the end it will link to the second part and so on. Or you
can use the table of contents above or the <code>docs</code> directory
to jump to desired part straight away.</p>
<h2 id="contributing">Contributing</h2>
<p>Any feedback, suggestions for improvement or questions are most
welcome via the issue tracker!</p>
<p>See the <a
href="./.github/CONTRIBUTING.md"><code>CONTRIBUTING.md</code></a> file
for more detailed guidelines regarding contributing.</p>
<h2 id="license">License</h2>
<p>See the <a href="./LICENSE"><code>LICENSE</code></a> file.</p>
]]></description>
      <category>Testing</category>
    </item>

    <item>
      <title>Erlang's not about lightweight processes and message passing...</title>
      <link>https://stevana.github.io/erlangs_not_about_lightweight_processes_and_message_passing.html</link>
      <guid>https://stevana.github.io/erlangs_not_about_lightweight_processes_and_message_passing.html</guid>
      <pubDate>Wed, 18 Jan 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>Erlang's not about lightweight processes and message passing...</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#background" id="toc-background">Background</a></li>
<li><a href="#behaviours" id="toc-behaviours">Behaviours</a>
<ul>
<li><a href="#generic-server-behaviour"
id="toc-generic-server-behaviour">Generic server behaviour</a></li>
<li><a href="#event-manager-behaviour"
id="toc-event-manager-behaviour">Event manager behaviour</a></li>
<li><a href="#state-machine-behaviour"
id="toc-state-machine-behaviour">State machine behaviour</a></li>
<li><a href="#supervisor-behaviour"
id="toc-supervisor-behaviour">Supervisor behaviour</a></li>
<li><a href="#application-and-release-behaviours"
id="toc-application-and-release-behaviours">Application and release
behaviours</a></li>
</ul></li>
<li><a href="#how-behaviours-can-be-implemented"
id="toc-how-behaviours-can-be-implemented">How behaviours can be
implemented</a></li>
<li><a href="#correctness-of-behaviours"
id="toc-correctness-of-behaviours">Correctness of behaviours</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
<li><a href="#discussion" id="toc-discussion">Discussion</a></li>
</ul>
</nav>
<div class="date">Posted on Jan 18, 2023</div>
<p>I used to think that the big idea of Erlang is its lightweight
processes and message passing. Over the last couple of years I’ve
realised that there’s a bigger insight to be had, and in this post I’d
like to share it with you.</p>
<h2 id="background">Background</h2>
<p>Erlang has an interesting history. If I understand things correctly,
it started off as a Prolog library for building reliable distributed
systems, morphed into a Prolog dialect, before finally becoming a
language in its own right.</p>
<p>The goal seemed to have always been to solve the problem of building
reliable distributed systems. It was developed at Ericsson and used to
program their telephone switches. This was sometime in the 80s and 90s,
before internet use become widespread. I suppose they were already
dealing with “internet scale” traffic, i.e. hundreds of millions of
users, with stricter SLAs than most internet services provide today. So
in a sense they were ahead of their time.</p>
<p>In 1998 Ericsson decided to ban all use of Erlang<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.
The people responsible for developing it argued that if they were going
to ban it, then they might as well open source it. Which Ericsson did
and shortly after most of the team that created Erlang quit and started
their own company.</p>
<p>One of these people was Joe Armstrong, which also was one of the main
people behind the design and implementation of Erlang. The company was
called Bluetail and they got bought up a couple of times but in the end
Joe got fired in 2002.</p>
<p>Shortly after, still in 2002, Joe starts writing his PhD thesis at
the Swedish Institute of Computer Science (SICS). Joe was born 1950, so
he was probably 52 years old at this point. The topic of the thesis is
<em>Making reliable distributed systems in the presence of software
errors</em> and it was finished the year after in 2003.</p>
<p>It’s quite an unusual thesis in many ways. For starters, most theses
are written by people in their twenties with zero experience of
practical applications. Whereas in Joe’s case he has been working
professionally on this topic since the 80s, i.e. about twenty years. The
thesis contains no math nor theory, it’s merely a presentation of the
ideas that underpin Erlang and how they used Erlang to achieve the
original goal of building reliable distributed systems.</p>
<p>I highly commend reading his <a
href="http://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A9492&amp;dswid=-1166">thesis</a>
and forming your own opinion, but to me it’s clear that the big idea
there isn’t lightweight processes<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a> and message passing, but
rather the generic components which in Erlang are called
<em>behaviours</em>.</p>
<h2 id="behaviours">Behaviours</h2>
<p>I’ll first explain in more detail what behaviours are, and then I’ll
come back to the point that they are more important than the idea of
lightweight processes.</p>
<p>Erlang behaviours are like interfaces in, say, Java or Go. It’s a
collection of type signatures which can have multiple implementations,
and once the programmer provides such an implementation they get access
to functions written against that interface. To make it more concrete
here’s a contrived example in Go:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode go"><code class="sourceCode go"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">// The interface.</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> HasName <span class="kw">interface</span> <span class="op">{</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        Name<span class="op">()</span> <span class="dt">string</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">// A generic function written against the interface.</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">func</span> Greet<span class="op">(</span>n HasName<span class="op">)</span> <span class="op">{</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">.</span>Printf<span class="op">(</span><span class="st">&quot;Hello %s!</span><span class="ch">\n</span><span class="st">&quot;</span><span class="op">,</span> n<span class="op">.</span>Name<span class="op">())</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">// First implementation of the interface.</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> Joe <span class="kw">struct</span> <span class="op">{}</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="kw">func</span> <span class="op">(</span>_ <span class="op">*</span>Joe<span class="op">)</span> Name<span class="op">()</span> <span class="dt">string</span> <span class="op">{</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;Joe&quot;</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">// Second implementation of the interface.</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> Mike <span class="kw">struct</span> <span class="op">{}</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="kw">func</span> <span class="op">(</span>_ <span class="op">*</span>Mike<span class="op">)</span> Name<span class="op">()</span> <span class="dt">string</span> <span class="op">{</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&quot;Mike&quot;</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="kw">func</span> main<span class="op">()</span> <span class="op">{</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        joe <span class="op">:=</span> <span class="op">&amp;</span>Joe<span class="op">{}</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        mike <span class="op">:=</span> <span class="op">&amp;</span>Mike<span class="op">{}</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        Greet<span class="op">(</span>mike<span class="op">)</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        Greet<span class="op">(</span>joe<span class="op">)</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Running the above program will display:</p>
<pre><code>Hello Mike!
Hello Joe!</code></pre>
<p>This hopefully illustrates how <code>Greet</code> is generic in, or
parametrised by, the interface <code>HasName</code>.</p>
<h3 id="generic-server-behaviour">Generic server behaviour</h3>
<p>Next lets have a look at a more complicated example in Erlang taken
from Joe’s thesis (p. 136). It’s a key-value store where we can
<code>store</code> a key value pair or <code>lookup</code> the value of
a key, the <code>handle_call</code> part is the most interesting:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-module</span><span class="fu">(</span><span class="ch">kv</span><span class="fu">).</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="fu">behaviour(</span><span class="ch">gen_server</span><span class="fu">).</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">start</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">stop</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">lookup</span><span class="op">/</span><span class="dv">1</span><span class="fu">,</span> <span class="ch">store</span><span class="op">/</span><span class="dv">2</span><span class="fu">]).</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">init</span><span class="op">/</span><span class="dv">1</span><span class="fu">,</span> <span class="ch">handle_call</span><span class="op">/</span><span class="dv">3</span><span class="fu">,</span> <span class="ch">handle_cast</span><span class="op">/</span><span class="dv">2</span><span class="fu">,</span> <span class="ch">terminate</span><span class="op">/</span><span class="dv">2</span><span class="fu">]).</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">start()</span> <span class="op">-&gt;</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_server:start_link({</span><span class="ch">local</span><span class="fu">,</span><span class="ch">kv</span><span class="fu">},</span><span class="ch">kv</span><span class="fu">,</span><span class="ch">arg1</span><span class="fu">,[]).</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="fu">stop()</span> <span class="op">-&gt;</span> <span class="fu">gen_server:cast(</span><span class="ch">kv</span><span class="fu">,</span> <span class="ch">stop</span><span class="fu">).</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="fu">init(</span><span class="ch">arg1</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">io:format(</span><span class="st">&quot;Key-Value server starting~n&quot;</span><span class="fu">),</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="fu">dict:new()}.</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="fu">store(</span><span class="va">Key</span><span class="fu">,</span> <span class="va">Val</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_server:call(</span><span class="ch">kv</span><span class="fu">,</span> <span class="fu">{</span><span class="ch">store</span><span class="fu">,</span> <span class="va">Key</span><span class="fu">,</span> <span class="va">Val</span><span class="fu">}).</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="fu">lookup(</span><span class="va">Key</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">gen_server:call(</span><span class="ch">kv</span><span class="fu">,</span> <span class="fu">{</span><span class="ch">lookup</span><span class="fu">,</span> <span class="va">Key</span><span class="fu">}).</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call({</span><span class="ch">store</span><span class="fu">,</span> <span class="va">Key</span><span class="fu">,</span> <span class="va">Val</span><span class="fu">},</span> <span class="va">From</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="va">Dict1</span> <span class="op">=</span> <span class="fu">dict:store(</span><span class="va">Key</span><span class="fu">,</span> <span class="va">Val</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">),</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span><span class="ch">reply</span><span class="fu">,</span> <span class="ch">ack</span><span class="fu">,</span> <span class="va">Dict1</span><span class="fu">};</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call({</span><span class="ch">lookup</span><span class="fu">,</span> <span class="ch">crash</span><span class="fu">},</span> <span class="va">From</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span><span class="op">/</span><span class="dv">0</span><span class="fu">;</span> <span class="co">%% &lt;- deliberate error :-)</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call({</span><span class="ch">lookup</span><span class="fu">,</span> <span class="va">Key</span><span class="fu">},</span> <span class="va">From</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span><span class="ch">reply</span><span class="fu">,</span> <span class="fu">dict:find(</span><span class="va">Key</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">),</span> <span class="va">Dict</span><span class="fu">}.</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_cast(</span><span class="ch">stop</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">stop</span><span class="fu">,</span> <span class="ch">normal</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">}.</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="fu">terminate(</span><span class="va">Reason</span><span class="fu">,</span> <span class="va">Dict</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">io:format(</span><span class="st">&quot;K-V server terminating~n&quot;</span><span class="fu">).</span></span></code></pre></div>
<p>This is an implementation of the <code>gen_server</code>
behaviour/interface. Notice how <code>handle_call</code> updates the
state (<code>Dict</code>) in case of a <code>store</code> and
<code>lookup</code>s the key in the state. Once <code>gen_server</code>
is given this implementation it will provide a server which can handle
concurrent <code>store</code> and <code>lookup</code> requests,
similarly to how <code>Greet</code> provided the displaying
functionality.</p>
<p>At this point you might be thinking “OK, so what? Lots of programming
languages have interfaces…”. That’s true, but notice how
<code>handle_call</code> is completely sequential, i.e. all concurrency
is hidden away in the generic <code>gen_server</code> component. “Yeah,
but that’s just good engineering practice which can be done in any
language” you say. That’s true as well, but the thesis pushes this idea
quite far. It identifies six behaviours: <code>gen_server</code>,
<code>gen_event</code>, <code>gen_fsm</code>, <code>supervisor</code>,
<code>application</code>, and <code>release</code> and then says these
are enough to build reliable distributed systems. As a case study Joe
uses one of Ericsson’s telephone switches (p. 157):</p>
<blockquote>
<p>When we look at the AXD301 project in chapter 8, we will see that
there were 122 instances of gen_server, 36 instances of gen_event and 10
instances of gen_fsm. There were 20 supervisors and 6 applications. All
this is packaged into one release.</p>
</blockquote>
<p>Joe gives several arguments for why behaviour should be used
(pp. 157-158):</p>
<ol type="1">
<li><p>The application programmer only has to provide the part of the
code which defines the <em>semantics</em> (or “business logic”) of their
problem, while the <em>infrastructure</em> code is provided
automatically by the behaviour;</p></li>
<li><p>The application programmer writes sequential code, all
concurrency is hidden away in the behaviour;</p></li>
<li><p>Behaviours are written by experts, and based on years of
experience and represent “best practices”;</p></li>
<li><p>Easier for new team members to get started: business logic is
sequential, similar structure that they might have seen before
elsewhere;</p></li>
<li><p>If whole systems are implemented reusing a small set of
behaviours: as behaviour implementations improve the whole systems will
improve without requiring any code changes;</p></li>
<li><p>Sticking to only using behaviours enforces structure, which in
turn makes testing and formal verification much easier.</p></li>
</ol>
<p>We’ll come back to this last point about testing later.</p>
<h3 id="event-manager-behaviour">Event manager behaviour</h3>
<p>Lets come back to the behaviours we listed above first. We looked at
<code>gen_server</code>, but what are the others for? There’s
<code>gen_event</code> which is a generic event manager, which lets you
register event handlers that are then run when the event manager gets
messages associated with the handlers. Joe says this is useful for,
e.g., error logging and gives the following example of an simple logger
(p. 142):</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-module</span><span class="fu">(</span><span class="ch">simple_logger</span><span class="fu">).</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="fu">behaviour(</span><span class="ch">gen_event</span><span class="fu">).</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">start</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">stop</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">log</span><span class="op">/</span><span class="dv">1</span><span class="fu">,</span> <span class="ch">report</span><span class="op">/</span><span class="dv">0</span><span class="fu">]).</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">init</span><span class="op">/</span><span class="dv">1</span><span class="fu">,</span> <span class="ch">terminate</span><span class="op">/</span><span class="dv">2</span><span class="fu">,</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>         <span class="ch">handle_event</span><span class="op">/</span><span class="dv">2</span><span class="fu">,</span> <span class="ch">handle_call</span><span class="op">/</span><span class="dv">2</span><span class="fu">]).</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="kw">-define</span><span class="fu">(</span><span class="va">NAME</span><span class="fu">,</span> <span class="ch">my_simple_event_logger</span><span class="fu">).</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="fu">start()</span> <span class="op">-&gt;</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">case</span> <span class="fu">gen_event:start_link({</span><span class="ch">local</span><span class="fu">,</span> <span class="fu">?</span><span class="va">NAME</span><span class="fu">})</span> <span class="kw">of</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="va">Ret</span> <span class="op">=</span> <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="va">Pid</span><span class="fu">}</span> <span class="op">-&gt;</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">gen_event:add_handler(?</span><span class="va">NAME</span><span class="fu">,?</span><span class="va">MODULE</span><span class="fu">,</span><span class="ch">arg1</span><span class="fu">),</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>      <span class="va">Ret</span><span class="fu">;</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  <span class="va">Other</span> <span class="op">-&gt;</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    <span class="va">Other</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">end</span><span class="fu">.</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="fu">stop()</span> <span class="op">-&gt;</span> <span class="fu">gen_event:stop(?</span><span class="va">NAME</span><span class="fu">).</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="fu">log(</span><span class="va">E</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">gen_event:notify(?</span><span class="va">NAME</span><span class="fu">,</span> <span class="fu">{</span><span class="ch">log</span><span class="fu">,</span> <span class="va">E</span><span class="fu">}).</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="fu">report()</span> <span class="op">-&gt;</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_event:call(?</span><span class="va">NAME</span><span class="fu">,</span> <span class="fu">?</span><span class="va">MODULE</span><span class="fu">,</span> <span class="ch">report</span><span class="fu">).</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="fu">init(</span><span class="ch">arg1</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">io:format(</span><span class="st">&quot;Logger starting~n&quot;</span><span class="fu">),</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="fu">[]}.</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_event({</span><span class="ch">log</span><span class="fu">,</span> <span class="va">E</span><span class="fu">},</span> <span class="va">S</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="fu">trim([</span><span class="va">E</span><span class="fu">|</span><span class="va">S</span><span class="fu">])}.</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="fu">handle_call(</span><span class="ch">report</span><span class="fu">,</span> <span class="va">S</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span> <span class="va">S</span><span class="fu">,</span> <span class="va">S</span><span class="fu">}.</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="fu">terminate(</span><span class="ch">stop</span><span class="fu">,</span> <span class="va">_</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="ch">true</span><span class="fu">.</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="fu">trim([</span><span class="va">X1</span><span class="fu">,</span><span class="va">X2</span><span class="fu">,</span><span class="va">X3</span><span class="fu">,</span><span class="va">X4</span><span class="fu">,</span><span class="va">X5</span><span class="fu">|</span><span class="va">_</span><span class="fu">])</span> <span class="op">-&gt;</span> <span class="fu">[</span><span class="va">X1</span><span class="fu">,</span><span class="va">X2</span><span class="fu">,</span><span class="va">X3</span><span class="fu">,</span><span class="va">X4</span><span class="fu">,</span><span class="va">X5</span><span class="fu">];</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="fu">trim(</span><span class="va">L</span><span class="fu">)</span> <span class="op">-&gt;</span> <span class="va">L</span><span class="fu">.</span></span></code></pre></div>
<p>The interesting part is <code>handle_event</code>, <code>trim</code>
and <code>report</code>. Together they let the user log, keep track and
display the last five error messages.</p>
<h3 id="state-machine-behaviour">State machine behaviour</h3>
<p>The <code>gen_fsm</code> behavior has been renamed to
<code>gen_statem</code> (for state machine) since thesis was written.
It’s very similar to <code>gen_server</code>, but more geared towards
implementing protocols, which often are specified as state machines. I
believe any <code>gen_server</code> can be implemented as a
<code>gen_statem</code> and vice versa so we won’t go into the details
of <code>gen_statem</code>.</p>
<h3 id="supervisor-behaviour">Supervisor behaviour</h3>
<p>The next interesting behavior is <code>supervisor</code>. Supervisors
are processes which sole job is to make sure that other processes are
healthy and doing their job. If a supervised process fails then the
supervisor can restart it according to some predefined strategy. Here’s
an example due to Joe (p. 148):</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-module</span><span class="fu">(</span><span class="ch">simple_sup</span><span class="fu">).</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="fu">behaviour(</span><span class="ch">supervisor</span><span class="fu">).</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">-export</span><span class="fu">([</span><span class="ch">start</span><span class="op">/</span><span class="dv">0</span><span class="fu">,</span> <span class="ch">init</span><span class="op">/</span><span class="dv">1</span><span class="fu">]).</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">start()</span> <span class="op">-&gt;</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">supervisor:start_link({</span><span class="ch">local</span><span class="fu">,</span> <span class="ch">simple_supervisor</span><span class="fu">},</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">?</span><span class="va">MODULE</span><span class="fu">,</span> <span class="ch">nil</span><span class="fu">).</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">init(</span><span class="va">_</span><span class="fu">)</span> <span class="op">-&gt;</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{</span><span class="ch">ok</span><span class="fu">,</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">{{</span><span class="ch">one_for_one</span><span class="fu">,</span> <span class="dv">5</span><span class="fu">,</span> <span class="dv">1000</span><span class="fu">},</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">[</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>   <span class="fu">{</span><span class="ch">packet</span><span class="fu">,</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>     <span class="fu">{</span><span class="ch">packet_assembler</span><span class="fu">,</span> <span class="ch">start</span><span class="fu">,</span> <span class="fu">[]},</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>     <span class="ch">permanent</span><span class="fu">,</span> <span class="dv">500</span><span class="fu">,</span> <span class="ch">worker</span><span class="fu">,</span> <span class="fu">[</span><span class="ch">packet_assembler</span><span class="fu">]},</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>   <span class="fu">{</span><span class="ch">server</span><span class="fu">,</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>     <span class="fu">{</span><span class="ch">kv</span><span class="fu">,</span> <span class="ch">start</span><span class="fu">,</span> <span class="fu">[]},</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>     <span class="ch">permanent</span><span class="fu">,</span> <span class="dv">500</span><span class="fu">,</span> <span class="ch">worker</span><span class="fu">,</span> <span class="fu">[</span><span class="ch">kv</span><span class="fu">]},</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>   <span class="fu">{</span><span class="ch">logger</span><span class="fu">,</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>     <span class="fu">{</span><span class="ch">simple_logger</span><span class="fu">,</span> <span class="ch">start</span><span class="fu">,</span> <span class="fu">[]},</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>     <span class="ch">permanent</span><span class="fu">,</span> <span class="dv">500</span><span class="fu">,</span> <span class="ch">worker</span><span class="fu">,</span> <span class="fu">[</span><span class="ch">simple_logger</span><span class="fu">]}]}}.</span></span></code></pre></div>
<p>The <code>{one_for_one, 5, 1000}</code> is the restart strategy. It
says that if one of the supervised processes
(<code>packet_assembler</code>, <code>kv</code>, and
<code>simple_logger</code>) fail then only restart the failing process
(<code>one_for_one</code>). If the supervisor needs to restart more than
<code>5</code> times in <code>1000</code> seconds then the supervisor
itself should fail.</p>
<p>The <code>permanent, 500, worker</code> part means that this is a
worker process which should be permanently kept alive and its given 500
milliseconds to gracefully stop what it’s doing in case the supervisor
wants to restart it.</p>
<p>“Why would the supervisor want to restart it if it’s not dead
already?”, one might wonder. Well, there are other restart strategies
than <code>one_for_one</code>. For example, <code>one_for_all</code>
where if one process fails then the supervisor restarts all of its
children.</p>
<p>If we also consider that supervisors can supervise supervisors, which
are not necessarily running on the same computer, then I hope that you
get an idea of how powerful this behaviour can be. And, no, this isn’t
“just Kubernetes”, because it’s at the thread/lightweight process level
rather than docker container level.</p>
<p>The idea for supervisors and their restart strategies comes from the
observation that often a restart appears to fix the problem, as captured
in the <em>Have You Tried Turning It Off And On Again?</em> sketches
from IT Crowd.</p>
<p>Knowing that failing processes will get restarted coupled with Jim
Gray’s idea of failing fast, that’s either produce the output according
to the specification or signal failure and stop operating, leads to
Joe’s slogan: “Let it crash!” (p. 107). Another way to think of it is
that a program should only express its “happy path”, should anything go
wrong on its happy way it should crash, rather than trying to be clever
about it and try to fix the problem (potentially making it worse), and
another program higher up the supervisor tree will handle it.</p>
<p>Supervisors and the “let it crash” philosophy, appear to produce
reliable systems. Joe uses the Ericsson AXD301 telephone switch example
again (p. 191):</p>
<blockquote>
<p>Evidence for the long-term operational stability of the system had
also not been collected in any systematic way. For the Ericsson AXD301
the only information on the long-term stability of the system came from
a power-point presentation showing some figures claiming that a major
customer had run an 11 node system with a 99.9999999% reliability,
though how these figure had been obtained was not documented.</p>
</blockquote>
<p>To put this in perspective, five nines (99.999%) reliability is
considered good (5.26 minutes of downtime per year). “59% of Fortune 500
companies experience a minimum of 1.6 hours of downtime per week”,
according to some <a
href="https://courseware.cutm.ac.in/wp-content/uploads/2020/06/Assessing-the-Financial-Impact-of-Downtime-UK.pdf">report</a>
from a biased company. Notice per <em>year</em> vs per <em>week</em>,
but as we don’t know how either reliability numbers are obtained its
probably safe to assume that the truth is somewhere in the middle –
still a big difference, but not 31.56 milliseconds (nine nines) of
downtime per year vs 1.6 hours of downtime per week.</p>
<h3 id="application-and-release-behaviours">Application and release
behaviours</h3>
<p>I’m not sure if <code>application</code> and <code>release</code>
technically are behaviours, i.e. interfaces. They are part of the same
chapter as the other behaviours in the thesis and they do provide a
clear structure which is a trait of the other behaviours though, so
we’ll include them in the discussion.</p>
<p>So far we’ve presented behaviours from the bottom up. We started with
“worker” behaviours <code>gen_server</code>, <code>gen_statem</code> and
<code>gen_event</code> which together capture the semantics of our
problem. We then saw how we can define <code>supervisor</code> trees
whose children are other supervisor trees or workers, to deal with
failures and restarts.</p>
<p>Next level up is an <code>application</code> which consists of a
supervisor tree together with everything else we need to deliver a
particular application.</p>
<p>A system can consist of several <code>application</code> and that’s
where the final “behaviour” comes in. A <code>release</code> packages up
one or more applications. They also contain code to handle upgrades. If
the upgrade fails, it must be able to rollback to the previous stable
state.</p>
<h2 id="how-behaviours-can-be-implemented">How behaviours can be
implemented</h2>
<p>I hope that by now I’m managed to convince you that it’s not actually
the lightweight processes and message passing by themselves that make
Erlang great for building reliable systems.</p>
<p>At best one might be able to claim that lightweight processes and
supervisors are the key mechanisms at play<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>,
but I think it would be more honest to recognise the structure that
behaviours provide and how that ultimately leads to reliable
software.</p>
<p>I’ve not come across any other language, library, or framework which
provides such relatively simple building blocks that compose into big
systems like the AXD301 (“over a million lines of Erlang code”,
p. 167).</p>
<p>This begs the question: why aren’t language and library designers
stealing the structure behind Erlang’s behaviours, rather than copying
the ideas of lightweight processes and message passing?</p>
<p>Let’s take a step back. We said earlier that behaviours are
interfaces and many programming languages have interfaces. How would we
go about starting to implement behaviours in other languages?</p>
<p>Lets start with <code>gen_server</code>. I like to think its
interface signature as being:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="dt">Input</span> <span class="ot">-&gt;</span> <span class="dt">State</span> <span class="ot">-&gt;</span> (<span class="dt">State</span>, <span class="dt">Output</span>)</span></code></pre></div>
<p>That’s it takes some input, its current state and produces a pair of
the new updated state and an output.</p>
<p>How do we turn this sequential signature into something that can
handle concurrent requests? One way would be to fire up a HTTP server
which transforms requests into <code>Input</code>s and puts them on a
queue, have an event loop which pops inputs from the queue and feeds it
to the sequential implementation, then writing the output back to the
client response. It wouldn’t be difficult to generalise this to be able
to handle multiple <code>gen_server</code>s at the same time, by giving
each a name and let the request include the name in addition to the
input.</p>
<p><code>gen_event</code> could be implemented by allowing registration
of callbacks to certain types of event on the queue.</p>
<p><code>supervisor</code>s is more interesting, one simple way to think
of it is: when we feed the <code>gen_server</code> function the next
input from the queue, we wrap that call in an exception handler, and
should it throw we notify its supervisor. It gets a bit more complicated
if the supervisor is not running on the same computer as the
<code>gen_server</code>.</p>
<p>I haven’t thought about <code>application</code> and
<code>release</code>s much yet, but given that configuration, deployment
and upgrades are difficult problems they seem important.</p>
<h2 id="correctness-of-behaviours">Correctness of behaviours</h2>
<p>Writing a post solely about stealing from Erlang doesn’t seem fair,
even though it’s the right thing to do, so I’d like to finish off with
how we can build upon the insights of Joe and the Erlang community.</p>
<p>I’ve been interesting in testing for a while now. Most recently I’ve
been looking into <a
href="https://github.com/stevana/property-based-testing-stateful-systems-tutorial">simulation
testing</a> distributed systems à la <a
href="https://www.youtube.com/watch?v=4fFDFbi3toc">FoundationDB</a>.</p>
<p>Simulation testing in a nutshell is running your system in a
simulated world, where the simulation has full control over which
messages get sent when over the network.</p>
<p>FoundationDB built their own programming language, or dialect of C++
with actors, in order do the simulation testing. Our team seemed to be
able to get quite far with merely using state machines of type:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="dt">Input</span> <span class="ot">-&gt;</span> <span class="dt">State</span> <span class="ot">-&gt;</span> (<span class="dt">State</span>, [<span class="dt">Output</span>])</span></code></pre></div>
<p>where <code>[Output]</code> is a sequence of outputs.</p>
<p>The idea being that the simulator keeps track of a priority queue of
messages sorted by their arrival time, it pops a message, advances the
clock to the arrival time of that message, feeds the message to the
receiving state machine, generates new arrival times for all output
messages and puts them back into the priority queue, rinse and repeat.
As long as everything is deterministic and the arrival times are
generated using a seed we can explore many different interleavings and
get reproducible failures. It’s also much faster than Jepsen, because
messaging is done in-memory and we advance the clock to the arrival
time, thereby triggering any timeouts without having to wait for
them.</p>
<p>We used to say that programs of this state machine type where written
in “network normal form”, and conjectured that every program which can
receive and send stuff over the network can be refactored into this
shape<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>. Even if we had a proof, “network
normal form” always felt a bit arbitrary. But then I read Joe’s thesis
and realised that <code>gen_server</code> and <code>gen_statem</code>
basically have the same type, so I stopped being concerned about it. As
I think that if a structure is found to be useful by different people,
then it’s usually a sign that it isn’t arbitrary.</p>
<p>Anyway, in, at least, one of Joe’s <a
href="https://youtu.be/cNICGEwmXLU?t=1439">talks</a> he mentions how
difficult it’s to correctly implement distributed leader election.</p>
<p>I believe this is a problem that would be greatly simplified by
having access to a simulator. A bit like I’d imagine having access to a
wind tunnel would make building an airplane easier. Both lets you test
your system under extreme conditions, such as unreliable networking or
power loss, before they happen in “production”. Furthermore, this
simulator can be generic in, or parametrised by, behaviours. Which means
that the developer gets it for free while the complexity of the
simulator is hidden away, just like the concurrent code of
<code>gen_server</code>!</p>
<p>FoundationDB is a good example of simulation testing working, as
witnessed by this <a
href="https://twitter.com/aphyr/status/405017101804396546">tweet</a>
where somebody asked Kyle “aphyr” Kingsbury to Jepsen test
FoundationDB:</p>
<blockquote>
<p>“haven’t tested foundation[db] in part because their testing appears
to be waaaay more rigorous than mine.”</p>
</blockquote>
<p>Formal verification is also made easier if the program is written a
state machine. Basically all of Lamport’s model checking <a
href="https://www.microsoft.com/en-us/research/publication/computation-state-machines/">work</a>
with TLA+ assumes that the specification is a state machine. Also more
recently Kleppmann has <a
href="https://lawrencecpaulson.github.io/2022/10/12/verifying-distributed-systems-isabelle.html">shown</a>
how to exploit the state machine structure to do proof by (structural)
induction to solve the state explosion problem.</p>
<p>So there you have it, we’ve gone full circle. We started by taking
inspiration from Joe and Erlang’s behaviours, and ended up using the
structure of the <code>gen_server</code> behaviour to make it easier to
solve a problem that Joe used to have.</p>
<h2 id="contributing">Contributing</h2>
<p>There are a bunch of related ideas that I have started working
on:</p>
<ul>
<li>Stealing ideas from Martin Thompson’s work on the LMAX Disruptor and
<a href="https://github.com/real-logic/aeron">aeron</a> to <a
href="https://github.com/stevana/pipelined-state-machines">make</a> a
fast event loop, on top of which the behaviours run;</li>
<li>Enriching the state machine type with <a
href="https://github.com/stevana/coroutine-state-machines">async
I/O</a>;</li>
<li>How to implement <a
href="https://github.com/stevana/supervised-state-machines">supervisors</a>
in more detail;</li>
<li>Hot code <a
href="https://github.com/stevana/hot-swapping-state-machines">swapping</a>
of state machines.</li>
</ul>
<p>Feel free to get in touch, if you find any of this interesting and
would like to get involved, or if you have have comments, suggestions or
questions.</p>
<h2 id="see-also">See also</h2>
<ul>
<li>Chapter 6.1 on behaviours in Joe Armstrong’s <a
href="http://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A9492&amp;dswid=-1166">thesis</a>,
p. 129;</li>
<li><a
href="https://www.erlang.org/doc/design_principles/des_princ.html">OTP
design principles</a>;</li>
<li>The documentation for behaviours:
<ul>
<li><a
href="https://www.erlang.org/doc/man/gen_server.html"><code>gen_server</code></a>;</li>
<li><a
href="https://www.erlang.org/doc/man/gen_event.html"><code>gen_event</code></a>;</li>
<li><a
href="https://www.erlang.org/doc/man/gen_statem.html"><code>gen_statem</code></a>;</li>
<li><a
href="https://www.erlang.org/doc/man/supervisor.html"><code>supervisor</code></a>;</li>
<li><a
href="https://www.erlang.org/doc/man/application.html"><code>application</code></a>;</li>
<li><a
href="https://www.erlang.org/doc/design_principles/release_structure.html">release</a>.</li>
</ul></li>
<li><a href="https://youtube.com/watch?v=7erJ1DV_Tlo">Hewitt, Meijer and
Szyperski: The Actor Model (everything you wanted to know, but were
afraid to ask)</a> (2012);</li>
<li>Erlang the <a
href="https://www.youtube.com/watch?v=xrIjfIjssLE">movie</a>
(1990);</li>
<li><a href="https://www.youtube.com/watch?v=cNICGEwmXLU">Systems that
run forever self-heal and scale</a> by Joe Armstrong (Strange Loop,
2013);</li>
<li><a href="https://www.youtube.com/watch?v=TTM_b7EJg5E">The Do’s and
Don’ts of Error Handling</a> by Joe Armstrong (GOTO, 2018);</li>
<li><a href="https://ferd.ca/the-zen-of-erlang.html">The Zen of
Erlang</a> by Fred Hebert (2016);</li>
<li><a
href="https://ferd.ca/the-hitchhiker-s-guide-to-the-unexpected.html">The
Hitchhiker’s Guide to the Unexpected</a> by Fred Hebert (2018);</li>
<li><a href="https://www.hpl.hp.com/techreports/tandem/TR-85.7.pdf">Why
Do Computers Stop and What Can Be Done About It?</a> by Jim Gray
(1985);</li>
<li>The supervision trees chapter of <a
href="https://adoptingerlang.org/docs/development/supervision_trees/"><em>Adopting
Erlang</em></a> (2019);</li>
<li>“If there’s one thing I’d say to the Erlang folks, it’s you got the
stuff right from a high-level, but you need to invest in your messaging
infrastructure so it’s super fast, super efficient and obeys all the
right properties to let this stuff work really well.” <a
href="https://youtu.be/OqsAGFExFgQ?t=2532">quote</a> by Martin Thompson
(Functional Conf, 2017).</li>
</ul>
<h2 id="discussion">Discussion</h2>
<ul>
<li><a href="https://news.ycombinator.com/item?id=34545061">Hacker
News</a></li>
<li><a
href="https://lobste.rs/s/7dguth/erlang_s_not_about_lightweight_processes">lobste.rs</a></li>
<li><a
href="https://old.reddit.com/r/programming/comments/10mt6hz/erlangs_not_about_lightweight_processes_and/">r/programming</a></li>
<li><a
href="https://old.reddit.com/r/haskell/comments/10mgd0a/erlangs_not_about_lightweight_processes_and/">r/haskell</a></li>
<li><a
href="https://old.reddit.com/r/erlang/comments/10g0zbg/erlangs_not_about_lightweight_processes_and/">r/erlang</a></li>
<li><a
href="https://elixirforum.com/t/erlangs-not-about-lightweight-processes-and-message-passing/53484/7">Elixir
Forum</a></li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>From Joe Armstrong’s thesis (p. 6):</p>
<blockquote>
<p>In February 1998 Erlang was banned for new product development within
Ericsson—the main reason for the ban was that Ericsson wanted to be a
consumer of sodware technologies rather than a producer.</p>
</blockquote>
<p>From Bjarne Däcker’s thesis (2000, p. 37):</p>
<blockquote>
<p>In February 1998, Erlang was banned within Ericsson Radio AB (ERA)
for new product projects aimed for external customers because:</p>
<p>“The selection of an implementation language implies a more long-term
commitment than selection of processors and OS, due to the longer life
cycle of implemented products. Use of a proprietary language, implies a
continued effort to maintain and further develop the support and the
development environment. It further implies that we cannot easily
benefit from, and find synergy with, the evolution following the large
scale deployment of globally used languages.”</p>
</blockquote>
<p>Joe also says, in this <a href="https://vimeo.com/97329186">talk</a>
(34:30), that there were two reasons for Erlang getting banned: 1) that
it wasn’t Java, and 2) that it wasn’t C++.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>It’s a common misconception is that Erlang is about
actors.</p>
<p>The actor model first presented in <a
href="https://www.ijcai.org/Proceedings/73/Papers/027B.pdf"><em>A
Universal Modular Actor Formalism for Artificial Intelligence</em></a>
by Carl Hewitt, Peter Bishop, Richard Steiger (1973) and refined by
others over time, e.g. see Irene Greif’s <a
href="https://dspace.mit.edu/handle/1721.1/57710">thesis</a> (1975) or
Gul Agha’s <a
href="https://dspace.mit.edu/handle/1721.1/6952">thesis</a> (1985).</p>
<p>Erlang first appeard later in 1986, but the Erlang developers were <a
href="https://erlang.org/pipermail/erlang-questions/2014-June/079794.html">not
aware</a> of the actor model. In fact Robert Virding, one of the
original Erlang designers, <a
href="https://erlang.org/pipermail/erlang-questions/2014-June/079865.html">claims</a>
that knowing about the actor model might even have slowed them down.</p>
<p>Carl Hewitt has written a paper called <a
href="https://arxiv.org/abs/1008.1459"><em>Actor Model of Computation:
Scalable Robust Information Systems</em></a> (2015) which documents the
differences between Erlang’s processes and the actor model.<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Scala’s Akka seems to be of this opinion. They got
something they call “actors”, not to be confused with the actor model as
per footnote 1, and obligatory supervisors trees. They don’t appear to
have any analogues of the other Erlang behaviours though.</p>
<p>Confusingly Akka has a concept called <a
href="https://doc.akka.io/docs/akka/current/general/actors.html#behavior">“behavior”</a>,
but it has nothing to do with Erlang behaviours.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The intuition being that since every program using the
state monad can be rewritten to a normal form where a single
<code>read</code>/<code>get</code> followed by a single
<code>write</code>/<code>put</code>, it seems reasonable to assume that
something similar would work for <code>recv</code> and <code>send</code>
over the network. I forget the reference for the state monad normal
form, either Plotkin and Power or Uustalu?<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></description>
      <category>Development</category>
    </item>

    <item>
      <title>Working with binary data</title>
      <link>https://stevana.github.io/working_with_binary_data.html</link>
      <guid>https://stevana.github.io/working_with_binary_data.html</guid>
      <pubDate>Wed, 11 Jan 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>Towards human-readable binary encodings</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#erlangs-bit-syntax" id="toc-erlangs-bit-syntax">Erlang’s
bit syntax</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
<li><a href="#extending-erlangs-bit-syntax"
id="toc-extending-erlangs-bit-syntax">Extending Erlang’s bit syntax</a>
<ul>
<li><a href="#in-place-updates" id="toc-in-place-updates">In-place
updates</a></li>
<li><a href="#on-disk-data-structures"
id="toc-on-disk-data-structures">On-disk data structures</a></li>
<li><a href="#zero-copy" id="toc-zero-copy">Zero-copy</a></li>
<li><a href="#backward--and-forward-compatiability-and-migrations"
id="toc-backward--and-forward-compatiability-and-migrations">Backward-
and forward-compatiability and migrations</a></li>
<li><a href="#compression" id="toc-compression">Compression</a></li>
<li><a href="#checksums" id="toc-checksums">Checksums</a></li>
<li><a href="#validation" id="toc-validation">Validation</a></li>
<li><a href="#protocols" id="toc-protocols">Protocols</a></li>
<li><a href="#pandoc-for-binary-encodings"
id="toc-pandoc-for-binary-encodings">Pandoc for binary
encodings</a></li>
</ul></li>
<li><a href="#discussion" id="toc-discussion">Discussion</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
</ul>
</nav>
<div class="date">Posted on Jan 11, 2023</div>
<p>Can we make binary encodings “human-readable”? This post explores
this question by means of implementing a library inspired by Erlang’s
bit syntax.</p>
<h2 id="motivation">Motivation</h2>
<p>JSON is probably the most commonly used format for serialising data
today. A frequent argument for using it is that JSON is
human-readable.</p>
<p>What does that mean exactly? I suppose that people usually mean two
things. First, it’s less verbose than XML, making it easier to read.
Most people would probably still call XML human-readable, but arguebly
less so than JSON. Second, it’s easier to read than binary encodings
produced by MessagePack, ASN.1 or Protobuf, etc. For example, the JSON
string <code>"foo"</code> is represented by the following byte sequence
when using MessagePack:</p>
<pre><code>                 +------------ A string of length 3 consisting of ...
                 |  +--------- ... the character &#39;f&#39;, following by ...
                 |  |  +--+--- ... two &#39;o&#39; characters.
                 |  |  |  |
                 v  v  v  v
                 a3 66 6f 6f</code></pre>
<p>If we were to open a file with the above bytes or echo them to the
terminal we’d see <code>£foo</code>. Which, while one character
shorter<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> than the JSON string, is starting to
become unreadable already and it will become worse once the JSON object
is more complicated.</p>
<p>It’s worth noting that all serialised data ends up being bytes once
on disk or sent over the network. So in a sense one could argue that the
reason JSON is human-readable, is because these bytes get displayed as
ASCII or UTF-8 by our editors and the standard terminal utilities.
Another way to think about it is that ASCII and UTF-8 are encodings as
well, which would be unreadable without tool support. This isn’t a new
argument, people like <a
href="https://youtu.be/ieEaaofM7uU?list=PL_aCdZH3eJJVki0YqHbJtqZKSmcbXH0jP&amp;t=28">Joe
Armstrong</a> and <a href="https://youtu.be/qDhTjE0XmkE?t=2280">Martin
Thompson</a> have separately and on <a
href="https://youtu.be/rQIE22e0cW8?t=2003">multiple</a> occasions
pointed this out. Both stress that we are <a
href="https://youtu.be/bzDAYlpSbrM?t=1481">wasting</a> massive amounts
of CPU cycles on parsing JSON.</p>
<p>It’s not just that it’s less space efficient, as we saw with
<code>"foo"</code> vs <code>£foo</code>, it’s also because with JSON we
need to inspect every single character after the first <code>"</code> in
order to determine when the string ends, i.e. finding the closing
<code>"</code>. Whereas in, for example, the MessagePack case the length
of the string is encoded in the <code>a3</code> byte so we can jump
forward and just copy the three bytes (without looking at them). Joe
calls this <em>reconstructing</em> as opposed to parsing.</p>
<p>So if JSON is merely human-readable because of our application-level
tooling, this raises the question: what would it take to make binary
encodings “human-readable”?</p>
<p>For starters I think we’d need to make it easier to work with binary
data in our programming languages. I believe Erlang’s bit syntax, which
lets us do bit-level pattern-matching, is a good example of what better
language support for working with binary data looks like. Even though
Erlang’s way ahead most programming languages on this front, there are
important use cases which are not possible to express efficiently using
bit syntax though, e.g. in-place updates, leaving more to be
desired.</p>
<p>In the rest of this post we’ll have first have a look at how Erlang’s
bit syntax works, then we’ll turn to its shortcomings and try to start
addressing them by means of implementing a library.</p>
<h2 id="erlangs-bit-syntax">Erlang’s bit syntax</h2>
<p>Erlang has a feature called bit syntax which allows the user to
encode and decode data at the bit-level. Here’s an example, where we
encode three integers into two bytes:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="op">&gt;</span>​ <span class="va">Red</span> <span class="op">=</span> <span class="dv">2</span><span class="fu">.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="op">&gt;</span>​ <span class="va">Green</span> <span class="op">=</span> <span class="dv">61</span><span class="fu">.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="dv">61</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span><span class="op">&gt;</span>​ <span class="va">Blue</span> <span class="op">=</span> <span class="dv">20</span><span class="fu">.</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span><span class="op">&gt;</span>​ <span class="va">Mem</span> <span class="op">=</span> <span class="op">&lt;&lt;</span><span class="va">Red</span><span class="fu">:</span><span class="dv">5</span><span class="fu">,</span> <span class="va">Green</span><span class="fu">:</span><span class="dv">6</span><span class="fu">,</span> <span class="va">Blue</span><span class="fu">:</span><span class="dv">5</span><span class="op">&gt;&gt;</span><span class="fu">.</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;&lt;</span><span class="dv">23</span><span class="fu">,</span><span class="dv">180</span><span class="op">&gt;&gt;</span></span></code></pre></div>
<p>Normally, even the smallest integer takes up one byte
(e.g. <code>char</code> in C or <code>Int8</code> in Haskell) but
Erlang’s bit syntax lets us encode, e.g., <code>Red</code> using only 5
bits (rather than the default 8 bits) and thus we can fit all three
integers in <span class="math inline">5 + 6 + 5 = 16</span> bits or two
bytes.</p>
<p>We can also pattern match at the bit-level using sizes to get our
integers back:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span><span class="op">&gt;</span>​ <span class="op">&lt;&lt;</span><span class="va">R1</span><span class="fu">:</span><span class="dv">5</span><span class="fu">,</span> <span class="va">G1</span><span class="fu">:</span><span class="dv">6</span><span class="fu">,</span> <span class="va">B1</span><span class="fu">:</span><span class="dv">5</span><span class="op">&gt;&gt;</span> <span class="op">=</span> <span class="va">Mem</span><span class="fu">.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;&lt;</span><span class="dv">23</span><span class="fu">,</span><span class="dv">180</span><span class="op">&gt;&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span><span class="op">&gt;</span>​ <span class="va">R1</span><span class="fu">.</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span><span class="op">&gt;</span>​ <span class="va">G1</span><span class="fu">.</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="dv">61</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="dv">8</span><span class="op">&gt;</span>​ <span class="va">B1</span><span class="fu">.</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span></span></code></pre></div>
<p>For larger integer types, e.g. <code>0x12345678 :: Int32</code>, we
can also specify the byte order or <a
href="https://en.wikipedia.org/wiki/Endianness">endianness</a>:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="op">&gt;</span>​ <span class="fu">{</span><span class="op">&lt;&lt;</span><span class="bn">16#12345678</span><span class="fu">:</span><span class="dv">32</span><span class="op">/</span><span class="ch">big</span><span class="op">&gt;&gt;</span><span class="fu">,</span><span class="op">&lt;&lt;</span><span class="bn">16#12345678</span><span class="fu">:</span><span class="dv">32</span><span class="op">/</span><span class="ch">little</span><span class="op">&gt;&gt;</span><span class="fu">,</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>​<span class="op">&lt;&lt;</span><span class="bn">16#12345678</span><span class="fu">:</span><span class="dv">32</span><span class="op">/</span><span class="ch">native</span><span class="op">&gt;&gt;</span><span class="fu">,</span><span class="op">&lt;&lt;</span><span class="bn">16#12345678</span><span class="fu">:</span><span class="dv">32</span><span class="op">&gt;&gt;</span><span class="fu">}.</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="op">&lt;&lt;</span><span class="dv">18</span><span class="fu">,</span><span class="dv">52</span><span class="fu">,</span><span class="dv">86</span><span class="fu">,</span><span class="dv">120</span><span class="op">&gt;&gt;</span><span class="fu">,</span><span class="op">&lt;&lt;</span><span class="dv">120</span><span class="fu">,</span><span class="dv">86</span><span class="fu">,</span><span class="dv">52</span><span class="fu">,</span><span class="dv">18</span><span class="op">&gt;&gt;</span><span class="fu">,</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;&lt;</span><span class="dv">120</span><span class="fu">,</span><span class="dv">86</span><span class="fu">,</span><span class="dv">52</span><span class="fu">,</span><span class="dv">18</span><span class="op">&gt;&gt;</span><span class="fu">,</span><span class="op">&lt;&lt;</span><span class="dv">18</span><span class="fu">,</span><span class="dv">52</span><span class="fu">,</span><span class="dv">86</span><span class="fu">,</span><span class="dv">120</span><span class="op">&gt;&gt;</span><span class="fu">}</span></span></code></pre></div>
<p>For a slightly larger example, here’s pattern-matching on an IP
datagram of IP protocol version 4:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode erlang"><code class="sourceCode erlang"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">-define</span>​<span class="fu">(</span><span class="va">IP_VERSION</span><span class="fu">,</span> <span class="dv">4</span><span class="fu">).</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>​<span class="op">-</span><span class="ch">define</span>​<span class="fu">(</span><span class="va">IP_MIN_HDR_LEN</span><span class="fu">,</span> <span class="dv">5</span><span class="fu">).</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">...</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="va">DgramSize</span> <span class="op">=</span> ​<span class="ch">byte_size</span>​<span class="fu">(</span><span class="va">Dgram</span><span class="fu">),</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>​<span class="ch">case</span>​ <span class="va">Dgram</span> ​<span class="ch">of</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="op">&lt;&lt;</span><span class="fu">?</span><span class="va">IP_VERSION</span><span class="fu">:</span><span class="dv">4</span><span class="fu">,</span> <span class="va">HLen</span><span class="fu">:</span><span class="dv">4</span><span class="fu">,</span> <span class="va">SrvcType</span><span class="fu">:</span><span class="dv">8</span><span class="fu">,</span> <span class="va">TotLen</span><span class="fu">:</span><span class="dv">16</span><span class="fu">,</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="va">ID</span><span class="fu">:</span><span class="dv">16</span><span class="fu">,</span> <span class="va">Flags</span><span class="fu">:</span><span class="dv">3</span><span class="fu">,</span> <span class="va">FragOff</span><span class="fu">:</span><span class="dv">13</span><span class="fu">,</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">TTL</span><span class="fu">:</span><span class="dv">8</span><span class="fu">,</span> <span class="va">Proto</span><span class="fu">:</span><span class="dv">8</span><span class="fu">,</span> <span class="va">HdrChkSum</span><span class="fu">:</span><span class="dv">16</span><span class="fu">,</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">SrcIP</span><span class="fu">:</span><span class="dv">32</span><span class="fu">,</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="va">DestIP</span><span class="fu">:</span><span class="dv">32</span><span class="fu">,</span> <span class="va">RestDgram</span><span class="op">/</span><span class="ch">binary</span><span class="op">&gt;&gt;</span> ​<span class="ch">when</span>​ <span class="va">HLen</span> <span class="op">&gt;=</span> <span class="dv">5</span><span class="fu">,</span> <span class="dv">4</span><span class="op">*</span><span class="va">HLen</span> <span class="op">=&lt;</span> <span class="va">DgramSize</span> <span class="op">-&gt;</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">OptsLen</span> <span class="op">=</span> <span class="dv">4</span><span class="op">*</span><span class="fu">(</span><span class="va">HLen</span> <span class="op">-</span> <span class="fu">?</span><span class="va">IP_MIN_HDR_LEN</span><span class="fu">),</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;&lt;</span><span class="va">Opts</span><span class="fu">:</span><span class="va">OptsLen</span><span class="op">/</span><span class="ch">binary</span><span class="fu">,</span><span class="va">Data</span><span class="op">/</span><span class="ch">binary</span><span class="op">&gt;&gt;</span> <span class="op">=</span> <span class="va">RestDgram</span><span class="fu">,</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="fu">...</span></span></code></pre></div>
<p>Note how we can match on the header length, <code>HLen</code>, and
later use the value of that match as the size when pattern matching on
later values.</p>
<h2 id="usage">Usage</h2>
<p>We can implement a library that lets us do similar things to Erlang’s
bit syntax, but in a more clunky way (it’s difficult to beat native
syntax support).</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">BitsAndBobs</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  pattern0    <span class="ot">=</span> sized word32 <span class="dv">5</span> <span class="op">:::</span> sized word32 <span class="dv">6</span> <span class="op">:::</span> sized word32 <span class="dv">5</span> <span class="op">:::</span> <span class="dt">Nil</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  bytestring0 <span class="ot">=</span> byteString [<span class="dv">2</span> <span class="op">:.</span> sized word32 <span class="dv">5</span>, <span class="dv">61</span> <span class="op">:.</span> sized word32 <span class="dv">6</span>, <span class="dv">20</span> <span class="op">:.</span> sized word32 <span class="dv">5</span>]</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>bitMatch pattern0 bytestring0</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- =&gt; (2,(61,(20,())))</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  pattern1    <span class="ot">=</span> word8 <span class="op">:&gt;&gt;=</span> \sz <span class="ot">-&gt;</span> sized bytes sz <span class="op">:::</span> bytes <span class="op">:::</span> <span class="dt">Nil</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  bytestring1 <span class="ot">=</span> byteString [<span class="dv">5</span> <span class="op">:.</span> word8, <span class="st">&quot;hello, rest&quot;</span> <span class="op">:.</span> bytes]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>bitMatch pattern1 bytestring1</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- =&gt; (5,(&quot;hello&quot;,(&quot;, rest&quot;,())))</span></span></code></pre></div>
<p>The above is <a
href="https://github.com/stevana/bits-and-bobs/blob/main/src/BitsAndBobs.hs">implemented</a>
in Haskell, but should be straightforward to port to most languages
using the following recipe.</p>
<h2 id="how-it-works">How it works</h2>
<p>The high-level idea when encoding a bunch of, possibly sized, values
into a <code>ByteString</code> is as follows:</p>
<ol type="1">
<li>For each value convert the value into a list of booleans (or
bits);</li>
<li>If the value is sized then only take that many bits, otherwise if it
isn’t sized use the default value, e.g. <code>Int8</code> = 8 bits,
<code>Float</code> = 32 bits, etc;</li>
<li>Concatenate the lists of booleans for each value into a single list
of booleans;</li>
<li>Split the list in groups of 8 bits;</li>
<li>Convert each 8 bits into a byte (<code>UInt8</code>);</li>
<li>Create a <code>ByteString</code> from list of
<code>UInt8</code>s.</li>
</ol>
<p>For decoding or pattern-matching a, possibly sized, pattern against a
<code>ByteString</code> the idea is:</p>
<ol type="1">
<li>Convert <code>ByteString</code> into list of booleans (or
bits);</li>
<li>For each pattern take its size many bits from the list;</li>
<li>Convert the bits into the value type of the pattern;</li>
<li>Continue matching the remaining patterns against the remaining
bits.</li>
</ol>
<p><code>Float</code> and <code>Double</code>s get converted into
<code>UInt32</code> and <code>UInt64</code> respectively before
converted into bits, and <code>Int</code>egers are encoding using <a
href="https://en.wikipedia.org/wiki/Variable-length_quantity#Zigzag_encoding">zigzag</a>
encoding<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>.</p>
<h2 id="extending-erlangs-bit-syntax">Extending Erlang’s bit syntax</h2>
<p>Erlang’s bit syntax makes it possible to decode binary data into the
host languague’s types, which can then be manipulated, and finally
encoded back to binary.</p>
<p>While already useful, it doesn’t cover some interesting use cases.
Let me try to explain the use cases and at the same time sketch possible
ways we can extend Erlang’s bit syntax to cover those.</p>
<h3 id="in-place-updates">In-place updates</h3>
<p>What if we merely want to update some binary in-place without reading
it all in and writing it all back out?</p>
<p>For example, the de facto standard for metadata format for mp3 files
is called <a href="https://en.wikipedia.org/wiki/ID3">ID3</a>. This was
never part of the mp3 specification, but rather added afterwards and so
in order to not break backwards-compatibility with old media players
they added it at the end of the file.</p>
<p>Lets imagine we wanted to write a metadata editor for mp3 files using
Erlang’s bit syntax. I think no matter how smart the Erlang run-time is
about bit syntax, it’s hard to imagine that it wouldn’t need to
deserialse and serialise more data than necessary. Worst case it would
deserialise all of the audio that leads up to where the metadata starts,
but even if it’s somehow clever and starts from the back then we’d still
probably need to at least deserialise all fields preceding the field we
want to update.</p>
<p>Inspired by this problem and how tools like <a
href="https://jemarch.net/poke"><code>poke</code></a> work, I’ve started
another experiment based on <code>Schema</code>s with this use case in
mind, here’s an example session of editing the metadata of an mp3
file:</p>
<pre><code>$ cabal run mp3 -- /tmp/test.mp3

mp3&gt; help
schema | read &lt;field&gt; | write &lt;field&gt; &lt;value&gt; | list | q(uit)

mp3&gt; schema
audio   : Binary
header  : Magic &quot;TAG&quot;
title   : ByteString (Fixed 30)
artist  : ByteString (Fixed 30)
album   : ByteString (Fixed 30)
year    : ByteString (Fixed 4)
comment : ByteString (Fixed 30)
genre   : UInt8

mp3&gt; read title
Unknown

mp3&gt; write title &quot;Bits and Bobs&quot;

mp3&gt; read title
Bits and Bobs

mp3&gt; list
Right (Id3V1 {title = &quot;Bits and Bobs&quot;, artist = &quot;&quot;, album = &quot;&quot;, year = &quot;2023&quot;, comment = &quot;&quot;})
mp3&gt; quit</code></pre>
<p>The user needs to specify the <code>Schema</code>, which is closely
mapped to the ID3v1 specficiation and the rest is provided by the
library. In particular all the offsets to the different fields are
calculated from the schema<a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>, which allow us to jump
straight to the field of interest and <em>reconstruct</em> it without
parsing. The above interactive <a href="app/Main.hs">editor</a> is
completely <a href="src/BitsAndBobs/Editor.hs">generic</a> and works for
any <code>Schema</code>!</p>
<p>If we can read and update fields, it should also be possible to get
<a
href="https://youtu.be/MUb8rD5mPvE?list=PLTj8twuHdQz-JcX7k6eOwyVPDB8CyfZc8&amp;t=830">diffs</a>
and patches for cheap.</p>
<h3 id="on-disk-data-structures">On-disk data structures</h3>
<p>Now that we can edit files in-place on the disk it would be nice to
use this in order to implement on-disk data structures. For example
imagine we’d like to do some kind of logging. If our schemas could
express arrays and records we could define our log to be an a struct
with a length field and an array of records field that of size length.
In addition to extending the schema with arrays and records, we’d also
need atomic increments of the length field so that we can in a
thread-safe manner allocate space in our array. B-trees or <a
href="https://github.com/real-logic/aeron">Aeron’s</a> <a
href="https://aeroncookbook.com/aeron/log-buffers-images/">log
buffers</a> would be other interesting on-disk data structures to
implement.</p>
<p>The generic editor would be useful for debugging and manipulating
such data structures, but we’d probably want more tooling. For logging
we probably want something like <code>cat</code> and <code>grep</code>
but generic in <code>Schema</code>.</p>
<h3 id="zero-copy">Zero-copy</h3>
<p>When we <code>read</code> a <code>ByteString</code> field in the mp3
metadata example above, we copied the bytes from the underlying file.
Sometimes we might want to avoid doing that.</p>
<p>For example imagine we are implementing some network protocol. We can
use a pre-allocated buffer and <a
href="https://linux.die.net/man/2/recv"><code>recv</code></a> bytes from
a socket into this buffer (avoiding allocating memory while handling
requests), once the request is inside our buffer we can decode
individual fields (without parsing) and from that we can determine what
kind of request it is. Let’s imagine it’s some kind of write request
where we want to save the payload of some field to disk. It would be a
waste to copy the bytestring of the payload only to write it disk
immediately after, since the network request consists of raw bytes and
that’s what we want to write to the disk anyway. Instead we’d like to be
able to decode the payload field as a pointer/slice of the buffer which
we pass to <a
href="https://linux.die.net/man/2/write"><code>write</code></a> (thus
avoiding copying aka “zero-copy”).</p>
<h3 id="backward--and-forward-compatiability-and-migrations">Backward-
and forward-compatiability and migrations</h3>
<p>Another big topic is schema evolution. How can we maintain backward-
and forward-compatibility as our software evolves? We probably want to
be able to migrate old formats into newer ones somehow also.</p>
<h3 id="compression">Compression</h3>
<p>Currently our schemas cannot express how to compress fields on disk,
or how to avoid sending unnecessary data in consecutive network
messages.</p>
<p>An example of the former might be to compress a bytestring field,
using say <a href="https://en.wikipedia.org/wiki/Deflate">deflate</a>,
before writing it to disk. While an example of the former might be to
only send the difference or change of some integer field, instead of
sending the whole integer again. To make things more concrete, lets say
the integer represents epoch time and we send messages several times per
second, then by only sending the difference or <a
href="https://en.wikipedia.org/wiki/Delta_encoding">delta</a> in time
since the last message we can save space. Other examples of compression
include <a
href="https://en.wikipedia.org/wiki/Dictionary_coder">dictionary</a>
compression, <a
href="https://en.wikipedia.org/wiki/Run-length_encoding">run-length
encoding</a>, <a
href="https://en.wikipedia.org/wiki/Apache_Parquet#Bit_packing">bit
packing</a> and <a
href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman
coding</a>.</p>
<p>It would be neat if encoding and decoding fields could be done modulo
compression! Likewise the schema-based <code>cat</code> and
<code>grep</code> could also work modulo compression.</p>
<p>A related topic is storing our data in a row-based or columnar
fashion. Take the example of a logging library we discussed earlier with
a schema that’s an array of records, i.e. each log call adds a new
record to the array. This is nice in terms of writing efficiency, but if
we wanted to do a lot of grepping or some aggregation on some field in
the record then we’d have to jump around a lot in the file (jumping over
the other fields that we are not interested in). It could be more
efficient to restructure our data into a record of arrays instead, where
each array only has data from one field, that way searching or
aggregating over that field would be much more efficient (no jumping
around). Some compression is also a lot easier to apply on columnar
data, e.g. delta and run-length encoding. Perhaps it would make sense if
the schema-based tools could do such data transformations in order to
optimise for reads or archiving?</p>
<h3 id="checksums">Checksums</h3>
<p>If we can do encoding and decoding fields modulo compression, why not
also handle checksums transparently? When we update a field which is
part of a checksum, we’d probably want to check the checksum beforehand
and recompute it afterwards.</p>
<h3 id="validation">Validation</h3>
<p>What if some input bytes don’t match the schema? Currently all magic
tags in a schema get verified, but sometimes we might want to be able to
edit incomplete or malformed inputs.</p>
<p>Can we add refinements to the schema which allow us to express things
like, integer between 18 and 150 or bytestring containing only
alphanumeric characters, etc?</p>
<h3 id="protocols">Protocols</h3>
<p>So far we’ve looked at how to specify what data our programs use and
how it’s transformed to and from bytes on disk or over the network.
Another important aspect is what protocol is followed when said data is
sent between components in the system.</p>
<p>For example consider some client-server application where our schema
describes the request and responses:</p>
<pre class="mermaid"><code>flowchart LR
    Client -- request --&gt; Server
    Server -- response --&gt; Client</code></pre>
<p>The schema doesn’t say anything about in which order requests are
legal. For example, we might want to always requrie a login-like request
at the start of a session. Or let’s say we are describing a POSIX-like
filesystem API, then <code>read</code>s and <code>write</code>s must
only be made on <code>open</code> (and not yet <code>close</code>d) file
descriptors.</p>
<p>Joe Armstrong wrote a paper called <a
href="https://erlang.org/workshop/2002/Armstrong.pdf"><em>Getting Erlang
to talk to the outside world</em></a> (2002) which discusses this
problem. He proposed a language for describing protocols and a dynamic
sessions type checker, it never seemed to have got much traction though
even though he gave several <a
href="https://youtu.be/ed7A7r6DBsM?t=1071">talks</a> about it. One
implementation can be found <a
href="https://ubf.github.io/ubf/ubf-user-guide.en.html">here</a>.</p>
<h3 id="pandoc-for-binary-encodings">Pandoc for binary encodings</h3>
<p>There’s this neat tool called <a
href="https://github.com/jgm/pandoc"><code>pandoc</code></a> that makes
possible to convert between different text formats, e.g. from Markdown
to HTML.</p>
<p>The list of supported formats to convert from and to is pretty long.
If we were to convert to and from each pair of possibilities would
require <span
class="math inline"><em>O</em>(<em>N</em><sup>2</sup>)</span> <a
href="https://youtu.be/ed7A7r6DBsM?t=2311">work</a>. So what
<code>pandoc</code> does instead is to convert each format to and from
its internal abstract representation, thereby reducing the problem to
<span class="math inline"><em>O</em>(<em>N</em>)</span>.</p>
<p>Could we do something similar for binary encodings?</p>
<p>In the book <em>Development and Deployment of Multiplayer Online
Games, Vol. I</em> by Sergey Ignatchenko (pp. 259-285, 2017) the author
talks about how most <a
href="https://en.wikipedia.org/wiki/Interface_description_language">IDLs</a>,
e.g. Protobufs, have the same language for describing <em>what</em> the
abstract data which we want to serialise and <em>how</em> we actually
want the data to be serialised. By separating the two, we could change
the binary format “on the wire” without changing the application which
operates on the abstract data (the <em>what</em> part). A clearer
separation between IDL and its encoding could perhaps be useful when
trying to solve the <code>pandoc</code> problem for binary.</p>
<p>Another way to think of this is: can we make a DSL for IDLs?</p>
<h2 id="discussion">Discussion</h2>
<ul>
<li><p>Q: Why not just use <a
href="https://en.wikipedia.org/wiki/Protocol_Buffers">Protobuf</a>?</p>
<p>A: Except for backward- and forward-compatibility, I don’t think
Protobufs can handle any of the above listed use cases. Also the way it
handles compatibility with it’s numbered and optional fields is quite
ugly<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>.</p></li>
<li><p>Q: Writing safely to disk without going via a database is almost
impossible!?</p>
<p>A: Dan Luu has <a
href="https://danluu.com/deconstruct-files/">written</a> about <a
href="https://danluu.com/fsyncgate/">this</a> on several <a
href="https://danluu.com/file-consistency/">occasions</a>. Short answer:
don’t store anything you are worried about losing using this library.
Longer answer: I’d like to revisit this topic from the point of view of
testing at some later point in time. In particular I’m interested in how
we can make the results from the paper <a
href="https://www.usenix.org/conference/osdi14/technical-sessions/presentation/pillai"><em>All
File Systems Are Not Created Equal: On the Complexity of Crafting
Crash-Consistent Applications</em></a></p>
<ol start="2014" type="1">
<li>more accessible, especially their tool <a
href="https://github.com/madthanu/alice"><em>ALICE: Application-Level
Intelligent Crash Explorer</em></a>.</li>
</ol></li>
</ul>
<h2 id="contributing">Contributing</h2>
<p>The current implementation is in Haskell, but I’d really like to
encourage a discussion beyond specific languages. In order to make
binary “human-readable” we need solutions that are universal, i.e. work
in any language, or perhaps better yet than libraries – extend
programming languages with something like Erlang’s bit syntax.</p>
<ul>
<li>Do you have use cases that are not listed above?</li>
<li>Do you know of tools, libraries or solutions any of the above use
cases that have already not been discussed or are not listed below in
the “see also” section?</li>
<li>Do you know if some use cases impossible in general or incompatible
with each other?</li>
<li>Interested in porting any of these ideas to your favorite
language?</li>
</ul>
<p>If so, feel free to get in touch!</p>
<h2 id="see-also">See also</h2>
<ul>
<li>The Erlang reference manual on <a
href="https://www.erlang.org/doc/reference_manual/expressions.html#bit_syntax">bit
syntax</a>;</li>
<li>Programming examples of bit syntax from the Erlang <a
href="https://www.erlang.org/doc/programming_examples/bit_syntax.html">user’s
guide</a>;</li>
<li>Joe Armstrong’s PhD <a
href="http://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A9492&amp;dswid=-1166">thesis</a>
<ol start="2003" type="1">
<li>also has a section on bit syntax on p. 60;</li>
</ol></li>
<li><a href="https://erlang.org/workshop/2002/Gustafsson.pdf">Native
Code Compilation of Erlang’s Bit Syntax</a> (2002);</li>
<li><a href="https://capnproto.org/">Cap’n Proto</a>;</li>
<li>Simple Binary Encoding (<a
href="https://github.com/real-logic/simple-binary-encoding">SBE</a>) by
Martin Thompson et al;</li>
<li>GNU <a href="https://jemarch.net/poke">poke</a>, extensible editor
for structured binary data;</li>
<li><a href="https://github.com/wader/fq">fq: jq for binary formats</a>
also described in this <a
href="https://www.youtube.com/watch?v=GJOq_b0eb-s&amp;list=PLTj8twuHdQz-JcX7k6eOwyVPDB8CyfZc8&amp;index=1">talk</a>;</li>
<li><a href="https://github.com/antonmedv/fx">Terminal JSON
viewer</a>;</li>
<li>Rust’s <a href="https://github.com/jam1garner/binrw">binrw</a>
crate;</li>
<li><em>Designing Data-Intensive Applications</em> by Martin Kleppmann
(chapter 3-4, 2017);</li>
<li><em>Development and Deployment of Multiplayer Online Games, Vol.
I</em> by Sergey Ignatchenko (pp. 200-216 and 259-285, 2017).</li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The savings are greater for more complicated JSON
objects, especially considering JSON doesn’t support binary data which
needs to be either escaped or base64 encoded before used as a string.<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>I don’t think Erlang uses zig-zag encoding of integers,
in fact I’m not sure what it does with them.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The library tries to calculate the offset of a field
from the start of the file, in this case the beginning of the file
contains an audio binary “field” of unknown length, so it fails and
retries calculating the offset from the end of the file instead.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Avro has a nicer story for <a
href="https://avro.apache.org/docs/1.11.1/specification/#schema-resolution">compatibility</a>.<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></description>
      <category>Development</category>
    </item>

    <item>
      <title>State machines with of async I/O</title>
      <link>https://stevana.github.io/state_machines_with_of_async_io.html</link>
      <guid>https://stevana.github.io/state_machines_with_of_async_io.html</guid>
      <pubDate>Sat, 7 Jan 2023 00:00:00 GMT</pubDate>
      <description><![CDATA[<h1>coroutine-state-machines</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a></li>
</ul>
</nav>
<div class="date">Posted on Jan  7, 2023</div>
<p>State machines of the type
<code>Input -&gt; State -&gt; (Output, State)</code> are great. They are
easy to reason about, and if run on a separate thread with access to a
queue of <code>Input</code>s they perform well too.</p>
<p>Sometimes the state machine might need to do some blocking I/O before
producing the output though, this slows down the processing of
inputs.</p>
<p>This repo is an experiment in how we can write the state machine as
if the I/O is blocking, but actually it’s non-blocking and inputs can
continue to be processes while we wait for the I/O action to
complete.</p>
<h2 id="usage">Usage</h2>
<p>To make things more concrete we will be implementing a key-value
store as a state machine.</p>
<p>To start the key-value store in a terminal issue:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cabal</span> run app</span></code></pre></div>
<p>Then interact with the key-value store from another terminal using
<code>Write</code> and <code>Read</code> commands as follows:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> http POST :8080 <span class="at">--raw</span> <span class="st">&#39;Write &quot;x&quot; 1&#39;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">HTTP/1.1</span> 200 OK</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Date:</span> Thu, 05 Jan 2023 08:47:03 GMT</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Server:</span> Warp/3.3.23</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="ex">Transfer-Encoding:</span> chunked</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="ex">Ok</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> http POST :8080 <span class="at">--raw</span> <span class="st">&#39;Read &quot;x&quot;&#39;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="ex">HTTP/1.1</span> 200 OK</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="ex">Date:</span> Thu, 05 Jan 2023 08:47:04 GMT</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="ex">Server:</span> Warp/3.3.23</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="ex">Transfer-Encoding:</span> chunked</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="ex">Result</span> 1</span></code></pre></div>
<h2 id="how-it-works">How it works</h2>
<p>The state machine for the key-value store example looks like
this:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">Input</span> <span class="ot">=</span> <span class="dt">Write</span> <span class="dt">String</span> <span class="dt">Int</span> <span class="op">|</span> <span class="dt">Read</span> <span class="dt">String</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock (<span class="dt">Show</span>, <span class="dt">Read</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">Output</span> <span class="ot">=</span> <span class="dt">Ok</span> <span class="op">|</span> <span class="dt">Result</span> (<span class="dt">Maybe</span> <span class="dt">Int</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock <span class="dt">Show</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="ot">sm ::</span> <span class="dt">SM</span> (<span class="dt">Map</span> <span class="dt">String</span> <span class="dt">Int</span>) <span class="dt">Input</span> <span class="dt">Output</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  i <span class="ot">&lt;-</span> ask</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">case</span> i <span class="kw">of</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Write</span> k v <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>      fsAppend k v</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>      modify (Map.insert k v)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span> <span class="dt">Ok</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Read</span> k <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>      m <span class="ot">&lt;-</span> get</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span> (<span class="dt">Result</span> (m <span class="op">Map.!?</span> k))</span></code></pre></div>
<p>Where <code>fsAppend</code> appends the key-value pair to a file, so
that we can recover in in-memory state in case of a crash.</p>
<p>The program looks sequential, but once the state machine hits the
<code>fsAppend</code> it will suspend using a coroutine monad, yielding
control back to the event loop which feeds it inputs, the event loop
will enqueue the I/O action to a separate thread that deals with I/O and
continue feeding the state machine new inputs, until the I/O thread
completes the write to disk, at which point the state machine will be
resumed with the latest state.</p>
<h2 id="contributing">Contributing</h2>
<p>Any feedback, comments or suggestions are most welcome!</p>
<p>In particular if you know how to solve this problem in a different or
better way.</p>
<p>A potential source of confusion and bugs might be the fact that once
we resume the state might not be the same as it was before we suspended.
It’s not clear to me how big of a problem this is in practice, or if
anything can be done about it without sacrificing either the “sequential
feel” or the parallelism?</p>
<p>One possible generalisation that seems feasible is to not suspend
immediately upon the I/O action, but rather merely return a “future”
which we later can <code>await</code> for. This would allow us to do
suspend and do multiple I/O actions before resuming, something like:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>  a1 <span class="ot">&lt;-</span> fsAppend k v</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  a2 <span class="ot">&lt;-</span> someOtherIOAction</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  awaitBoth a1 a2 <span class="co">-- or awaitEither a1 a2</span></span></code></pre></div>
<p>Arguably the await makes it more clear where the suspension and
resumption happen, which could help against the confusion regarding that
the state might change.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><em>Development and Deployment of Multiplayer Online Games, Vol.
II</em> by Sergey Ignatchenko (2020), especially chapter 5;</li>
<li><a
href="https://abhinavsarkar.net/posts/implementing-co-3/"><em>Implementing
Co, a Small Language With Coroutines #3: Adding
Coroutines</em></a>;</li>
<li><a
href="https://ayazhafiz.com/articles/23/a-lambda-calculus-with-coroutines-and-heapless-closures"><em>A
Lambda Calculus With Coroutines and Heapless, Directly-Called
Closures</em></a>;</li>
<li><a href="https://blog.dziban.net/coroutines/">Small VMs &amp;
Coroutines</a>;</li>
<li><a href="https://github.com/slembcke/Tina">Tina is a teeny tiny,
header only, coroutine and job library</a>;</li>
<li><a href="http://dunkels.com/adam/pt/">Protothreads</a>;</li>
<li><a href="https://en.wikipedia.org/wiki/Proactor_pattern">Proactor
pattern</a>;</li>
<li><a
href="https://github.com/bytecodealliance/wasmtime/blob/main/docs/WASI-rationale.md#why-not-async">WebAssembly
Reactors</a>.</li>
</ul>
]]></description>
      <category>Development</category>
    </item>


  </channel>
</rss>
