<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Stevan A" />
  <title>pipelined-state-machines</title>
  <link rel="stylesheet" href="style.css" />
  <link rel="alternate" type="application/rss+xml"
        title="RSS feed"
        href="rss.xml" />
  <script src="script.js"></script>
  <script data-goatcounter="https://stevana-github-io.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
  <noscript>
    <img src="https://stevana-github-io.goatcounter.com/count?p=/pipelined_state_machines.html&t=pipelined-state-machines">
  </noscript>
</head>
<body>
<header id="title-block-header">
  <nav id="nav">
    <span class="title"><a href="/">Stevan's notes...</a></span>
    <a href="about.html">About</a>
    <a href="rss.xml">Feed <img height="10px" src="rss.svg" /></a>
  </nav>
</header>
<hr />
<main>
<h1>pipelined-state-machines</h1>
<nav id="TOC" class="sidenote" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#usage" id="toc-usage">Usage</a></li>
<li><a href="#disruptor" id="toc-disruptor">Disruptor</a>
<ul>
<li><a href="#example" id="toc-example">Example</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
<li><a href="#performance" id="toc-performance">Performance</a></li>
</ul></li>
<li><a href="#contributing" id="toc-contributing">Contributing</a></li>
<li><a href="#see-also" id="toc-see-also">See also</a>
<ul>
<li><a href="#presentations"
id="toc-presentations">Presentations</a></li>
<li><a href="#writings" id="toc-writings">Writings</a></li>
</ul></li>
</ul>
</nav>
<div class="date">Posted on Mar  1, 2023</div>
<p>An experiment in declaratively programming parallel pipelines of
state machines.</p>
<section id="motivation" class="level2">
<h2><a href="#motivation" title="Motivation">Motivation</a></h2>
<p>Imagine a flat complex in Sweden. Being the socialist utopia Sweden
is there’s a shared laundry room which the people in the flat complex
can book. In the laundry room there’s everything one needs to wash, dry
and iron your clothes. You don’t even need to bring your own laundry
detergent!</p>
<p>Lets call three people living there Ann, Bo and Cecilia, and lets
assume they all want to use the laundry room. Depending on how the
booking system is implemented the total time it would take for all three
people to do their laundry varies.</p>
<p>For example if the booking system allocates a big time slot per
person in which that person can do the whole cycle of <em>W</em>ashing,
<em>D</em>rying and <em>I</em>roning then, assuming each step takes one
time unit, we get a situation like this:</p>
<pre><code>      Person
        ^
    Ann | W D I                             W = Washing
     Bo |       W D I                       D = Drying
Cecilia |             W D I                 I = Ironing
        +-------------------&gt; Time
        0 1 2 3 4 5 6 7 8 9</code></pre>
<p>Bo cannot start washing until Ann is done ironing, because Ann has
booked the room for the whole cycle, and so on.</p>
<p>If the booking system is more granular and allows booking a time slot
per step then we can get a situation that looks like this:</p>
<pre><code>      Person
        ^
    Ann | W D I
     Bo |   W D I
Cecilia |     W D I
        +-------------------&gt; Time
        0 1 2 3 4 5 6 7 8 9</code></pre>
<p>It should be clear that the total time is shorter in this case,
because the machines are utilised better (Bo can start using the washing
machine right after Ann is done with it). Also note that if each person
would start a new washing after they finish ironing the first one and so
on then the time savings would be even greater.</p>
<p>This optimisation is called pipelining. It’s used a lot in
manufacturing, for example Airbus <a
href="https://youtu.be/oxjT7veKi9c?t=2682">builds</a> two airplanes per
day. If you were to order a plane today you’d get it delivered in two
months time. How is that they deliver two per day if it takes two months
to build them? Pipelining! It’s also used inside CPUs to <a
href="https://en.wikipedia.org/wiki/Instruction_pipelining">pipeline
instructions</a>.</p>
<p>The rest of this document is an experiment in how we can construct
such pipelining in software in a declarative way.</p>
</section>
<section id="usage" class="level2">
<h2><a href="#usage" title="Usage">Usage</a></h2>
<p>The workers or stages in our pipeline will be state machines of the
following type.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">SM</span> s a b <span class="kw">where</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Id</span><span class="ot">      ::</span> <span class="dt">SM</span> s a a</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Compose</span><span class="ot"> ::</span> <span class="dt">SM</span> s b c <span class="ot">-&gt;</span> <span class="dt">SM</span> s a b <span class="ot">-&gt;</span> <span class="dt">SM</span> s a c</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Fst</span><span class="ot">     ::</span> <span class="dt">SM</span> s (a, b) a</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Snd</span><span class="ot">     ::</span> <span class="dt">SM</span> s (a, b) b</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&amp;&amp;&amp;)  ::</span> <span class="dt">SM</span> s a c <span class="ot">-&gt;</span> <span class="dt">SM</span> s a d <span class="ot">-&gt;</span> <span class="dt">SM</span> s a (c, d)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:***)  ::</span> <span class="dt">SM</span> s a c <span class="ot">-&gt;</span> <span class="dt">SM</span> s b d <span class="ot">-&gt;</span> <span class="dt">SM</span> s (a, b) (c, d)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SlowIO</span><span class="ot">  ::</span> <span class="dt">SM</span> s a a <span class="co">-- Simulate a slow I/O computation.</span></span></code></pre></div>
<p>Here’s an example of a stage which takes an ordered pair as input and
swaps the elements of the pair. Note the use of <code>SlowIO</code> to
simulate that some slow I/O computation happens.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swap ::</span> <span class="dt">SM</span> () (a, b) (b, a)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>swap <span class="ot">=</span> <span class="dt">Snd</span> <span class="op">:***</span> <span class="dt">Fst</span> <span class="ot">`Compose`</span> copy <span class="ot">`Compose`</span> <span class="dt">SlowIO</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    copy <span class="ot">=</span> <span class="dt">Id</span> <span class="op">:&amp;&amp;&amp;</span> <span class="dt">Id</span></span></code></pre></div>
<p>We can <code>interpret</code> such state machines into plain
functions as follows.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ot">interpret ::</span> <span class="dt">SM</span> s a b <span class="ot">-&gt;</span> (a <span class="ot">-&gt;</span> s <span class="ot">-&gt;</span> <span class="dt">IO</span> (s, b))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">Id</span>            x s <span class="ot">=</span> <span class="fu">return</span> (s, x)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>interpret (<span class="dt">Compose</span> g f) x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  (s&#39;, y) <span class="ot">&lt;-</span> interpret f x s</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  interpret g y s&#39;</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">Fst</span>           x s <span class="ot">=</span> <span class="fu">return</span> (s, <span class="fu">fst</span> x)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">Snd</span>           x s <span class="ot">=</span> <span class="fu">return</span> (s, <span class="fu">snd</span> x)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>interpret (f <span class="op">:&amp;&amp;&amp;</span> g)    x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  (s&#39;, y)  <span class="ot">&lt;-</span> interpret f x s</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  (s&#39;&#39;, z) <span class="ot">&lt;-</span> interpret g x s&#39;</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (s&#39;&#39;, (y, z))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>interpret (f <span class="op">:***</span> g)    x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  (s&#39;, y)  <span class="ot">&lt;-</span> interpret f (<span class="fu">fst</span> x) s</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  (s&#39;&#39;, z) <span class="ot">&lt;-</span> interpret g (<span class="fu">snd</span> x) s&#39;</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (s&#39;&#39;, (y, z))</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>interpret <span class="dt">SlowIO</span> x s <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  threadDelay <span class="dv">200000</span> <span class="co">-- 0.2s</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (s, x)</span></code></pre></div>
<p>Next lets have a look at how we can construct pipelines of such state
machines.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">P</span> a b <span class="kw">where</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span><span class="ot">     ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">SM</span> s a b <span class="ot">-&gt;</span> s <span class="ot">-&gt;</span> <span class="dt">P</span> a b</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="ot">  (:&gt;&gt;&gt;) ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">P</span> b c <span class="ot">-&gt;</span> <span class="dt">P</span> a c</span></code></pre></div>
<p>The following is an example pipeline where there’s only one stage in
which we do our pair swapping three times.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swapsSequential ::</span> <span class="dt">P</span> (a, b) (b, a)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>swapsSequential <span class="ot">=</span> <span class="dt">SM</span> <span class="st">&quot;three swaps&quot;</span> (swap <span class="ot">`Compose`</span> swap <span class="ot">`Compose`</span> swap) ()</span></code></pre></div>
<p>The above corresponds to our coarse grained booking system where the
laundry was booked for the whole cycle. Whereas the following
corresponds to the more fine grained approach where we get
pipelining.</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swapsPipelined ::</span> <span class="dt">P</span> (a, b) (b, a)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>swapsPipelined <span class="ot">=</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span> <span class="st">&quot;first swap&quot;</span>  swap () <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span> <span class="st">&quot;second swap&quot;</span> swap () <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">SM</span> <span class="st">&quot;third swap&quot;</span>  swap ()</span></code></pre></div>
<p>A pipeline can be deployed, we’ll use the following type to keep
track of the queue associated with the pipeline as well as the name and
pids of the state machines involved in the pipeline.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">Deployment</span> a <span class="ot">=</span> <span class="dt">Deployment</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  {<span class="ot"> queue ::</span> <span class="dt">TQueue</span> a</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  ,<span class="ot"> pids  ::</span> [(<span class="dt">String</span>, <span class="dt">Async</span> ())]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="ot">names ::</span> <span class="dt">Deployment</span> a <span class="ot">-&gt;</span> <span class="dt">String</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>names <span class="ot">=</span> bracket <span class="op">.</span> intercalate <span class="st">&quot;,&quot;</span> <span class="op">.</span> <span class="fu">reverse</span> <span class="op">.</span> <span class="fu">map</span> <span class="fu">fst</span> <span class="op">.</span> pids</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    bracket s <span class="ot">=</span> <span class="st">&quot;[&quot;</span> <span class="op">++</span> s <span class="op">++</span> <span class="st">&quot;]&quot;</span></span></code></pre></div>
<p>Here’s the actual <code>deploy</code>ment function which takes a
pipeline and gives back an input-queue and a <code>Deployment</code>
which holds the output-queue and the names and pids of the state
machines.</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ot">deploy ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">TQueue</span> a, <span class="dt">Deployment</span> b)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>deploy p <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  q <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  d <span class="ot">&lt;-</span> deploy&#39; p (<span class="dt">Deployment</span> q [])</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (q, d)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="ot">deploy&#39; ::</span> <span class="dt">P</span> a b <span class="ot">-&gt;</span> <span class="dt">Deployment</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Deployment</span> b)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>deploy&#39; (<span class="dt">SM</span> name sm s0) d <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  q&#39; <span class="ot">&lt;-</span> newTQueueIO</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  pid <span class="ot">&lt;-</span> async (go s0 q&#39;)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> <span class="dt">Deployment</span> { queue <span class="ot">=</span> q&#39;, pids <span class="ot">=</span> (name, pid) <span class="op">:</span> pids d }</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">where</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    f <span class="ot">=</span> interpret sm</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    go s q&#39; <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">&lt;-</span> atomically <span class="op">$</span> readTQueue (queue d)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>      (s&#39;, o) <span class="ot">&lt;-</span> f x s</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>      atomically <span class="op">$</span> writeTQueue q&#39; o</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>      go s&#39; q&#39;</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>deploy&#39; (sm <span class="op">:&gt;&gt;&gt;</span> sm&#39;) d <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  d&#39; <span class="ot">&lt;-</span> deploy&#39; sm d</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>  deploy&#39; sm&#39; d&#39;</span></code></pre></div>
<p>We now have everything we need to run a simple benchmark comparing
the sequential version of three swaps versus the pipelined version.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">PipelineKind</span> <span class="ot">=</span> <span class="dt">Sequential</span> <span class="op">|</span> <span class="dt">Pipelined</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> <span class="dt">Show</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="ot">main ::</span> <span class="dt">IO</span> ()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>main <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mapM_</span> libMain [<span class="dt">Sequential</span>, <span class="dt">Pipelined</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="ot">libMain ::</span> <span class="dt">PipelineKind</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>libMain k <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  (q, d) <span class="ot">&lt;-</span> deploy <span class="op">$</span> <span class="kw">case</span> k <span class="kw">of</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>                       <span class="dt">Sequential</span> <span class="ot">-&gt;</span> swapsSequential</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>                       <span class="dt">Pipelined</span>  <span class="ot">-&gt;</span> swapsPipelined</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span> k</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="op">$</span> <span class="st">&quot;Pids: &quot;</span> <span class="op">++</span> names d</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  start <span class="ot">&lt;-</span> getCurrentTime</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  forM_ [(<span class="dv">1</span>, <span class="dv">2</span>), (<span class="dv">2</span>, <span class="dv">3</span>), (<span class="dv">3</span>, <span class="dv">4</span>), (<span class="dv">4</span>, <span class="dv">5</span>), (<span class="dv">5</span>, <span class="dv">6</span>), (<span class="dv">6</span>, <span class="dv">7</span>)] <span class="op">$</span> \x <span class="ot">-&gt;</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    atomically <span class="op">$</span> writeTQueue q x</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  resps <span class="ot">&lt;-</span> replicateM <span class="dv">6</span> <span class="op">$</span> atomically <span class="op">$</span> readTQueue (queue d)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  end <span class="ot">&lt;-</span> getCurrentTime</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="op">$</span> <span class="st">&quot;Responses: &quot;</span> <span class="op">++</span> <span class="fu">show</span> resps</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="op">$</span> <span class="st">&quot;Time: &quot;</span> <span class="op">++</span> <span class="fu">show</span> (diffUTCTime end start)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">putStrLn</span> <span class="st">&quot;&quot;</span></span></code></pre></div>
<p>We can run the above with
<code>cabal run readme-pipeline-example</code>, which results in
something like the following being printed to the screen.</p>
<pre><code>Sequential
Pids: [three swaps]
Responses: [(2,1),(3,2),(4,3),(5,4),(6,5),(7,6)]
Time: 3.611045787s

Pipelined
Pids: [first swap,second swap,third swap]
Responses: [(2,1),(3,2),(4,3),(5,4),(6,5),(7,6)]
Time: 1.604990775s</code></pre>
<p>Cool, we managed to reduce the total running time by more than half!
We can do even better though! In addition to pipelining we can also
shard the queues by letting two state machines work on the same queue,
the first processing the elements in the even positions of the queue and
the second processing the elements in the odd positions.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>data P a b where</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  SM     :: String -&gt; SM s a b -&gt; s -&gt; P a b</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  (:&gt;&gt;&gt;) :: P a b -&gt; P b c -&gt; P a c</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="va">+ Shard  :: P a b -&gt; P a b</span></span></code></pre></div>
<p>Here’s an example of a sharded pipeline, where each shard will spawn
two state machines (one working on the even indexes of the queue and the
other on the odd).</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ot">swapsSharded ::</span> <span class="dt">P</span> (a, b) (b, a)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>swapsSharded <span class="ot">=</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span> (<span class="dt">SM</span> <span class="st">&quot;first swap&quot;</span>  swap ()) <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span> (<span class="dt">SM</span> <span class="st">&quot;second swap&quot;</span> swap ()) <span class="op">:&gt;&gt;&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">Shard</span> (<span class="dt">SM</span> <span class="st">&quot;third swap&quot;</span>  swap ())</span></code></pre></div>
<p>In the deployment of shards, we achieve the even-odd split by reading
from the input queue, <code>qIn</code>, and first writing to the even
queue, <code>qEven</code>, and then switching over to the odd queue,
<code>qOdd</code>, when making the recursive call in
<code>shardQIn</code>. Whereas <code>shardQOut</code> does the inverse
and merges the two queues back into the output queue:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="va">+ deploy&#39; (Shard p) d = do</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="va">+   let qIn = queue d</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="va">+   qEven  &lt;- newTQueueIO</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="va">+   qOdd   &lt;- newTQueueIO</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="va">+   pidIn  &lt;- async $ shardQIn qIn qEven qOdd</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="va">+   dEven  &lt;- deploy&#39; p (Deployment qEven [])</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="va">+   dOdd   &lt;- deploy&#39; p (Deployment qOdd [])</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="va">+   qOut   &lt;- newTQueueIO</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="va">+   pidOut &lt;- async $ shardQOut (queue dEven) (queue dOdd) qOut</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="va">+   return (Deployment qOut ((&quot;shardIn:  &quot; ++ names dEven ++ &quot; &amp; &quot; ++ names dOdd, pidIn) :</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="va">+                            (&quot;shardOut: &quot; ++ names dEven ++ &quot; &amp; &quot; ++ names dOdd, pidOut) :</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="va">+                            pids dEven ++ pids dOdd ++ pids d))</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="va">+   where</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQIn :: TQueue a -&gt; TQueue a -&gt; TQueue a -&gt; IO ()</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQIn  qIn qEven qOdd = do</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="va">+       atomically (readTQueue qIn &gt;&gt;= writeTQueue qEven)</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="va">+       shardQIn qIn qOdd qEven</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQOut :: TQueue a -&gt; TQueue a -&gt; TQueue a -&gt; IO ()</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="va">+     shardQOut qEven qOdd qOut = do</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="va">+       atomically (readTQueue qEven &gt;&gt;= writeTQueue qOut)</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="va">+       shardQOut qOdd qEven qOut</span></span></code></pre></div>
<p>Running this version we see more than 3.5x speed-up compared to the
sequential pipeline.</p>
<pre><code>Sharded
Pids: [first swap,first swap,shardOut: [first swap] &amp; [first swap],shardIn:  [first swap] &amp; [first swap],second swap,second swap,shardOut: [second swap] &amp; [second swap],shardIn:  [second swap] &amp; [second swap],third swap,third swap,shardOut: [third swap] &amp; [third swap],shardIn:  [third swap] &amp; [third swap]]
Responses: [(2,1),(3,2),(4,3),(5,4),(6,5),(7,6)]
Time: 1.00241912s</code></pre>
<p>There are still many more improvements to be made here:</p>
<ul>
<li>Avoid spawning threads for merely shuffling elements between queues,
e.g. <code>shardQ{In, Out}</code> above;</li>
<li>Avoid copying elements between queues;</li>
<li>Back-pressure;</li>
<li>Batching.</li>
</ul>
<p>I believe all these problems can be solved by choosing a better
concurrent queue data structure than <code>TQueue</code>, so that’s what
we’ll have a look at next.</p>
</section>
<section id="disruptor" class="level2">
<h2><a href="#disruptor" title="Disruptor">Disruptor</a></h2>
<p>The <code>Disruptor*</code> modules are a Haskell port of the <a
href="https://github.com/LMAX-Exchange/disruptor">LMAX Disruptor</a>,
which is a high performance inter-thread messaging library. The
developers at LMAX, which operates a financial exchange, <a
href="https://www.infoq.com/presentations/LMAX/">reported</a> in 2010
that they could process more than 100,000 transactions per second at
less than 1 millisecond latency.</p>
<p>At its core it’s just a lock-free concurrent queue, but it also
provides building blocks for achieving several useful concurrent
programming tasks that typical queues don’t (or at least don’t make
obvious how to do). The extra features include:</p>
<ul>
<li>Multi-cast (many consumers can in parallel process the same
event);</li>
<li>Batching (both on producer and consumer side);</li>
<li>Back-pressure;</li>
<li>Sharding for scalability;</li>
<li>Dependencies between consumers.</li>
</ul>
<p>It’s also performs better than most queues, as we shall see further
down.</p>
<section id="example" class="level3">
<h3><a href="#example" title="Example">Example</a></h3>
<div class="sourceCode" id="cb17"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">Control.Concurrent</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">Control.Concurrent.Async</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">import</span> <span class="dt">Disruptor.SP</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="ot">main ::</span> <span class="dt">IO</span> ()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>main <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Create the shared ring buffer.</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> bufferCapacity <span class="ot">=</span> <span class="dv">128</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  rb <span class="ot">&lt;-</span> newRingBuffer bufferCapacity</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- The producer keeps a counter and produces events that are merely the pretty</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- printed value as a string of that counter.</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span><span class="ot"> produce ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">String</span>, <span class="dt">Int</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>      produce n <span class="ot">=</span> <span class="fu">return</span> (<span class="fu">show</span> n, n <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- The counter starts at zero.</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>      initialProducerState <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- No back-pressure is applied in this example.</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="ot">      backPressure ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>      backPressure _ <span class="ot">=</span> <span class="fu">return</span> ()</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>  producer <span class="ot">&lt;-</span> newEventProducer rb produce backPressure initialProducerState</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- The consumer merely prints the string event to the terminal.</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span><span class="ot"> consume ::</span> () <span class="ot">-&gt;</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">SequenceNumber</span> <span class="ot">-&gt;</span> <span class="dt">EndOfBatch</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>      consume () event snr endOfBatch <span class="ot">=</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        <span class="fu">putStrLn</span> (event <span class="op">++</span> <span class="kw">if</span> endOfBatch <span class="kw">then</span> <span class="st">&quot; (end of batch)&quot;</span> <span class="kw">else</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- The consumer doesn&#39;t need any state in this example.</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>      initialConsumerState <span class="ot">=</span> ()</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- Which other consumers do we need to wait for before consuming an event?</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>      dependencies <span class="ot">=</span> []</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>      <span class="co">-- What to do in case there are no events to consume?</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>      waitStrategy <span class="ot">=</span> <span class="dt">Sleep</span> <span class="dv">1</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>  consumer <span class="ot">&lt;-</span> newEventConsumer rb consume initialConsumerState dependencies waitStrategy</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tell the ring buffer which the last consumer is, to avoid overwriting</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- events that haven&#39;t been consumed yet.</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>  setGatingSequences rb [ecSequenceNumber consumer]</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>  withEventProducer producer <span class="op">$</span> \ap <span class="ot">-&gt;</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>    withEventConsumer consumer <span class="op">$</span> \ac <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>      threadDelay (<span class="dv">3</span> <span class="op">*</span> <span class="dv">1000</span> <span class="op">*</span> <span class="dv">1000</span>) <span class="co">-- 3 sec</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>      cancel ap</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>      cancel ac</span></code></pre></div>
<p>You can run the above example with
<code>cabal run readme-disruptor-example</code>.</p>
<p>A couple of things we could change to highlight the features we
mentioned in the above section:</p>
<ol type="1">
<li><p>Add a second consumer that saves the event to disk, this consumer
would be slower than the current one which logs to the terminal, but we
could use buffer up events in memory and only actually write when the
end of batch flag is set to speed things up;</p></li>
<li><p>We could also shard depending on the sequence number, e.g. have
two slower consumers that write to disk and have one of them handle even
sequence numbers while the other handles odd ones;</p></li>
<li><p>The above producer writes one event at the time to the ring
buffer, but since we know at which sequence number the last consumer is
at we can easily make writes in batches as well;</p></li>
<li><p>Currently the producer doesn’t apply any back-pressure when the
ring buffer is full, in a more realistic example where the producer
would, for example, create events from requests made to a http server we
could use back-pressure to tell the http server to return status code
429 (too many requests);</p></li>
<li><p>If we have one consumer that writes to the terminal and another
one that concurrently writes to disk, we could add a third consumer that
does something with the event only if it has both been logged and stored
to disk (i.e. the third consumer depends on both the first and the
second).</p></li>
</ol>
</section>
<section id="how-it-works" class="level3">
<h3><a href="#how-it-works" title="How it works">How it works</a></h3>
<p>The ring buffer is implemented using a bounded array, it keeps track
of a monotonically increasing sequence number and it knows its the
capacity of the array, so to find out where to write the next value by
simply taking the modulus of the sequence number and the capacity. This
has several advantages over traditional queues:</p>
<ol type="1">
<li><p>We never remove elements when dequeing, merely overwrite them
once we gone all way around the ring. This removes write <a
href="https://en.wikipedia.org/wiki/Resource_contention">contention</a>
between the producer and the consumer, one could also imagine avoiding
garbage collection by only allocating memory the first time around the
ring (but we don’t do this in Haskell);</p></li>
<li><p>Using an array rather than linked list increasing <a
href="https://en.wikipedia.org/wiki/Stride_of_an_array">striding</a> due
to <a
href="https://en.wikipedia.org/wiki/Locality_of_reference#Spatial_and_temporal_locality_usage">spatial
locality</a>.</p></li>
</ol>
<p>The ring buffer also keeps track of up to which sequence number its
last consumer has consumed, in order to not overwrite events that
haven’t been handled yet.</p>
<p>This also means that producers can ask how much capacity left a ring
buffer has, and do batched writes. If there’s no capacity left the
producer can apply back-pressure upstream as appropriate.</p>
<p>Consumers need keep track of which sequence number they have
processed, in order to avoid having the ring buffer overwrite
unprocessed events as already mentioned, but this also allows consumers
to depend on each other.</p>
<p>When a consumer is done processing an event, it asks the ring buffer
for the event at its next sequence number, the ring buffer then replies
that either there are no new events, in which case the consumer applies
it wait strategy, or the ring buffer can reply that there are new
events, the consumer the handles each one in turn and the last one will
be have the end of batch flag set, so that the consumer can effectively
batch the processing.</p>
</section>
<section id="performance" class="level3">
<h3><a href="#performance" title="Performance">Performance</a></h3>
<p>Our Disruptor implementation, which hasn’t been optimised much yet,
is about 2x slower than LMAX’s Java version on their single-producer
single-consumer <a
href="https://github.com/LMAX-Exchange/disruptor/blob/master/src/perftest/java/com/lmax/disruptor/sequenced/OneToOneSequencedThroughputTest.java">benchmark</a>
(1P1C) (basically the above example) on a couple of years old Linux
laptop.</p>
<p>The same benchmark compared to other Haskell libraries:</p>
<ul>
<li><p>10.3x faster than <a
href="https://hackage.haskell.org/package/base-4.15.0.0/docs/Control-Concurrent-Chan.html"><code>Control.Concurrent.Chan</code></a>;</p></li>
<li><p>8.3x faster than <a
href="https://hackage.haskell.org/package/stm/docs/Control-Concurrent-STM-TBQueue.html"><code>Control.Concurrent.STM.TBQueue</code></a>;</p></li>
<li><p>1.7x faster than <a
href="https://hackage.haskell.org/package/unagi-chan"><code>unagi-chan</code></a>;</p></li>
<li><p>25.5x faster than <a
href="https://hackage.haskell.org/package/chaselev-deque"><code>chaselev-deque</code></a>;</p></li>
<li><p>700x faster than <a
href="https://hackage.haskell.org/package/ring-buffer"><code>ring-buffer</code></a>;</p></li>
<li><p>1.3x slower than <a
href="https://hackage.haskell.org/package/lockfree-queue"><code>lockfree-queue</code></a>;</p></li>
<li><p>TODO: Compare with <a
href="https://github.com/kim/data-ringbuffer/tree/master/src/Data/RingBuffer"><code>data-ringbuffer</code></a>.</p></li>
</ul>
<p>In the triple-producer single-consumer (3P1C) <a
href="https://github.com/LMAX-Exchange/disruptor/blob/master/src/perftest/java/com/lmax/disruptor/sequenced/ThreeToOneSequencedThroughputTest.java">benchmark</a>,
the Java version is 5x slower than the Java 1P1C case. And our 3P1C is
4.6x slower than our 1P1C version and our 3P1C version is 2.7x slower
than the Java version.</p>
<p>The same benchmark compared to other Haskell libraries:</p>
<ul>
<li><p>73x faster than <a
href="https://hackage.haskell.org/package/base-4.15.0.0/docs/Control-Concurrent-Chan.html"><code>Control.Concurrent.Chan</code></a>;</p></li>
<li><p>3.5x faster than <a
href="https://hackage.haskell.org/package/stm/docs/Control-Concurrent-STM-TBQueue.html"><code>Control.Concurrent.STM.TBQueue</code></a>;</p></li>
<li><p>1.3x faster than <a
href="https://hackage.haskell.org/package/unagi-chan"><code>unagi-chan</code></a>;</p></li>
<li><p>1.9x faster than <a
href="https://hackage.haskell.org/package/lockfree-queue"><code>lockfree-queue</code></a>.</p></li>
</ul>
<p>For a slightly more “real world” example, we modified the 3P1C test
to have three producers that log messages while the consumer writes them
to a log file and compared it to <a
href="https://hackage.haskell.org/package/fast-logger"><code>fast-logger</code></a>.
The <code>pipelined-state-machines</code> benchmark has a throughput of
3:4 that of <code>fast-logger</code>. When we bump it to ten
concurrently logging threads the <code>pipelined-state-machines</code>
benchmark has a throughput of 10:7 that of <code>fast-logger</code>.</p>
<p>See the file <a href="benchmark.sh"><code>benchmark.sh</code></a> for
full details about how the benchmarks are run.</p>
<p>As always take benchmarks with a grain of salt, we’ve tried to make
them as fair with respect to each other and as true to the original Java
versions as possible. If you see anything that seems unfair, or if you
get very different results when trying to reproduce the numbers, then
please file an issue.</p>
</section>
</section>
<section id="contributing" class="level2">
<h2><a href="#contributing" title="Contributing">Contributing</a></h2>
<p>There’s a lot of possible paths to explore from here, including:</p>
<ul class="task-list">
<li><input type="checkbox" />Can we swap out our use of
<code>TQueue</code> for <code>Disruptor</code> in our
<code>deploy</code> of <code>P</code>ipelines?</li>
<li><input type="checkbox" />Can we add something like a
<code>FanOut :: P a b -&gt; P a c -&gt; P a (b, c)</code> and a
<code>Par :: P a c -&gt; P b d -&gt; P (a, b) (c, d)</code> combinator
to allow two parallel queues?</li>
<li><input type="checkbox" />What about sum-types and error
handling?</li>
<li><input type="checkbox" />Our current, and the above just mentioned,
pipeline combinators are all binary to can we generalise this to
N-ary?</li>
<li><input type="checkbox" />Can we visualise pipelines using
<code>dot</code> or similar?</li>
<li><input type="checkbox" />Can we build a performance/cost simulator
of pipelines?</li>
<li><input type="checkbox" />Arrow syntax or monadic DSL for
pipelines?</li>
<li><input type="checkbox" />We’ve seen <a
href="https://github.com/stevana/hot-swapping-state-machines">previously</a>
how we can hot-code upgrade state machines, what about hot-code
upgrading pipelines?</li>
<li><input type="checkbox" />Can we implement the Erlang
<code>gen_event</code> behaviour using Disruptor?</li>
<li><input type="checkbox" />Would it make sense to use the spiritual
successor of the Disruptor instead, i.e. the different array queues from
<code>aeron</code> and <code>agrona</code>:
<ul>
<li><a
href="https://github.com/real-logic/agrona/blob/master/agrona/src/main/java/org/agrona/concurrent/OneToOneConcurrentArrayQueue.java">Single-producer
single-consumer</a>;</li>
<li><a
href="https://github.com/real-logic/agrona/blob/master/agrona/src/main/java/org/agrona/concurrent/ManyToOneConcurrentArrayQueue.java">Multiple-producers
single-consumer</a>;</li>
<li><a
href="https://github.com/real-logic/agrona/blob/master/agrona/src/main/java/org/agrona/concurrent/ManyToManyConcurrentArrayQueue.java">Multiple-producers
multiple-consumers</a>.</li>
</ul></li>
<li><input type="checkbox" />How exactly do these pipelines relate to
the libraries <a
href="https://hackage.haskell.org/package/pipes"><code>pipes</code></a>,
<a
href="https://hackage.haskell.org/package/conduit"><code>conduit</code></a>
and <a
href="https://hackage.haskell.org/package/streamly"><code>streamly</code></a>?</li>
<li><input type="checkbox" />How does it relate to synchronous
programming languages such as <a
href="https://en.wikipedia.org/wiki/Esterel">Esterel</a>, <a
href="https://en.wikipedia.org/wiki/Lustre_(programming_language)">Lustre</a>,
<a href="https://rml.lri.fr">ReactiveML</a>, etc? It seems to me that
their main motivation is to be concurrent or parallel while still
determinstic, which is what we’d like as well. Looking at ReactiveML’s
documentation for <a
href="https://rml.lri.fr/documentation.html#compositions">compositions</a>
we see the same constructs as we’ve discussed: their <code>;</code> is
our <code>Compose</code> (with its arguments flipped), their
<code>||</code> is our <code>FanOut</code>, their <code>|&gt;</code> is
our <code>:&gt;&gt;&gt;</code> and their <code>let-and</code> construct
could be achived by adding projection functions to our
<code>P</code>ipelines similar to <code>Fst</code> and <code>Snd</code>
for <code>SM</code>. Interestingly they don’t have any sum-types-like
construct here, i.e. something like
<code>(:|||) :: P a c -&gt; P b c -&gt; P (Either a b) c</code>;</li>
<li><input type="checkbox" />I like to think of how one constructs a
pipeline, i.e. the choice of which tasks should happen in parallel or
should be sharded etc, as a choice of how to best make use of the
CPUs/cores of a single computer. If seen this way then that begs the
question: what about a network of multiple computers? Perhaps there
should be something like a <code>Topology</code> data type which
describes how multiple pipelines interact and a topology is deployed by
deploying multiple pipelines over multiple machines?</li>
</ul>
</section>
<section id="see-also" class="level2">
<h2><a href="#see-also" title="See also">See also</a></h2>
<section id="presentations" class="level3">
<h3><a href="#presentations"
title="Presentations">Presentations</a></h3>
<ul>
<li><p><a href="https://www.infoq.com/presentations/LMAX/">LMAX - How to
Do 100K TPS at Less than 1ms Latency</a> by Martin Thompson (QCon
2010);</p></li>
<li><p><a href="https://youtube.com/watch?v=Qho1QNbXBso">LMAX Disruptor
and the Concepts of Mechanical Sympathy</a> by Jamie Allen
(2011);</p></li>
<li><p><a
href="https://www.infoq.com/presentations/Concurrent-Programming-Using-The-Disruptor/">Concurrent
Programming with the Disruptor</a> by Trisha Gee (2012);</p></li>
<li><p><a href="https://youtube.com/watch?v=2Be_Lqa35Y0">Disruptor 3.0:
Details and Advanced Patterns</a> by Mike Barker (YOW! 2013);</p></li>
<li><p><a href="https://youtube.com/watch?v=fDGWWpHlzvw">Designing for
Performance</a> by Martin Thompson (GOTO 2015);</p></li>
<li><p><a href="https://vimeo.com/181814364">A quest for predictable
latency with Java concurrency</a> Martin Thompson (JavaZone
2016);</p></li>
<li><p><a href="https://www.youtube.com/watch?v=qDhTjE0XmkE">Evolution
of Financial Exchange Architectures</a> by Martin Thompson (QCon
2020)</p>
<ul>
<li>1,000,000 tx/s and less than 100 microseconds latency, he is no
longer at LMAX though so we don’t know if these exchanges are using the
disruptor pattern.</li>
</ul></li>
<li><p><a href="https://youtube.com/watch?v=tM4YskS94b0"><em>Aeron:
Open-source high-performance messaging</em></a> talk by Martin Thompson
(Strange Loop, 2014);</p></li>
<li><p><em>Aeron: What, Why and What Next?</em> <a
href="https://youtube.com/watch?v=p1bsloPeBzE">talk</a> by Todd
Montgomery (GOTO, 2015);</p></li>
<li><p><em>Cluster Consensus: when Aeron met Raft</em> <a
href="https://youtube.com/watch?v=GFfLCGW_5-w">talk</a> by Martin
Thompson (GOTO, 2018);</p></li>
<li><p><em>Fault Tolerant 24/7 Operations with Aeron Cluster</em> <a
href="https://youtube.com/watch?v=H9yqzfNiEb4">talk</a> by Todd
Montgomery (2022).</p></li>
</ul>
</section>
<section id="writings" class="level3">
<h3><a href="#writings" title="Writings">Writings</a></h3>
<ul>
<li>Martin Thompson’s <a
href="https://mechanical-sympathy.blogspot.com/">blog</a>;</li>
<li>The Disruptor <a
href="https://groups.google.com/g/lmax-disruptor">mailing list</a>;</li>
<li>The Mechanical Sympathy <a
href="https://groups.google.com/g/mechanical-sympathy">mailing
list</a>;</li>
<li><a href="https://martinfowler.com/articles/lmax.html">The LMAX
Architecture</a> by Martin Fowler (2011);</li>
<li><a
href="https://en.wikipedia.org/wiki/Staged_event-driven_architecture">Staged
event-driven architecture</a>;</li>
<li><a href="https://www.reactivemanifesto.org/">The Reactive
Manifesto</a>;</li>
<li><a
href="https://en.wikipedia.org/wiki/Flow-based_programming">Flow-based
programming</a>.</li>
</ul>
</section>
</section>
</main>
</body>
</html>
